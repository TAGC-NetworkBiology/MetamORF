<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Sébastien A. Choteau" />
  <title>sORF datafreezer - User’s manual</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">sORF datafreezer - User’s manual</h1>
<p class="author">Sébastien A. Choteau</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#purpose">Purpose</a></li>
<li><a href="#starting-with-the-sorf-datafreezer">Starting with the sORF datafreezer</a>
<ul>
<li><a href="#system-requirements-and-dependencies">System requirements and dependencies</a></li>
<li><a href="#installing-the-sorf-datafreezer">Installing the sORF datafreezer</a></li>
</ul></li>
<li><a href="#quick-start">Quick start</a>
<ul>
<li><a href="#important-information-about-the-program">Important information about the program</a></li>
<li><a href="#running-a-strategy">Running a strategy</a></li>
<li><a href="#available-strategies">Available strategies</a></li>
<li><a href="#mandatory-options">Mandatory options</a></li>
</ul></li>
<li><a href="#log-files-and-verbosity-levels">Log files and verbosity levels</a>
<ul>
<li><a href="#main-log-file">Main log file</a></li>
<li><a href="#log-codes">Log codes</a></li>
<li><a href="#log-file-dedicated-to-gene-references-problems">Log file dedicated to gene references problems</a></li>
</ul></li>
<li><a href="#config-file">Config file</a>
<ul>
<li><a href="#description">Description</a>
<ul>
<li><a href="#database-connection-settings">Database connection settings</a></li>
<li><a href="#data-freeze-settings">Data-freeze settings</a></li>
<li><a href="#other-settings">Other settings</a></li>
</ul></li>
<li><a href="#example-of-config-file">Example of config file</a></li>
</ul></li>
<li><a href="#build-new-databases-check-existing-databases-add-a-release-version">Build new databases, check existing databases, add a release version</a>
<ul>
<li><a href="#build-new-databases-or-check-existing-ones">Build new databases or check existing ones</a>
<ul>
<li><a href="#databasecheck-command-line">DatabaseCheck command line</a></li>
</ul></li>
<li><a href="#add-release-version">Add release version</a>
<ul>
<li><a href="#addreleaseversion-command-line">AddReleaseVersion command line</a></li>
</ul></li>
</ul></li>
<li><a href="#freeze-the-data-sources-in-a-ds-database">Freeze the data sources in a DS database</a>
<ul>
<li><a href="#insert-data-sources">Insert data sources</a>
<ul>
<li><a href="#information-regarding-the-insertion-strategy">Information regarding the Insertion strategy</a></li>
<li><a href="#insertion-command-line">Insertion command line</a></li>
<li><a href="#description-of-the-rules-of-insertion">Description of the rules of insertion</a></li>
<li><a href="#dealing-with-conflicting-information-about-orf-properties">Dealing with conflicting information about ORF properties</a></li>
</ul></li>
<li><a href="#resume-an-insertion-that-failed">Resume an insertion that failed</a>
<ul>
<li><a href="#information-regarding-the-forceinsertion-strategy">Information regarding the ForceInsertion strategy</a></li>
<li><a href="#forceinsertion-command-line">ForceInsertion command line</a></li>
</ul></li>
<li><a href="#remove-data-sources">Remove data sources</a>
<ul>
<li><a href="#information-regarding-the-deletion-strategy">Information regarding the Deletion strategy</a></li>
<li><a href="#deletion-command-line">Deletion command line</a></li>
</ul></li>
</ul></li>
<li><a href="#normalize-data">Normalize data</a>
<ul>
<li><a href="#convert-the-genomic-coordinates-lift-over">Convert the genomic coordinates (lift over)</a>
<ul>
<li><a href="#information-regarding-the-liftover-strategy">Information regarding the LiftOver strategy</a></li>
<li><a href="#liftover-command-line">LiftOver command line</a></li>
<li><a href="#description-of-the-rules-of-lift-over">Description of the rules of lift over</a></li>
</ul></li>
</ul></li>
<li><a href="#merge-redundant-data-into-unique-entries">Merge redundant data into unique entries</a>
<ul>
<li><a href="#create-the-pro-database-from-a-ds-database">Create the PRO database from a DS database</a>
<ul>
<li><a href="#information-regarding-the-merge-strategy">Information regarding the Merge strategy</a></li>
<li><a href="#merge-command-line">Merge command line</a></li>
</ul></li>
<li><a href="#resume-a-merging-that-failed">Resume a merging that failed</a>
<ul>
<li><a href="#information-regarding-the-resumemerge-strategy">Information regarding the ResumeMerge strategy</a></li>
<li><a href="#troubleshooting">Troubleshooting</a></li>
<li><a href="#resumemerge-command-line">ResumeMerge command line</a></li>
</ul></li>
</ul></li>
<li><a href="#complete-the-missing-information-normalize-data-and-compute-new-information">Complete the missing information, normalize data and compute new information</a>
<ul>
<li><a href="#download-missing-information-and-normalize-cell-contexts">Download missing information and normalize cell contexts</a>
<ul>
<li><a href="#information-regarding-the-computemissinginfo-strategy">Information regarding the ComputeMissingInfo strategy</a></li>
<li><a href="#computemissinginfo-command-line">computeMissingInfo command line</a></li>
<li><a href="#resume-a-computemissinginfo-that-failed">Resume a ComputeMissingInfo that failed</a></li>
<li><a href="#troubleshooting-1">Troubleshooting</a></li>
</ul></li>
<li><a href="#computing-the-relative-coordinates">Computing the relative coordinates</a>
<ul>
<li><a href="#information-regarding-the-computerelcoord-strategy">Information regarding the ComputeRelCoord strategy</a></li>
<li><a href="#computerelcoord-command-line">ComputeRelCoord command line</a></li>
<li><a href="#resume-a-computerelcoord-that-failed">Resume a ComputeRelCoord that failed</a></li>
<li><a href="#troubleshooting-2">Troubleshooting</a></li>
</ul></li>
<li><a href="#get-the-start-flanking-sequence-and-information-regarding-the-kozak-context">Get the start flanking sequence and information regarding the Kozak context</a>
<ul>
<li><a href="#information-regarding-the-computekozakcontext-strategy">Information regarding the ComputeKozakContext strategy</a></li>
<li><a href="#computekozakcontext-command-line">ComputeKozakContext command line</a></li>
<li><a href="#resume-a-computekozakcontext-that-failed">Resume a ComputeKozakContext that failed</a></li>
</ul></li>
<li><a href="#normalize-the-orf-categories-compute-new-orf-annotations">Normalize the ORF categories, compute new ORF annotations</a>
<ul>
<li><a href="#information-regarding-the-annotateorf-strategy">Information regarding the AnnotateORF strategy</a></li>
<li><a href="#annotateorf-command-line">AnnotateORF command line</a></li>
<li><a href="#resume-a-annotateorf-that-failed">Resume a AnnotateORF that failed</a></li>
</ul></li>
</ul></li>
<li><a href="#filter-in-the-database-content-and-create-a-new-database">Filter in the database content and create a new database</a>
<ul>
<li><a href="#information-regarding-the-filter-strategy">Information regarding the Filter strategy</a></li>
<li><a href="#filter-command-line">Filter command line</a></li>
</ul></li>
<li><a href="#export-the-database-content">Export the database content</a>
<ul>
<li><a href="#export-the-orf-sequences-at-fasta-format">Export the ORF sequences at fasta format</a>
<ul>
<li><a href="#information-regarding-the-headers">Information regarding the headers</a></li>
<li><a href="#generatefastafile-command-line">GenerateFastaFile command line</a></li>
</ul></li>
<li><a href="#export-the-orf-information-at-bed-format">Export the ORF information at BED format</a>
<ul>
<li><a href="#information-regarding-the-bed-format">Information regarding the BED format</a></li>
<li><a href="#adding-a-track-line-to-the-file">Adding a track line to the file</a></li>
<li><a href="#information-regarding-the-additional-columns">Information regarding the additional columns</a></li>
<li><a href="#converting-the-bed-file-at-bigbed-format">Converting the BED file at bigBed format</a></li>
<li><a href="#additional-information-regarding-the-generatebedfile-strategy">Additional information regarding the GenerateBEDFile strategy</a></li>
<li><a href="#generatebedfile-command-line">GenerateBEDFile command line</a></li>
<li><a href="#generatebedcontent-command-line">GenerateBEDContent command line</a></li>
</ul></li>
<li><a href="#generate-a-trackdb-file-for-track-hub-implementation">Generate a trackDb file for track hub implementation</a>
<ul>
<li><a href="#information-regarding-the-trackdb-file-generated">Information regarding the trackDb file generated</a></li>
<li><a href="#generatetrackdbfile-command-line">GenerateTrackDbFile command line</a></li>
</ul></li>
<li><a href="#export-the-orf-information-at-gff-format-beta-version">Export the ORF information at GFF format [BETA VERSION]</a>
<ul>
<li><a href="#information-regarding-the-gff3-file">Information regarding the GFF3 file</a></li>
<li><a href="#generategfffile-command-line">GenerateGFFFile command line</a></li>
</ul></li>
</ul></li>
<li><a href="#diagnosis-tools">Diagnosis tools</a>
<ul>
<li><a href="#assess-consistency-of-the-database-content">Assess consistency of the database content</a>
<ul>
<li><a href="#assessment-of-ds-databases">Assessment of DS databases</a></li>
<li><a href="#assessment-of-pro-databases">Assessment of PRO databases</a></li>
<li><a href="#assessdatabasecontent-command-line">AssessDatabaseContent command line</a></li>
</ul></li>
<li><a href="#get-a-summary-of-log-files">Get a summary of log files</a>
<ul>
<li><a href="#generatestatfiles-command-line">GenerateStatFiles command line</a></li>
</ul></li>
<li><a href="#statistical-analysis-of-the-database-content">Statistical analysis of the database content</a></li>
</ul></li>
<li><a href="#backup-restore-and-convert-databases">Backup, restore and convert databases</a>
<ul>
<li><a href="#database-backup">Database backup</a>
<ul>
<li><a href="#backup-command-line">Backup command line</a></li>
</ul></li>
<li><a href="#restoring-a-database">Restoring a database</a>
<ul>
<li><a href="#restore-command-line">Restore command line</a></li>
</ul></li>
<li><a href="#convert-sqlite-databases-at-mysql-format-and-vice-versa">Convert SQLite databases at MySQL format and vice versa</a></li>
</ul></li>
<li><a href="#information-to-developers">Information to developers</a></li>
<li><a href="#list-of-available-options">List of available options</a></li>
<li><a href="#list-of-default-values">List of default values</a></li>
<li><a href="#additional-information">Additional information</a></li>
<li><a href="#authors-license-and-copyright">Authors, license and copyright</a></li>
<li><a href="#last-update-of-the-manual-25052020">Last update of the manual: 25/05/2020</a></li>
</ul>
</nav>
<h1 id="purpose">Purpose</h1>
<p>This manual is dedicated to sORF datafreezer users and aims to describe the main functions of this tool and to provide useful information regarding its use. The sORF datafreezer is able to handle data from pre-defined data sources, parse them and insert them into MySQL or SQLite databases and process these information. The processing steps includes data normalization, completion of missing information, computation of new informations as well as the export of data at convenient formats (Fasta, BED …) for further use. The sORF datafreezer come along with some diagnosis tools allowing to ensure the consistency of data, integrity of the database as well as export / import databases.</p>
<h1 id="starting-with-the-sorf-datafreezer">Starting with the sORF datafreezer</h1>
<h2 id="system-requirements-and-dependencies">System requirements and dependencies</h2>
<p>The sORF datafreezer is a software build in Python 2.7. It can be run on any operating system where dependencies have been successfully installed. A minimum of 62 GB of RAM memory, 12 threads is highly recommended to run the software. We advice to use machines with at least 40 threads, 192 GB of RAM if you intend to use all strategies. A stable connection to the Internet is also required as some information are queried from different databases accessible online.</p>
<p>To be able to use all functions of the program, the following dependencies are required:</p>
<ul>
<li><p><code>Python 2.7</code>, with packages:</p>
<ul>
<li><code>SQLAlchemy</code></li>
<li><code>Pandas</code></li>
<li><code>PyEnsembl</code></li>
<li><code>PyBiomart</code></li>
<li><code>PyLiftOver</code></li>
<li><code>wget</code></li>
<li><code>statistics</code></li>
<li><code>BioPython</code></li>
<li><code>mysql-connector-python</code></li>
<li><code>pathos</code></li>
</ul></li>
<li><p><code>R</code>, with packages:</p>
<ul>
<li><code>getopt</code></li>
<li><code>devtools</code></li>
<li><code>Bioconductor</code>: <code>ensembldb</code>, <code>AnnotationHub</code></li>
</ul></li>
<li><p><code>MySQL</code></p></li>
<li><p><code>SQLite3</code></p></li>
<li><p><code>MUSCLE</code> (Multiple sequence alignment software)</p></li>
<li><p>UCSC utils</p>
<ul>
<li><code>fetchChromSizes</code></li>
<li><code>bedToBigBed</code></li>
</ul></li>
</ul>
<p>Please see the official documentation of these sotwares and packages for more information regarding their installation. A dockerfile as well as a Singularity image providing the appropriate environment are available with the source code.</p>
<h2 id="installing-the-sorf-datafreezer">Installing the sORF datafreezer</h2>
<p>The ORF datafreezer may be run using the Singularity image provided with the code source. In such cases, Singularity needs to be installed on the computer. Please refer to the <a href="https://singularity.lbl.gov/">official documentation</a> for more information about the use and installation of Singularity.</p>
<p>The program may also be run using the docker image provided with the source code. Please refer to the <a href="https://www.docker.com/">official documentation</a> of Docker for more information about the use and installation of Docker. Please note that we do not guarantee the success of building a new docker image using the dockerfile as some external links could be out-of-date or programs source code / binaries could be no longer available.</p>
<p>The <code>PYTHONPATH</code> environment variable needs to be defined and point to the path to the <code>06_src</code> folder (<code>export PYTHONPATH=/path/to/06_src</code>).</p>
<p>In this manual, the alias <code>sORFdatafreezer</code> will be used to refer to the following command: <code>python $PYTHONPATH/fr/tagc/uorf/uorf.py</code>. <code>uorf.py</code> represents the entrypoint of the source code and must <strong>always</strong> be called to use any function defined in the current manual.</p>
<h1 id="quick-start">Quick start</h1>
<h2 id="important-information-about-the-program">Important information about the program</h2>
<p>This program has been developed in order to build a datafreeze of short open reading frames (sORFs)-related data. It includes several <strong>“strategies”</strong> that may be run in order to build SQLite or MySQL databases, parse and insert data from some data sources and process the data. This manual describes all available strategies and provides the necessary information to use this program. It also provides general information about the way the data are handled within each strategy.</p>
<p>This datafreezer uses several databases to handle the data. Each database uses a particular model (<em>i.e.</em> a particular structure) to store the data. More precisely, the data from the sources are parsed and stored in a “<strong>DS</strong> database” (standing for <em>Data Source</em> database, and corresponding to an actual data-freeze of available data), while the processed data are stored in a “<strong>PRO</strong> database” (standing for <em>PROcessed</em> database).</p>
<p>New databases may be created from the PRO database, for instance by filtering all the entries on a particular list of genes or to get only the ORFs having a particular annotation (<em>e.g.</em> sORFs, uORFs…). In such cases, the resulting databases are called <strong>FILT</strong> databases, and follow the same model as the <strong>PRO</strong> database, meaning that both have the same structure but contain different data. Hence, the term “<strong>PRO-like databases</strong>” used in this manual refers indifferently to PRO or FILT databases. Any strategy requiring a PRO-like database may be used on both PRO and FILT databases.</p>
<p>The source code has been developed in order to be able to handle both MySQL and SQLite database. Nevertheless, all strategies and options have <strong>not</strong> been tested on SQLite databases. Hence we strongly encourage to use MySQL databases.</p>
<h2 id="running-a-strategy">Running a strategy</h2>
<p>In order to start a process, <code>sORFdatafreezer</code> needs to be followed by the name of the <strong>strategy</strong> to run and the options to use, using a syntax similar to the following one:</p>
<pre><code>sORFdatafreezer [StrategyKeyword] [Options]</code></pre>
<p>The options may be provided using indifferently short (<code>-h</code>) or long tags (<code>--help</code>). Use the tag <code>-h</code> / <code>--help</code> to display help. The command <code>sORFdatafreezer -h</code> will display on the terminal a general help and list available strategies whilst <code>sORFdatafreezer [StrategyKeyword] -h</code> will display all the options available for the strategy with a short description. Options are case-sensitive.</p>
<h2 id="available-strategies">Available strategies</h2>
<p>The sORF datafreezer includes several strategies that may be run independently from each other. Nevertheless, some strategies may need an other strategy to have been run successfully in order to run properly. Each strategy may require the access to one of several databases. All the strategies are described more extensively in the following sections of this manual.</p>
<p>The following strategies are available:</p>
<ul>
<li><p>Build databases, check existing databases, add a release version</p>
<ul>
<li><p><strong>DatabaseCheck</strong>: Build new empty DS and PRO databases; check existing databases are reachable and use the appropriate models.</p></li>
<li><p><strong>AddReleaseVersion</strong>: Tag a database by adding a release version in the metadata table.</p></li>
</ul></li>
<li><p>Build a data-freeze</p>
<ul>
<li><p><strong>Insertion</strong>: Parse and insert data from a pre-defined set of sources into the DS database.</p></li>
<li><p><strong>Deletion</strong>: Remove all the data related to a particular data source from the DS database.</p></li>
<li><p><strong>ForceInsertion</strong>: Insert data that have already been parsed (using the <strong>Insertion</strong> strategy), but for which insertion in the DS database failed.</p></li>
</ul></li>
<li><p>Normalize data</p>
<ul>
<li><strong>LiftOver</strong>: Lift over the genomic coordinates contained in the DS database, <em>i.e</em> convert the genomic coordinates of all the DSORF and DSTranscript entries from their original annotation version to the current version.</li>
</ul></li>
<li><p>Merge redundant data</p>
<ul>
<li><p><strong>Merge</strong>: Build a new PRO database by merging the redundant data present in the DS database.</p></li>
<li><p><strong>ResumeMerge</strong>: Resume at a particular checkpoint a merging that failed.</p></li>
</ul></li>
<li><p>Complete missing data and compute new information</p>
<ul>
<li><p><strong>ComputeMissingInfo</strong>: Complete the missing information of the PRO database by computing it or downloading it.</p></li>
<li><p><strong>ComputeRelCoord</strong>: Compute ORF and CDS relative coordinates on transcripts.</p></li>
<li><p><strong>ComputeKozakContext</strong>: Compute the Kozak contexts for each ORF on each known transcript.</p></li>
<li><p><strong>AnnotateORFStrategy</strong>: Perform a classification of ORFs by categories (short, upstream…).</p></li>
</ul></li>
<li><p>Filter the database</p>
<ul>
<li><strong>Filter</strong>: Create a new <strong>FILT</strong> database by filtering the entries on a list of genes, cell contexts, ORF categories or ORF annotations.</li>
</ul></li>
<li><p>Export data</p>
<ul>
<li><p><strong>GenerateFastaFile</strong>: Generate a fasta file of all nucleic or amino acid sequences of the <em>ORF</em> or <em>ORFTranscriptAsso</em> table.</p></li>
<li><p><strong>GenerateBEDFile</strong>: Generate a BED file that may be used to visualize the data in a genome browser.</p></li>
<li><p><strong>GenerateTrackDbFile</strong>: Generate a trackDb file that may be used to implement track hubs compatible with UCSC and Ensembl genome browsers.</p></li>
<li><p><strong>GenerateGFFFile</strong>: <strong>[Beta-version]</strong> Generate a GFF3 file from the content of the <em>ORF</em> table of the PRO database. Currently the GFF3 generated does not respect the sequence ontology, this should be fix in a future version.</p></li>
</ul></li>
<li><p>Diagnosis tools</p>
<ul>
<li><p><strong>AssessDatabaseContent</strong>: Check the consistency of the data contained in a database.</p></li>
<li><p><strong>GenerateStatFiles</strong>: Generate a set of files that summarize information contained in logs.</p></li>
</ul></li>
<li><p>Backup and restore</p>
<ul>
<li><p><strong>Backup</strong>: Backup a DS or PRO database in ‘.dcorf’ files.</p></li>
<li><p><strong>Restore</strong>: Restore a DS or PRO database previously saved using the <strong>Backup</strong> strategy.</p></li>
</ul></li>
</ul>
<h2 id="mandatory-options">Mandatory options</h2>
<p>For any strategy, this is necessary to provide the database(s) type using the <code>--databaseType</code> (<code>-T</code>) option. If this option is not provided by the user, the program uses SQLite database type by default (as it does not need an available MySQL server to run properly). Be aware that for any strategy using several databases at the same time (such as the <strong>Merge</strong> or the <strong>Filter</strong> strategies for instance), all the databases <strong>must</strong> be of the same type and located in the same folder (SQLite) or on the same server (MySQL).</p>
<p>Most of the strategies uses a config file that needs to be provided using the <code>--configfile</code> (<code>-c</code>) option. A section of this manual is dedicated to the format in which this file has to be provided. Please see the <em>Config file</em> section of the current manual for more information.</p>
<p>Verbosity level may be set using the <code>-v</code> / <code>--verbosity</code> option. See the <strong>Log files and verbosity levels</strong> section of the current manual for more information.</p>
<h1 id="log-files-and-verbosity-levels">Log files and verbosity levels</h1>
<h2 id="main-log-file">Main log file</h2>
<p>During the execution of the program, all useful information are written in log files (<code>execution.log</code>) and displayed on the console at runtime. By default, the level of verbosity is set to <code>info</code> but it is possible to set it to an other level using the <code>--verbose</code> (<code>-v</code>) option. By default, the log files may not exceed 1 MB for each. When a file reaches this value, a new one is created adding the <code>.n</code> suffix.</p>
<p>The following levels of verbosity are available:</p>
<ul>
<li><p><strong>debug</strong>: Show all the logs generated during the execution of the program. These include extensive information about the processing of each step of the program and logs essentially dedicated to the developers. Information exclusively displayed in this mode are not essentials for most of the users.</p></li>
<li><p><strong>info</strong>: Show information about the execution of the program. These include information related to the major steps of the processing which are dedicated to the user and/or allowing the user to follow the process. All warning, error and critical logs are also displayed in this mode.</p></li>
<li><p><strong>warning</strong>: Show information related to problems that may alter the data (and eventually the processing). Messages logged at the warning level does not provoke the halt of the program but may reveal some important problems related to the operation performed by the program or related to the data itself. All warning, error and critical logs are displayed but information about the normal processing of the program are not.</p></li>
<li><p><strong>error</strong>: Show information about errors that happened during processing. Note that errors logged at this levels do not stop the program. Only error and critical logs are displayed in this mode.</p></li>
<li><p><strong>critical</strong>: Show information about critical errors that occurred and were responsible of the premature end of the program. A critical message is logged when the program has been stopped due to a major problem. When available, information about the operation that raised the error and / or a traceback are added to the message. Only critical logs are displayed when the verbosity is set to this level. Critical errors dues to the error are expected to always display a clear message about the problem (<em>e.g.</em> missing config file, incorrect path provided …). If this is not the case, please contact the developer with a copy of the log file.</p></li>
</ul>
<p>If you do not know which level use, we advice to use default <code>info</code> level.</p>
<p>Each log is preceded by the date and precise hour at which the message has been generated as well as the level of the log (in the format <code>yyyy-mm-dd hh:mm:ss,sss :: VERBOSITY_LEVEL :: Message logged</code>).</p>
<h2 id="log-codes">Log codes</h2>
<p>Most of the warning and error messages contain a unique <strong>“log code”</strong> allowing to easily extract the information from the log files. A “hierarchy” of log codes has been set based upon the related problem reported by the message, so this makes possible to extract all the logs related to a category of problems at the same time (using the <code>grep</code> command for instance). The list of all available log codes (warning and errors) is provided with the documentation at <code>.csv</code> format.</p>
<h2 id="log-file-dedicated-to-gene-references-problems">Log file dedicated to gene references problems</h2>
<p>All problems related to gene references (<em>e.g.</em> when the program was not able to find in the database an unique gene corresponding to a particular alias) are logged in separated log files (called <code>generefwarnings.log</code>). Please note that this is not possible to change the level of verbosity of the messages logged of this file as it is automatically set by the program. This file is generated when a warning related to gene references appears for the first time and its creation is indicated at warning level in the main log file (<code>execution.log</code>).</p>
<p>In this log file, one of the following prefix is usually added prior to the message:</p>
<ul>
<li><p><strong>CROSSREF WARNING</strong>: Report a warning related to the cross-references (<em>e.g.</em> when the same official symbol is used for several genes).</p></li>
<li><p><strong>GENE UPDATE</strong>: Report a warning related to the update of a gene or gene alias (<em>e.g.</em> when the chromosome information of a gene was missing and filled in later using information provided in a source).</p></li>
<li><p><strong>MISSING REFERENCE</strong>: Report a warning when the program has not been able to find a particular gene or alias.</p></li>
<li><p><strong>NEW ENTRY</strong>: Report a message when the program creates a new entry in the Gene or in the <em>GeneAlias</em> table. Note that the program does not log the creation of all entries during the insertion of the gene lists (<em>i.e.</em> it only logs the entries created later, such as during the insertion of data).</p></li>
<li><p><strong>CONFLICTING INFO</strong>: Report a warning when conflicting information have been found for the same gene (<em>e.g</em> when the same gene is found in a source with a different chromosome location than the one already registered for this gene).</p></li>
<li><p><strong>GENE SEARCH</strong>: Report a warning related to problems during gene search (<em>e.g.</em> when several genes have been found associated to one single alias and the program has no way to determine which one to use).</p></li>
</ul>
<h1 id="config-file">Config file</h1>
<h2 id="description">Description</h2>
<p>Most of the strategies need a config file in order to run properly. The config file should be a file without any extension (or eventually with a <code>.txt</code> extension) and aims to provide file paths and options necessary to run the program.</p>
<p>The config file may contain sections embedding themselves items. The section names have to be declared with brackets (<em>e.g.</em> <code>[SECTION]</code>) whilst the items of the section are followed by an equal symbol (<em>e.g.</em> <code>ITEM = value</code>). Both section and item names are <strong>case-sensitive</strong>. Depending on the strategy used, some sections and items are mandatory whilst other are not (in such cases default values are used when they are missing from the config file).</p>
<p>Comments may be added anywhere in the config file starting the line with <code>#</code>.</p>
<pre><code># Example of config file
[SECTION_NAME]
ITEM_1 = value
ITEM_2 = value</code></pre>
<p>The sections and their items are described here. See the chapter of the current manual related to the strategy you are willing to use for more information about these options.</p>
<h3 id="database-connection-settings">Database connection settings</h3>
<ul>
<li><p><code>[DATABASE]</code> section: Aims to contain general information related to the database.</p>
<ul>
<li><p><code>DATABASE_SPECIES</code>: Short scientific name of the species contained in the database. Only <code>Hsapiens</code> and <code>Mmusculus</code> are allowed at the moment. One single species must be provided at the time, as the program is not able to build database containing data from multiple species.</p></li>
<li><p><code>DS_DATABASE_NAME</code>: Name of the DS database.</p></li>
<li><p><code>PRO_DATABASE_NAME</code>: Name of the PRO (or PRO-like) database.</p></li>
<li><p><code>FILT_DATABASE_NAME</code>: Name of the FILT database.</p></li>
<li><p>Items allowing connection to MySQL database:</p>
<ul>
<li><code>DATABASE_HOST_IP</code>: IP of the MySQL server.</li>
<li><code>DATABASE_PORT</code>: Port of the MySQL server.</li>
<li><code>DATABASE_USER_NAME</code>: MySQL user.</li>
<li><code>DATABASE_USER_PASSWD</code>: MySQL user’s password.</li>
</ul></li>
<li><p>Items allowing connection to SQLite database:</p>
<ul>
<li><code>DATABASE_FOLDER</code>: Folder where the SQLite file is located or has to be created.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="data-freeze-settings">Data-freeze settings</h3>
<ul>
<li><p><code>[GENE_LISTS]</code> section: Aims to contain information about the gene lists to insert. Each list to insert has to be provided as a new line of this section and with the <strong>absolute</strong> path to its associated file, using the format <code>GeneListName = /aboslute/path/to/file.ext</code>). Be aware that the name of the gene list (<code>GeneListName</code>) has to be the same (with same case) than the name of one parser. A list of available parsers with a short description is provided in the <em>Additional information</em> section of this manual. The <code>[GENE_LIST_ORDER_OF_INSERTION]</code> section may be filled when several gene lists are provided to insert the lists in a particular order. In such case, the name of the gene lists to insert first has to be provided using the item named <code>GL_INSERTION_ORDER</code>, separating each gene list name by a comma (<code>,</code>, the list may include spaces between each gene list) and the name of each gene list <strong>has to be the same as the one used to provide the path to its file</strong>.</p></li>
<li><p><code>[DATASOURCE]</code> section: Aims to contain information about the data to insert. Each data source has to be provided as an item of this section and with the <strong>absolute</strong> path to the file (using the format <code>DataSource = /absolute/path/to/file.ext</code>). Like for the gene lists, be aware that the name of the data source (<code>DataSource</code>) has to be the same (and using the same case) as the name of one parser (see <em>Additional information</em> section). The <code>[DATA_INSERTION_ORDER]</code> section offers the possibility to insert data in a particular order when several datasets are provided. If this option is used, the name of the sources to insert first have to be provided using the item <code>DATA_INSERTION_ORDER</code>, separating each source name by a comma (<code>,</code>, the list may include spaces between each datasource name) and the name of each source has to be the same as the one used to provide the path to its file.</p></li>
<li><p>NB: When the <code>[GENE_LIST_ORDER_OF_INSERTION]</code> or the <code>[DATA_ORDER_OF_INSERTION]</code> section is provided, the program first inserts all the sources explicitly named using the option (respectively using the <code>GL_INSERTION_ORDER</code> and <code>DATA_INSERTION_ORDER</code> lists) in the appropriate order. If there are other sources provided in the config file which are not present in this list, the program will then treats them after in a random order.</p></li>
</ul>
<h3 id="other-settings">Other settings</h3>
<ul>
<li><p><code>[MERGE_PARAMETERS]</code> section: Aims to contain parameters necessary to run the Merge strategy.</p>
<ul>
<li><p><code>GENOMIC_LENGTH_DIFF_THRESHOLD</code>: Threshold for absolute difference in genomic length. The genomic length (defined as the cumulative sum of an ORF exons) is computed for each entry of the ORF table prior and after the lift over (<em>i.e.</em> the conversion of genomic coordinates from an annotation version to the current one) and their absolute difference is calculated. This item allow to exclude all the entries that have a difference larger or equal to the provided threshold. Setting the threshold to <code>-1</code> allow to ignore this option.</p></li>
<li><p><code>SEQUENCE_CONSENSUS_AMBIGUOUS_THRESHOLD</code>: Threshold to use to include a nucleotide or an amino acid in a sequence consensus.</p></li>
<li><p><code>MAX_LEN_DIFF_FOR_DSOTA_CLUSTERS</code>: Maximum difference between the lengths of two ORF to belong to the same cluster when merging the DSORFTranscriptAsso entries (in amino acids). When setting this parameter to 3, two DSORFTranscriptAsso will be considered as being part of two different “clusters” if the difference of their length equals or exceeds 4.</p></li>
</ul></li>
<li><p><code>[COMPUTE_MISSING_INFO_PARAMETERS]</code> section: Aims to contain parameters to compute missing data.</p>
<ul>
<li><code>CELL_CONTEXTS_DICTIONARY</code>: A dictionary (using Python syntax) that inform how the cell contexts have to be renamed and / or merged. This dictionary should be provided using a syntax similar to the following one:</li>
</ul></li>
</ul>
<pre><code>CELL_CONTEXTS_DICTIONARY = { &#39;NewContext1&#39; : [ &#39;context1&#39;, &#39;context2&#39; ], &#39;NewContext2&#39; : [ &#39;context3&#39; ] }
# Using this dictionary,
# context1 and context2 will be merged and renamed into NewContext1
# context3 will be renamed into NewContext2

# The default dictionary is available in the additional information section of the current manual</code></pre>
<ul>
<li><p><code>[ANNOTATE_ORF_PARAMETERS]</code> section: Aims to contain parameters necessary to run the ORFAnnotation strategy.</p>
<ul>
<li><p><code>CATEGORY_ASSOCIATION_DICTIONARY</code>: A dictionary (using Python syntax) that informs how the provided ORF categories have to be renamed and / or merged. See the <strong>Additionnal information</strong> section of the current manual for the default dictionary.</p></li>
<li><p><code>SHORT_ORF_ANNOTATION_SIZE_THRESHOLD</code>: Until which length in in amino acids the ORFs have to be annotated as short.</p></li>
</ul></li>
<li><p><code>[FILTERING]</code> section: Aims to provide parameters necessary to build a <strong>FILT</strong> database</p>
<ul>
<li><p><code>FILTERING_TYPE</code>: Should the query use an intersection or an union of the provided values? (<code>intersection</code> or <code>union</code>). This item is mandatory.</p></li>
<li><p><code>GENE_LIST_FILTER</code>: The absolute path to a list of genes.</p></li>
<li><p><code>CELL_CONTEXT_FILTER</code>: A comma-separated list of cellular contexts.</p></li>
<li><p><code>ORF_CATEGORY_FILTER</code>: A comma-separated list of ORF categories.</p></li>
<li><p><code>ORF_ANNOTATION_FILTER</code>: A comma-separated list of ORF annotations.</p></li>
</ul></li>
</ul>
<p>The sections or items that are not necessary for a strategy will be ignored. Any line starting with <code>#</code> will be considered as a comment and hence ignored.</p>
<h2 id="example-of-config-file">Example of config file</h2>
<pre><code>
# The structure of this file and section names should not be changed!
# See the documentation for more information.

# ===============================================================================
# Information
# ===============================================================================

# This is an example of config file that may be used 
# with the sORF datafreezer.


# ===============================================================================
# Database
# ===============================================================================

## DATABASE
#  --------
# This section contains general information about the database.

[DATABASE]

# Name of the database
DS_DATABASE_NAME = Hsapiens_DS
PRO_DATABASE_NAME = Hsapiens_PRO
FILT_DATABASE_NAME = Hsapiens_PRO_uORF

# Species contained in the database
DATABASE_SPECIES = Hsapiens

# MySQL server settings
DATABASE_USER_NAME = root
DATABASE_USER_PASSWD = root
DATABASE_HOST_IP = 127.0.0.1
DATABASE_PORT = 3306




# ===============================================================================
# Gene lists of reference
# ===============================================================================

## GENE_LISTS
#  ----------
# This section contains the paths to the gene lists and cross-references that need to be
# parsed and for which data need to be inserted in the database.
# For a given list, provide the name of the list and the absolute path to its file.
# The name of the list has to be the same as the name of one file parser.

[GENE_LISTS]

# HGNC gene list (HGNC IDs used as unique gene IDs in the database)
HGNCGeneList = /07_input/cross_references/hsapiens_HGNC.txt



## GENE_LIST_ORDER_OF_INSERTION
#  ----------------------------
# This section has to be provided if the gene lists need to be parsed and inserted in a 
# specific order. List names have to be separated with a comma and using the same name as 
# in the &quot;DATASOURCE&quot; section. This section does not need to be provided if there is one 
# single list use for cross-references.

[GENE_LIST_ORDER_OF_INSERTION]
GL_INSERTION_ORDER = HGNCGeneList




# ===============================================================================
# Data sources to insert in the database
# ===============================================================================

## DATASOURCE
#  ----------
# This section contains the paths to the files that need to be parsed and for which data 
# need to be inserted in the database.
# For a given source, provide the name of the source and the absolute path to its file.
# The name of the source has to be the same as the name of one file parser.

[DATASOURCE]

# sORFs database (Olexiouk et al., 2017)
sORFs_org_Human = /07_input/ORF_datasources/hsapiens_sORFs.org.txt

# Erhard et al., 2018
Erhard2018 = /07_input/ORF_datasources/hsapiens_Erhard2018.csv

# Mackowiak et al., 2015
Mackowiak2015 = /07_input/ORF_datasources/hsapiens_Mackowiak2015.txt

# Johnstone et al., 2016
Johnstone2016 = /07_input/ORF_datasources/hsapiens_Johnstone2016.txt

# Laumont et al., 2016
Laumont2016 = /07_input/ORF_datasources/hsapiens_Laumont2016.csv

# Samandi et al., 2017
Samandi2017 = /07_input/ORF_datasources/hsapiens_Samandi2017.tsv



## DATA_ORDER_OF_INSERTION
#  -----------------------
# This section has to be provided if the raw data need to be parsed and inserted in a 
# specific order. Sources have to be separated with a comma and using the same name as 
# in the &quot;DATASOURCE&quot; section. The program will first treat the sources provided in this
# list in the appropriate order and then parse and insert data from the other sources if 
# all of them are not present in this list. Usually this section does not need to be 
# provided.

[DATA_ORDER_OF_INSERTION]
DATA_INSERTION_ORDER = sORFs_org_Human, Erhard2018, Mackowiak2015, Johnstone2016, Laumont2016, Samandi2017




# ===============================================================================
# Parameters for the merging
# ===============================================================================

## MERGE_PARAMETERS
#  ----------------
# This section contains parameters necessary to build the PRO database.

[MERGE_PARAMETERS]

# Threshold for the genomic length differences over which the DSORF entry
# have to be excluded from the PRO database. Use -1 to ignore this option.
GENOMIC_LENGTH_DIFF_THRESHOLD = 1

# Threshold to use for a letter (nucleotide / amino acid) to not be considered ambiguous
# (i.e. minimal proportion of sequences that needs to contains a particular letter at a
# given place to consider this letter in the consensus).
SEQUENCE_CONSENSUS_AMBIGUOUS_THRESHOLD = 0.66


# Maximal difference to use between the maximal and minimal lengths of DSORFTranscriptAsso
# to belong to the same group (value included).
# e.g. If max_len_diff = 3, Two DSORFTranscriptAsso will be considered as being part 
#      of two different &quot;clusters&quot; if the difference of their length exceed 4.
MAX_LEN_DIFF_FOR_DSOTA_CLUSTERS = 3




# ===============================================================================
# Parameters for the computation of missing information
# ===============================================================================

## COMPUTE_MISSING_INFO_PARAMETERS
#  -------------------------------
# This section contains parameters necessary compute missing information
# in the PRO database.

[COMPUTE_MISSING_INFO_PARAMETERS]

# The following dictionary allows to associate the cell contexts as
# provided in the data sources to &quot;normalized&quot; cell contexts                                    
CELL_CONTEXTS_DICTIONARY = { 
                                &#39;BJ&#39;:               [ &#39;loayza_puch_2013&#39;, &#39;rooijers_2013&#39;, &#39;ji_BJ_2015&#39; ],
                                &#39;B_cell&#39;:           [ &#39;B cells&#39; ],
                                &#39;Blood&#39;:            [ &#39;mills_2016&#39; ],
                                &#39;Brain&#39;:            [ &#39;gonzalez_2014&#39; ],
                                &#39;Brain_tumor&#39;:      [ &#39;Human brain tumor&#39;, &#39; Human brain tumor&#39; ],
                                &#39;Breast&#39;:           [ &#39;ji_breast_2015&#39; ],
                                &#39;HAP1&#39;:             [ &#39;jakobsson_2017&#39; ],
                                &#39;HCT116&#39;:           [ &#39;crappe_2014&#39; ],
                                &#39;HEK293&#39;:           [ &#39;lee_2012&#39;, &#39;andreev_2015&#39;, &#39;sidrauski_2015&#39;, &#39;liu_2013_HEK&#39;, 
                                                      &#39;ingolia_2012&#39;, &#39;ingolia_2014&#39;, &#39;calviello_2016&#39;, &#39;iwasaki_2016&#39;,
                                                      &#39;park_2017&#39;, &#39;zhang_2017&#39;, &#39; HEK293&#39; ],
                                &#39;HEK293T&#39;:          [ &#39;eichorn_2014&#39;, &#39;jan_2014&#39; ],
                                &#39;HFF&#39;:              [ &#39;Primary human foreskin fibroblasts (HFFs)&#39;, 
                                                      &#39;Primary human fibroblast (HFF)&#39;, &#39;rutkowski_2015&#39; ],
                                &#39;HeLa&#39;:             [ &#39;wang_2015&#39;, &#39;niu_2014&#39;, &#39;yoon_2014&#39;, &#39;liu_2013_HeLa&#39;, &#39;stumpf_2013&#39;,
                                                      &#39;park_2016&#39;, &#39;zur_2016&#39;, &#39;shi_2017&#39; ],
                                &#39;hES&#39;:              [ &#39;werner_2015&#39;, &#39;xu_2016&#39; ],
                                &#39;Jurkat&#39;:           [ &#39;gawron_2016&#39; ],
                                &#39;LCL&#39;:              [ &#39;cenik_2015&#39; ],
                                &#39;MCF7&#39;:             [ &#39;Loayza_Puch_2016&#39; ],
                                &#39;MDA-MB-231&#39;:       [ &#39;rubio_2014&#39; ],
                                &#39;MM1S&#39;:             [ &#39;wiita_2013&#39; ],
                                &#39;Monocyte&#39;:         [ &#39;su_2015&#39; ],
                                &#39;NCCIT&#39;:            [ &#39;grow_2015&#39; ],
                                &#39;RPE-1&#39;:            [ &#39;tanenbaum_2015&#39;, &#39;tirosh_2015&#39; ],
                                &#39;Skeletal_muscle&#39;:  [ &#39;wein_2014&#39; ],
                                &#39;THP-1&#39;:            [ &#39;fritsch_2012&#39;, &#39;stern_ginossar_2012&#39; ],
                                &#39;U2OS&#39;:             [ &#39;elkon_2015&#39; ] 
                            }


## ORF ANNOTATE_ORF_PARAMETERS
#  ---------------------------
# This section contains parameter necessary compute the ORF annotations.

[ANNOTATE_ORF_PARAMETERS]

# Length in amino acids up to which an ORF may be considered as short
SHORT_ORF_ANNOTATION_SIZE_THRESHOLD = 100

# The following dictionary allows to associate the ORF categories as
# provided in the data sources to &quot;normalized&quot; categories
# Values associated with &#39;None&#39; will be ignore and no message will 
# be logged by the program for them.
CATEGORY_ASSOCIATION_DICTIONARY = { &#39;None&#39;:             [ &#39;NO_FRAME&#39;, &#39;other&#39;, &#39;ANTISENSE&#39;, &#39;TEC&#39; ], 
                                    &#39;sORF&#39;:             [ &#39;sORF&#39;, &#39;uORF&#39;, &#39;uoORF&#39;, &#39;iORF&#39;, &#39;dORF&#39; ],
                                    &#39;Upstream&#39;:         [ &#39;5UTR&#39;, &#39;5_UTR&#39;, &#39;uoORF&#39;, &#39;uORF&#39;, &#39;utr5&#39; ],
                                    &#39;Overlapping&#39;:      [ &#39;CDS_overlap&#39;, &#39;uoORF&#39; ],
                                    &#39;Exonic&#39;:           [ &#39;EXON&#39;, &#39;exonic&#39; ],
                                    &#39;Intronic&#39;:         [ &#39;INTRON&#39;, &#39;iORF&#39;, &#39;intronic&#39;, &#39;RETAINED_INTRON&#39; ],
                                    &#39;Downstream&#39;:       [ &#39;3UTR&#39;, &#39;3_UTR&#39;, &#39;dORF&#39;, &#39;utr3&#39; ],
                                    &#39;Intergenic&#39;:       [ &#39;INTERGENIC&#39;, &#39;lincRNA&#39;, &#39;lncrna&#39;, &#39;ncRNA&#39;, &#39;pseudogene&#39; ],
                                    &#39;CDS&#39;:              [ &#39;annotated&#39;, &#39;Annotated&#39;, &#39;Isoform&#39; ],
                                    &#39;NMD&#39;:              [ &#39;NMD&#39; ],
                                    &#39;NSD&#39;:              [ &#39;NSD&#39; ],
                                    &#39;Alternative&#39;:      [ &#39;Out&#39;, &#39;alternative_frame&#39; ],
                                  }



# ===============================================================================
# Filter settings
# ===============================================================================

## FILTERING
#  ---------
# This section contains parameters necessary to create a new PRO-like 
# database by filtering the content of an existing PRO database.

[FILTERING]

# Should the program use an union (OR) or an intersection (AND) 
# of the provided filters? 
FILTERING_TYPE = intersection

# Get all ORF that have both short and upstream annotations
ORF_ANNOTATION_FILTER = sORF, Upstream 
</code></pre>
<h1 id="build-new-databases-check-existing-databases-add-a-release-version">Build new databases, check existing databases, add a release version</h1>
<h2 id="build-new-databases-or-check-existing-ones">Build new databases or check existing ones</h2>
<p>The <strong>DatabaseCheck</strong> strategy allows to build new empty DS and PRO databases or to check that existing ones are reachable and contain the expected structures.</p>
<p>If a database does not yet exist, an empty database is built using the appropriate model (tables, primary keys and relationships) and the program insert the name of the species in the (<em>PRO</em>)<em>SpeciesCatalog</em> table.</p>
<p>If a database of the same name exists at the same path (SQLite) or on the same server (MySQL):</p>
<ul>
<li><p>and the <code>--forceOverwrite</code> (<code>-f</code>) option has been selected, then the program first removes the existing database and then creates a new database of this name.</p></li>
<li><p>and the <code>-f</code> option has not been selected, the program ensures the database is reachable and uses the expected model. Then it tries to get the name of the species contained in the <em>SpeciesCatalog</em> table and report it to the user. If the database checked does not follow the expected model (<em>i.e</em> does not have the expected tables, attributes or primary keys), then the program asks the user if it has to overwrite the existing database.</p></li>
</ul>
<p>This strategy may be directly run by the user from the command line but is also automatically run by most of the other strategies prior to perform the expected tasks. When called by the user, the strategy check both the <strong>DS</strong> and <strong>PRO</strong> databases. If the <code>-f</code> option is selected, it will delete and re-built both of them.</p>
<h3 id="databasecheck-command-line">DatabaseCheck command line</h3>
<p>To run the DatabaseCheck strategy, use:</p>
<pre><code>sORFdatafreezer DatabaseCheck -c configFilePath [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-c</code>, <code>--configfile</code>: Absolute path to the config file.</li>
</ul>
<p>The following section and items of the config file are mandatory:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DS_DATABASE_NAME</code> item.</li>
<li><code>PRO_DATABASE_NAME</code> item.</li>
<li><code>DATABASE_SPECIES</code> item.</li>
</ul></li>
</ul>
<p>When using MySQL databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_HOST_IP</code>: The IP of the database host.</li>
<li><code>DATABASE_PORT</code>: The port to use to establish the connection to the database.</li>
<li><code>DATABASE_USER_NAME</code>: The username to use to connect to MySQL server.</li>
<li><code>DATABASE_USER_PASSWD</code>: The password to use to connect to MySQL server.</li>
</ul></li>
</ul>
<p>When using SQLite databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_FOLDER</code>: The folder of the database.</li>
</ul></li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-f</code>, <code>--forceOverwrite</code>: Delete any existing database at the provided path / on the server prior to build a new one.</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
</ul>
<h2 id="add-release-version">Add release version</h2>
<p>The <strong>AddReleaseVersion</strong> strategy allows to tag a database by adding a version tag and description in the metadata table.</p>
<h3 id="addreleaseversion-command-line">AddReleaseVersion command line</h3>
<p>To run the AddReleaseVersion strategy, use:</p>
<pre><code>sORFdatafreezer AddReleaseVersion -N databaseName -M databaseModel -r tag -d description [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-N</code>, <code>--databaseName</code>: The database name.</li>
<li><code>-M</code>, <code>--databaseModel</code>: The schema of the database (PRO / DS).</li>
<li><code>-r</code>, <code>--releaseNumber</code>: The tag of the version.</li>
</ul>
<p>When using MySQL databases, the following options may be used:</p>
<ul>
<li><code>-H</code>, <code>--databaseHost</code>: The IP of the database host.</li>
<li><code>-P</code>, <code>--databasePort</code>: The port to use to establish the connection to the database.</li>
<li><code>-u</code>, <code>--databaseUser</code>: The username to use to connect to MySQL server.</li>
<li><code>-p</code>, <code>--databasePassword</code>: The password to use to connect to MySQL server.</li>
</ul>
<p>When using SQLite databases, the following options may be used:</p>
<ul>
<li><code>-F</code>, <code>--databaseFolder</code>: The folder of the database.</li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-d</code>, <code>--releaseDescription</code>: The description of the version.</li>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-f</code>, <code>--forceOverwrite</code>: Overwrite any existing version tag / description.</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
</ul>
<h1 id="freeze-the-data-sources-in-a-ds-database">Freeze the data sources in a DS database</h1>
<h2 id="insert-data-sources">Insert data sources</h2>
<p>The <strong>Insertion</strong> strategy allows to parse and insert a set of data sources in the database. Running this strategy automatically runs the <strong>DatabaseCheck</strong> strategy.</p>
<h3 id="information-regarding-the-insertion-strategy">Information regarding the Insertion strategy</h3>
<p>The program first parses and inserts data from the gene lists in order to fill in the <em>Gene</em> and <em>GeneAlias</em> tables of the DS database. When this step has been completed, it computes for each unique alias registered in the <em>GeneAlias</em> table the list of gene IDs (as registered in the <em>Gene</em> table) that may be associated to it. The associations are saved as new entries of the <em>UTGeneFromAlias</em> table, allowing to improve the computation time of future steps.</p>
<p>Then, it sequentially parses and insert data from the provided sources in the appropriate order (either the one defined in the config file or in a random order).</p>
<p>If the Insertion strategy is run a second time (without using the <code>-f</code> option) after a modification of the config file, then it skips the parsing and insertion of data that have already been inserted and only insert the new data sources. Be aware that removing a data source of a config file after its insertion will <strong>NOT</strong> delete it from the database and that updating the file of a data source that has already been inserted will <strong>not</strong> update the content of the database.</p>
<p>If a data source has been updated and you want to change the database, then the database must be rebuilt! You must use the <strong>Insertion</strong> strategy with the <code>-f</code> option in such case. Note that the <strong>ForceInsertion</strong> and <strong>Deletion</strong> strategy may be of particular interest in such cases (see the following sections of the current manual related for more information).</p>
<h3 id="insertion-command-line">Insertion command line</h3>
<p>To run the Insertion strategy, use:</p>
<pre><code>sORFdatafreezer Insertion -c configFilePath [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-c</code>, <code>--configfile</code>: Absolute path to the config file.</li>
</ul>
<p>The following section and items of the config file are mandatory:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DS_DATABASE_NAME</code> item.</li>
<li><code>DATABASE_SPECIES</code> item.</li>
</ul></li>
<li><code>[GENE_LISTS]</code> section:
<ul>
<li>Each of the item must have the name of one of a gene list parser and may only appears once in the file.</li>
</ul></li>
<li><code>[DATASOURCE]</code> section:
<ul>
<li>Each of the item must have the name of one of a data source parser and may only appears once in the file.</li>
</ul></li>
</ul>
<p>The following section and items of the config file may be provided:</p>
<ul>
<li><code>[GENE_LIST_ORDER_OF_INSERTION]</code> section:
<ul>
<li><code>GL_INSERTION_ORDER</code> item: A comma-separated list of gene list names to be inserted in a particular order. The list does not necessarily needs to contain all gene lists defined in the <code>[GENE_LISTS]</code> section but <strong>all</strong> gene lists declared in the current item have to be defined in the <code>[GENE_LISTS]</code> section (using the same name).</li>
</ul></li>
<li><code>[DATA_ORDER_OF_INSERTION]</code> section:
<ul>
<li><code>DATA_INSERTION_ORDER</code> item: A comma-separated list of data source to be inserted in a particular order. The list does not necessarily needs to contain all data sources defined in the <code>[DATASOURCE]</code> section but <strong>all</strong> data sources declared in the current item have to be defined in the <code>[DATASOURCE]</code> section (using the same name).</li>
</ul></li>
</ul>
<p>When using MySQL databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_HOST_IP</code>: The IP of the database host.</li>
<li><code>DATABASE_PORT</code>: The port to use to establish the connection to the database.</li>
<li><code>DATABASE_USER_NAME</code>: The username to use to connect to MySQL server.</li>
<li><code>DATABASE_USER_PASSWD</code>: The password to use to connect to MySQL server.</li>
</ul></li>
</ul>
<p>When using SQLite databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_FOLDER</code>: The folder of the database.</li>
</ul></li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-f</code>, <code>--forceOverwrite</code>: Delete any existing database at the provided path / on the server prior to build a new one and to run the insertion.</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
</ul>
<h3 id="description-of-the-rules-of-insertion">Description of the rules of insertion</h3>
<p>The current section of the manual describes more extensively the rules that are used to parse and insert the data. These rules are applied for <strong>all</strong> the data source.</p>
<p><strong>Chromosome names:</strong></p>
<ul>
<li>The chromosome names are always stored in the database without the ‘<strong>chr</strong>’ prefix.</li>
<li>The sexual chromosome are changed to the <code>X|Y</code> value.</li>
<li>Mitochondrial chromosomes are changed to <code>MT</code>.</li>
</ul>
<p><strong>Genomics coordinates:</strong></p>
<p>All the coordinates used in the databases are registered using a “1-based, fully-close” counting system. This means that the first nucleotide on the chromosome is located at the position <code>1</code> and both start and end coordinates describing an ORF (or any other feature) are included in the feature.</p>
<p>When the same attribute is defined in a table (of the DS database) both with and without <code>raw_</code> prefix, the prefix starting with <code>raw_</code> contains the coordinates in the original genome annotation (<em>i.e.</em> as provided by the data source) whilst the attribute without the prefix contains the coordinates after the lift over (see the <strong>Normalization</strong> section of the manual for more information about the lift over). Hence, these last are left empty during the <strong>Insertion</strong> strategy and only computed later when running the <strong>LiftOver</strong> strategy.</p>
<ul>
<li><p>In the <strong>DSORF</strong> table:</p>
<ul>
<li><p>The <strong>strand</strong> attribute corresponds to the ORF strand.</p>
<ul>
<li>The <strong><em>start_pos</em></strong> attribute corresponds:
<ul>
<li>to the genomic coordinates of the first nucleotide of the start codon for the ORFs on the ‘+’ strand.</li>
<li>to the genomic coordinates of the last nucleotide of the stop codon for the ORFs on the ‘-’ strand.</li>
</ul></li>
<li>The <strong><em>stop_pos</em></strong> attribute corresponds:
<ul>
<li>to the genomic coordinates of the last nucleotide of the stop codon for the ORFs on the ‘+’ strand.</li>
<li>to the genomic coordinates of the first nucleotide of the start codon for the ORFs on the ‘-’ strand.</li>
</ul></li>
<li>The <strong><em>splice_starts</em></strong> attributes correspond to an underscore-separated list of the genomic coordinates of the first nucleotide of each “exon” of the ORF, in the actual order of the exons on the RNA, meaning that:
<ul>
<li>the first value is the coordinates of the first nucleotide of the first exon (<em>i.e.</em> of the start codon),</li>
<li>the second the coordinates of the first nucleotide of the 2nd exon,</li>
<li>etc. and this whatever the strand of the ORF is.</li>
</ul></li>
<li>The <strong><em>splice_ends</em></strong> attributes correspond to an underscore-separated list of the genomic coordinates of the last nucleotide of each “exon” of the ORF, in the actual order of the exons on the RNA, meaning that:
<ul>
<li>the first value is the coordinates of the last nucleotide of the 1st exon,</li>
<li>the second value is the coordinates of the last nucleotide of the 2nd exon,</li>
<li>etc., and the last value is the coordinates of the last nucleotide of the last exon (<em>i.e.</em> of the stop codon), and this whatever the strand of the ORF is.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p><strong>Sequences:</strong></p>
<ul>
<li><p>In the <em>DSORFTranscriptAsso</em> table:</p>
<ul>
<li><p>The ORF sequence in nucleotide (<strong>raw_sequence</strong>) includes both the start and the stop codons.</p></li>
<li><p>The ORF sequence in amino acids (<strong>raw_sequence_aa</strong>) includes the start codon but excludes the stop codon.</p></li>
<li><p>The <code>orf_length_nt</code> correspond to the ORF length in nucleotides including both the start and the stop codons.</p></li>
<li><p>The <code>orf_length</code> correspond to the ORF length in amino acids including the start codon but excluding the stop codon.</p></li>
</ul></li>
</ul>
<p><strong>Missing transcript IDs:</strong></p>
<ul>
<li>When the transcript ID is missing, a “fake” transcript ID is created by concatenating the <code>UNKNOWN_TRANSCRIPT_</code> prefix, the name of the source and the row index of the entry.</li>
</ul>
<p><strong>Recovering missing gene symbols, alias and IDs:</strong></p>
<p>When the gene symbol is missing, <code>pyensembl</code> is used to query Ensembl databases and:</p>
<ul>
<li><p>If the transcript ID is provided, then it tries to get the corresponding gene alias,</p></li>
<li><p>Otherwise,</p>
<ul>
<li><p>if the chromosome name is provided and if the ORF strand is provided and:</p>
<ul>
<li><p>there is one single gene overlapping with the ORF coordinates, then the ORF is associated to this gene.</p></li>
<li><p>there are several genes overlapping with the ORF coordinates, then the symbols of these genes are concatenated (or only the first and last symbols of the list if the ORF overlaps with more than two genes) to create a “fake” gene ID with the <code>OVERLAPPING_GENES_</code> prefix.</p></li>
<li><p>there is no gene overlapping with the ORF coordinates, then the program search for lncRNAs overlapping with the ORF coordinates and:</p>
<ul>
<li><p>there is one single lncRNA overlapping with the ORF coordinates, then the alias of the lncRNA is used as gene symbol.</p></li>
<li><p>there are several lncRNAs overlapping with the ORF coordinates, then the aliases of these lncRNAs are concatenated (or only the first and last aliases of the list if the ORF overlaps with more than two lncRNAs) to create a “fake” gene ID with the <code>OVERLAPPING_LNCRNAS_</code> prefix.</p></li>
<li><p>there is no lncRNAs overlapping with the ORF coordinates, then a “fake” gene ID is created concatenating the <code>INTERGENIC_GENE_</code> prefix and the chromosome name.</p></li>
</ul></li>
</ul></li>
<li><p>if the chromosome name is provided but the ORF strand is not provided, then a “fake” gene ID is created concatenating the <code>UNKNOWN_GENE_</code> prefix and the chromosome name.</p></li>
<li><p>if the chromosome name is not provided, then a “fake” gene ID is created using the <code>UNKNOWN_GENE_chr_UNKNOWN</code> alias.</p></li>
</ul></li>
</ul>
<p><strong>Identifying the appropriate gene from a symbol, alias or ID:</strong></p>
<p>For any gene symbol, gene alias or gene ID, the following algorithm is used to identify the appropriate entry in the <em>Gene</em> table:</p>
<p>The program first get the list of all <em>Gene</em> entries that have the provided alias (or gene ID) as one of their alias (using the <em>UTGeneFromAlias</em> table). Then,</p>
<ul>
<li><p>If there is one single <em>Gene</em> entry in the list and:</p>
<ul>
<li><p>if the chromosome name associated to the ORF is known and:</p>
<ul>
<li><p>the chromosome name of the ORF is the same as the chromosome name of the <em>Gene</em> entry, then the ORF is associated to this entry.</p></li>
<li><p>the chromosome name of the ORF is different from the chromosome name of the <em>Gene</em> entry, then the ORF is associated to a newly created “fake” <em>Gene</em> entry with an ID obtained by concatenating the <code>UNKNOWN_GENE_</code> prefix, the alias, and the chromosome name.</p></li>
</ul></li>
<li><p>and the chromosome name associated to the ORF is not provided, then the ORF is associated to this <em>Gene</em> entry.</p></li>
</ul></li>
<li><p>If there are several <em>Gene</em> entries in the list and:</p>
<ul>
<li><p>if there is one single <em>Gene</em> entry on the chromosome associated to the ORF, then the the ORF is associated to this entry.</p></li>
<li><p>if there are several <em>Gene</em> entries on the chromosome associated to the ORF, then the ORF is associated to a newly created “fake” <em>Gene</em> entry with an ID obtained by concatenating the <code>UNKNOWN_GENE_</code> prefix, the alias, and the chromosome name.</p></li>
<li><p>if there is no <em>Gene</em> entry on the chromosome associated to the ORF and:</p>
<ul>
<li>the chromosome associated to the ORF is known and there are <em>Gene</em> entries missing their chromosome name and:
<ul>
<li>there is one single <em>Gene</em> entry missing its chromosome information, then this last is updated and the ORF is associated to the <em>Gene</em> entry.</li>
<li>there are several <em>Gene</em> entries missing their chromosome information, then the ORF is associated to a newly created “fake” <em>Gene</em> entry with an ID obtained by concatenating the <code>UNKNOWN_GENE_</code> prefix, the alias, and the chromosome name.</li>
</ul></li>
<li>the chromosome associated to the ORF is not known or if there is no <em>Gene</em> entries of the list missing their chromosome information, then the ORF is associated to a newly created “fake” <em>Gene</em> entry with an ID obtained by concatenating the <code>UNKNOWN_GENE_</code> prefix, the alias, and the chromosome name.</li>
</ul></li>
</ul></li>
<li><p>Otherwise, if there is no <em>Gene</em> entry in the list, a new entry is created in the <em>Gene</em> table using the alias and chromosome information associated to the ORF in the data source.</p></li>
</ul>
<h3 id="dealing-with-conflicting-information-about-orf-properties">Dealing with conflicting information about ORF properties</h3>
<p>Any conflicting information found during the insertion of data is logged at the warning or error level in the main log files.</p>
<p>Sometimes, a provided transcript ID may be found associated to several <em>Gene</em> entries during the insertion of data. This may happen for instance when a line of a source file being parsed provides both the gene symbol and transcripts ID related to the ORF whilst an other line of the same source provides only the transcript ID related to an other ORF. In such cases, the second line may associate the transcript to an other <em>Gene</em> entry if the alias returned when querying the Ensembl databases associated with the provided transcript ID is not an alias registered in the database. Then the same <em>Transcript</em> entry should theoritically be associated with two different <em>Gene</em> entries. Nevertheless, as a transcript is actually expected to be related to one single gene and in order to respect the referential integrity, the program logs an error message and creates a new <em>Gene</em> entry using the prefix <code>CONFLICT_GENE_</code> for the <code>gene_id</code> attribute. To avoid reporting several times the same conflicts, all the association of the transcript ID with the list of related gene ids are saved in the <code>UTDSTranscriptGeneConflict</code> table.</p>
<h2 id="resume-an-insertion-that-failed">Resume an insertion that failed</h2>
<p>When the <strong>Insertion</strong> strategy is run, at the end of the parsing of each gene list and source and prior the insertion of data in the DS database, a file is automatically generated in order to store all the entries created during the parsing (the objects are serialized and saved in hidden files). The <strong>ForceInsertion</strong> strategy may be useful when the parsing happened correctly but a problem was encountered during the insertion into the database, as it allows to try again the insertion of data using the files previously generated. Obviously, the <strong>ForceInsertion</strong> strategy must <strong>never</strong> be run prior to the <strong>Insertion</strong> strategy and it is <strong>absolutely necessary</strong> to make sure the parsing happened successfully prior to run it (check the main log file to ensure the parsing was successful).</p>
<h3 id="information-regarding-the-forceinsertion-strategy">Information regarding the ForceInsertion strategy</h3>
<p>The <strong>ForceInsertion</strong> strategy first loads the data from the file corresponding to the data source and try again the insertion into the DS database. Hence, running this strategy may be useful to save the time of the parsing, but be aware that trying to force the insertion of data may raise several problems or silently introduce errors in the database.</p>
<p>In particular:</p>
<ul>
<li><p>If you try to insert the sources in a different order that the one in which they were initially treated. Explanation: In such cases, the program may for instance create a new entry of the <em>Gene</em> table during the parsing of a first source, which will then be used by a second source; then trying to insert them in the reverse order will report a non-respect of the database integrity (SQL duplicate exception will be raised).</p></li>
<li><p>If a first source (<em>e.g. source1</em>) is parsed successfully but its insertion fails, and then a second source (<em>e.g. source2</em>) is parsed <em>and</em> inserted successfully, trying to build a new empty DS database and to insert the two sources (in the same order) using the ForceInsertion strategy may cause new problems. Explanation: the program may for example create a new entry (<em>e.g.</em> in the <em>Gene</em> table) during the parsing of the first source (<em>source1</em>), which were then not available during the parsing of the second source (<em>source2</em>) and then trying to create a new entry with the same primary-key but different non-primary-key attributes, raising an exception due to duplicates in the primary keys.</p></li>
</ul>
<p>Hence, in order to avoid these problems, when the insertion of data from a source failed whilst running the <strong>Insertion</strong> strategy, we highly recommend to:</p>
<ul>
<li><p>First, erase the existing database and rebuilt a new one, using the <strong>DatabaseCheck</strong> strategy <strong>with the</strong> <code>--f</code> <strong>option</strong>,</p></li>
<li><p>Then, insert again all the gene list and data sources <strong>properly parsed prior the first insertion fail</strong> and in <strong>the same order as the one in which they were initially inserted</strong> (either the one provided in the config file or the one generated by the program - in any case this order is logged in the main log file) using the <strong>ForceInsertion</strong> strategy. You need there to add the <code>UTGeneFromAlias</code> as first value of the list of data sources to re-insert, <em>i.e.</em> after the last list of genes and prior the first data source.</p></li>
<li><p>Finally, run again the Insertion strategy to perform (a new time) the parsing and insertion of sources that had to be inserted after the first source for which the insertion failed, using the same config file.</p></li>
</ul>
<p>We also highly recommend to provide an order of insertion in the config file (see <strong>Config file</strong> section of the current manual) putting the largest data source first, even if this is not mandatory.</p>
<h3 id="forceinsertion-command-line">ForceInsertion command line</h3>
<p>To run the ForceInsertion strategy, use:</p>
<pre><code>sORFdatafreezer ForceInsertion -N databaseName -s sourceNames [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-N</code>, <code>--databaseName</code>: The database name.</li>
<li><code>-s</code>, <code>--source</code>: A comma-separated list of the data source to insert in the database (without space), in the order in which they need to be inserted. You must use <code>UTGeneFromAlias</code> as a source name to re-insert data computed after the insertion of the last gene list and prior to the first data source name if you are re-inserting both gene lists and data sources.</li>
</ul>
<p>When using MySQL databases, the following options may be used:</p>
<ul>
<li><code>-H</code>, <code>--databaseHost</code>: The IP of the database host.</li>
<li><code>-P</code>, <code>--databasePort</code>: The port to use to establish the connection to the database.</li>
<li><code>-u</code>, <code>--databaseUser</code>: The username to use to connect to MySQL server.</li>
<li><code>-p</code>, <code>--databasePassword</code>: The password to use to connect to MySQL server.</li>
</ul>
<p>When using SQLite databases, the following options may be used:</p>
<ul>
<li><code>-F</code>, <code>--databaseFolder</code>: The folder of the database.</li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
</ul>
<h2 id="remove-data-sources">Remove data sources</h2>
<p>The <strong>Deletion</strong> strategy allows to delete from a database a source that has been previously parsed and inserted using the <strong>Insertion</strong> strategy.</p>
<h3 id="information-regarding-the-deletion-strategy">Information regarding the Deletion strategy</h3>
<p>The <strong>Deletion</strong> strategy allows to remove data related to a particular data source from the database. It removes all the information related to the source in the <em>DataSource</em>, <em>DSORF</em>, <em>DSTranscript</em> and <em>DSORFTranscriptAsso</em> tables. Nevertheless, be aware that any <em>Gene</em> (and subsequent <em>GeneAlias</em>) entry generated during the insertion of the data source will not be removed.</p>
<p>Several data sources to remove may be provided as a comma-separated list (without any space between each data source name). The program report the number of entries expected to be deleted and ask the user to confirm the deletion prior to perform it.</p>
<p>You should <strong>never</strong> delete a data source with this strategy and insert it again using the <strong>ForceInsertion</strong> strategy as entries related to this source but persisting (<em>i.e.</em> <em>Gene</em> or <em>GeneAlias</em> entries) may have been updated, which could raise problems related to primary-key duplicates. Hence, if a source that has been deleted needs to be inserted again, we strongly advice to use the <strong>Insertion</strong> strategy.</p>
<h3 id="deletion-command-line">Deletion command line</h3>
<p>To run the Deletion strategy, use:</p>
<pre><code>sORFdatafreezer Deletion -N databaseName -s sourceNames [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-N</code>, <code>--databaseName</code>: The database name.</li>
<li><code>-s</code>, <code>--source</code>: A comma-separated list of the data source to delete from the database (without space).</li>
</ul>
<p>When using MySQL databases, the following options may be used:</p>
<ul>
<li><code>-H</code>, <code>--databaseHost</code>: The IP of the database host.</li>
<li><code>-P</code>, <code>--databasePort</code>: The port to use to establish the connection to the database.</li>
<li><code>-u</code>, <code>--databaseUser</code>: The username to use to connect to MySQL server.</li>
<li><code>-p</code>, <code>--databasePassword</code>: The password to use to connect to MySQL server.</li>
</ul>
<p>When using SQLite databases, the following options may be used:</p>
<ul>
<li><code>-F</code>, <code>--databaseFolder</code>: The folder of the database.</li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
</ul>
<h1 id="normalize-data">Normalize data</h1>
<h2 id="convert-the-genomic-coordinates-lift-over">Convert the genomic coordinates (lift over)</h2>
<p>The <strong>LiftOver</strong> strategy allows to convert all the genomic coordinates contained in the entries of the DS database from their original genome annotation version (the one of the data source) to the current one (GRCh38 or GRCm38).</p>
<h3 id="information-regarding-the-liftover-strategy">Information regarding the LiftOver strategy</h3>
<p>To perform the lift over of the genomic coordinates, the program uses the <code>PyLiftOver</code> package and chain files downloaded from UCSC.</p>
<p>Note that the original values (as provided by the data sources) are stored in the DS database under the attributes starting with the <code>raw_</code> prefix whilst the corresponding attributes not starting with this prefix contain the converted coordinates (<em>e.g</em> the <code>raw_start_pos</code> attribute of a DSORF entry contains the start position of this ORF as it is provided by the source, whilst the <code>start_pos</code> attribute contains the start position of this ORF after the lift over).</p>
<p>The program updates the following coordinates:</p>
<p><strong>DSORF table:</strong></p>
<ul>
<li><p>The strand, start position, stop position and splicing positions (starts and ends of exons) of the all the entries are lifted over.</p></li>
<li><p>At the end of the process, the cumulative genomic length (<em>i.e.</em> the total length of the exons in nucleotides) is computed for each ORF using the coordinates in the original annotation and using the lift overed coordinates for each ORF for which the conversion succeed. These values are respectively stored in the <code>raw_genomic_length</code> and <code>genomic_length</code> attributes of the <em>DSORF</em> table. The difference between these two length is computed too and store under the <code>genomic_length_diff</code> attribute. Hence, this value may be used to ensure the right conversion of all coordinates for an ORF and is used as filtering criteria by the <strong>Merge</strong> strategy.</p></li>
</ul>
<p><strong>DSTranscript table:</strong></p>
<ul>
<li>The strand, start position, end position, CDS start and CDS stop positions of all the entries are lifted over.</li>
</ul>
<h3 id="liftover-command-line">LiftOver command line</h3>
<p>To run the LiftOver strategy, use:</p>
<pre><code>sORFdatafreezer LiftOver -c ConfigFilePath [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-c</code>, <code>--configfile</code>: Absolute path to the config file.</li>
</ul>
<p>The following section and items of the config file are mandatory:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DS_DATABASE_NAME</code> item.</li>
<li><code>DATABASE_SPECIES</code> item.</li>
</ul></li>
</ul>
<p>When using MySQL databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_HOST_IP</code>: The IP of the database host.</li>
<li><code>DATABASE_PORT</code>: The port to use to establish the connection to the database.</li>
<li><code>DATABASE_USER_NAME</code>: The username to use to connect to MySQL server.</li>
<li><code>DATABASE_USER_PASSWD</code>: The password to use to connect to MySQL server.</li>
</ul></li>
</ul>
<p>When using SQLite databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_FOLDER</code>: The folder of the database.</li>
</ul></li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
</ul>
<h3 id="description-of-the-rules-of-lift-over">Description of the rules of lift over</h3>
<p>The current section of the manual describes more extensively the rules that are used to lift over the genomic coordinates.</p>
<p><strong>DSORF table:</strong></p>
<ul>
<li><p>If the lift over returns a different chromosome after conversion, then a critical message is logged and the program is interrupted.</p></li>
<li><p>If the strand information after conversion:</p>
<ul>
<li><p>of the start <strong>and</strong> stop positions are both missing (<em>i.e.</em> the conversion failed for both of them), then the conversion is stopped and there are no new attributes registered.</p></li>
<li><p>of the start <strong>or</strong> of the stop positions is missing, but the other one is available (<em>i.e.</em> the conversion succeeded for only one of them), then it is check if the strand after conversion is the same as prior. If the strand changed, then the start and stop coordinates are reversed.</p></li>
<li><p>of the start and of the stop positions are provided (<em>i.e.</em> the conversion succeeded for both of them), then:</p>
<ul>
<li><p>if the strands of the start and stop positions are the same and did not changed after conversion (<em>i.e.</em> same as the raw strand), then the new positions are registered.</p></li>
<li><p>if the strands of the start and stop positions are the same but changed after conversion (<em>i.e.</em> opposite of the raw strand), then the start and stop coordinates are reversed.</p></li>
<li><p>if the strands of the start and stop positions are different, then the conversion is stopped, an error is logged and none of the new attribute values is registered.</p></li>
</ul></li>
</ul></li>
<li><p>For <code>splice_starts</code> and <code>splice_stops</code> attributes, if the conversion fails for one of the splicing coordinates (impossible conversion or strand that is different after conversion compared to the “raw” strand), then the conversion is stopped and the none of the new attribute is registered.</p></li>
</ul>
<p><strong>DSTranscript table:</strong></p>
<ul>
<li><p>The chromosome of the transcript is get from the information of the gene related to this transcript.</p></li>
<li><p>If the lift over returns a different chromosome after conversion, then a critical message is logged and the program is interrupted.</p></li>
<li><p>If the strand information after conversion:</p>
<ul>
<li><p>of the start <strong>and</strong> end positions are both missing (<em>i.e.</em> the conversion failed for both of them), then the conversion is stopped and there are no new attribute registered.</p></li>
<li><p>of the start <strong>or</strong> of the end positions is missing, but the other one is available (<em>i.e.</em> the conversion succeeded for only one of them), then it is check if the strand after conversion is the same as prior. If the strand changed, then the start and end coordinates are reversed.</p></li>
<li><p>of the start and of the end positions are provided (<em>i.e.</em> the conversion succeeded for both of them), then:</p>
<ul>
<li><p>if the strands of the start and end positions are the same and did not changed after conversion (<em>i.e.</em> same as the raw strand), then the new positions are registered.</p></li>
<li><p>if the strands of the start and end positions are the same but changed after conversion (<em>i.e.</em> opposite of the raw strand), then the start and end coordinates are reversed.</p></li>
<li><p>if the strands of the start and end positions are different, then the conversion is stopped, an error is logged and none of the new attribute values is registered.</p></li>
</ul></li>
</ul></li>
<li><p>For <code>cds_start_pos</code> and <code>cds_stop_pos</code> attributes, if the strand after conversion is different from the one of the transcript, then the conversion of this attribute is stopped and it is not registered. Otherwise, the attribute is saved and the start and stop coordinates are reversed if the strand changed during the conversion.</p></li>
</ul>
<p>For all entries of <em>DSORF</em> and <em>DSTranscript</em> tables, if the data source was already using the current genome annotation, then the attributes are just copied as no conversion needs to be performed.</p>
<h1 id="merge-redundant-data-into-unique-entries">Merge redundant data into unique entries</h1>
<h2 id="create-the-pro-database-from-a-ds-database">Create the PRO database from a DS database</h2>
<p>The <strong>Merge</strong> strategy allows to merge the redundant information into single entries by creating a new PRO database from an existing DS database. In other words a given ORF and a given transcript are registered only once in the PRO database, whilst several entries may be actually describing the same ORF or the same Transcript in the DS database due to the redundancy of some information between the data sources. The relationships between PRO and DS databases are registered in the PRO database.</p>
<p><strong>Caution</strong>: This strategy needs the <strong>LiftOver</strong> strategy to have been run successfully to be used.</p>
<h3 id="information-regarding-the-merge-strategy">Information regarding the Merge strategy</h3>
<p>An empty PRO database is first build and the merging the consists of 6 successive important steps: - the copy of conserved information - the merging of the ORF entries - the merging of the Transcript entries - the resolution of the associations between the ORFs and the Transcripts - the merging of the ORF-Transcript associations - a final step to clean the database</p>
<p>These steps are described more extensively below.</p>
<h4 id="copying-conserved-information">Copying conserved information</h4>
<p>All the metadata contained in the DS database are copied as is in the PRO database. This includes at least the genome version and the species scientific short name.</p>
<p>All the information related to the genes and their alias (symbol / alias / IDs) are copied in the PRO database.</p>
<h4 id="merging-the-orfs">Merging the ORFs</h4>
<p>Two entries of the <em>DSORF</em> table are considered as actually describing the same ORF when all the following conditions are met:</p>
<ul>
<li>they are located on the same chromosome</li>
<li>they are located on the same strand</li>
<li>they have the same start position</li>
<li>they have the same stop position</li>
<li>they have the same number of exons</li>
<li>their exons have the same starts and ends</li>
</ul>
<p>All the coordinates here are absolute genomics coordinates in the current annotation version (<em>i.e.</em> after lift over).</p>
<p>When the <code>GENOMIC_LENGTH_DIFF_THRESHOLD</code> item is set in the config file, all the DSORF entries that have a <code>genomic_length_diff</code> equal or over the provided value are discarded of the list of ORFs to look for when performing the merging (see the section about the <strong>LiftOver</strong> strategy for more information about this attribute). If this parameter is set to <code>-1</code>, then this option will be ignored (<code>0</code> by default).</p>
<p>The merging of the ORFs is solved in three successive steps.</p>
<p><strong>First</strong> all the ORFs:</p>
<ul>
<li><p>that share the same chromosome, strand, start and stop positions, number of exons and start and end position of all exons,</p></li>
<li><p><strong>and</strong> for which <strong>all</strong> of these attributes are known,</p></li>
</ul>
<p>are merged together.</p>
<p>As all the information required to properly characterize an ORF are known, this merging is considered <strong>unambiguous</strong>.</p>
<p><strong>Then</strong> all the remaining ORFs:</p>
<ul>
<li><p>that share the same chromosome, strand, start and stop positions, number of exons and start and end position of all exons,</p></li>
<li><p><strong>and</strong> for which the chromosome, the strand and the start position are known <strong>and</strong></p>
<ul>
<li>that are unspliced <strong>or</strong></li>
<li>that are spliced but for which the start and/or stop positions of the exons are missing,</li>
</ul></li>
</ul>
<p>are compared with the ORFs previously merged and added to the PRO database:</p>
<ul>
<li><p>If one of the entry of the PRO database matches with the current ORFs, then they are merged with it,</p></li>
<li><p>Otherwise, if there is not any entry of the PRO database matching with the current ORFs, then they are merged together and a new entry is created in the PRO database.</p></li>
</ul>
<p>As the ambiguity is solely related to the coordinates of the exons and all the most important properties to characterize an ORF are known, this merging is considered <strong>unambiguous</strong>.</p>
<p><strong>Finally</strong> all the remaining ORFs:</p>
<ul>
<li><p>that share the same chromosome, strand, start and stop positions, number of exons and start and end position of all exons,</p></li>
<li><p><strong>and</strong> for which the chromosome is known <strong>and</strong></p>
<ul>
<li>for which the strand is unknown and the start position is unknown,</li>
<li><strong>or</strong> for which the strand is unknown and the stop position is unknown,</li>
<li><strong>or</strong> for which both the start and stop positions are unknown</li>
</ul></li>
<li><p><strong>and</strong> on which there is no constraint regarding the splicing information (number and coordinates of exons may eventually be missing)</p></li>
</ul>
<p>are compared with the ORFs previously merged and added to the PRO database:</p>
<ul>
<li><p>If one of the entry of the PRO database matches with the current ORFs, then they are merged with it,</p></li>
<li><p>Otherwise, if there is not any entry of the PRO database matching with the current ORFs, then they are discarded from the PRO database as there are missing at least one of the important information necessary to characterize properly the ORF.</p></li>
</ul>
<p>As there are some important information missing for these ORFs, this merging is considered <strong>ambiguous</strong>. Note that due to this ambiguity, a same DSORF entry could actually be merged with different ORF entries in the PRO database.</p>
<p><strong>NB</strong>: - The eventual entries of the DS database not previously described (<em>e.g.</em> missing both their strand, start and stop positions) are actually missing too many crucial information to be considered for the merging. Hence these are not used to create the PRO database. - The <code>count_ds</code> and <code>count_ds_ambiguous</code> attributes of a <em>ORF</em> entry respectively inform the number of DSORF entries merged in an unambiguous and in an ambiguous way. - The <em>ORFDSAsso</em> table records for each entry of the <em>ORF</em> table the IDs of the <em>DSORF</em> table that have been merged together to create it.</p>
<h4 id="merging-the-transcripts">Merging the transcripts</h4>
<p>Two entries of the <em>DSTranscript</em> table are considered as actually describing the same transcript when all the following conditions are met:</p>
<ul>
<li>they have the same “official” ID (such as Ensembl ID)</li>
<li>they are related to the same gene</li>
</ul>
<p>The merging of the transcripts is solved in two successive steps:</p>
<p><strong>First</strong> all the transcripts that have a gene ID which is not a “fake” transcript (<em>i.e.</em> which ID is not <code>UNKNOWN_TRANSCRIPT</code> and does not start by this prefix) are merged together. This merging is considered <strong>unambiguous</strong>.</p>
<p><strong>Then</strong> all the remaining transcripts (<em>i.e.</em> the ones with a “fake” transcript ID) that are related to the same gene and share the same strand, start position, position and CDS start and end positions are compared with the transcripts previously merged and added to the PRO database:</p>
<ul>
<li><p>If one of the entry of the PRO database matches with the current transcripts, then they are merged with it,</p></li>
<li><p>Otherwise, if there is not any entry of the PRO database matching with the current transcripts, then they are merged together and a new entry is created in the PRO database. This merging is considered <strong>ambiguous</strong>.</p></li>
</ul>
<p><strong>NB:</strong> - We decided not to use the genomics coordinates as all of the data sources currently used do not provide the transcript coordinates. - The <code>count_ds</code> and <code>count_ds_ambiguous</code> attributes of a <em>Transcript</em> entry respectively inform the number of DSTranscript entries merged in an unambiguous and in an ambiguous way. - The <em>TranscriptDSAsso</em> table records for each entry of the <em>Transcript</em> table the IDs of the <em>DSTranscript</em> table that have been merged together to create it.</p>
<h4 id="finding-out-which-dsorftranscriptasso-entries-to-merge">Finding out which DSORFTranscriptAsso entries to merge</h4>
<p>At this stage of the merging, the similar ORFs have been merged and inserted in the PRO database and the similar transcripts have been merged and inserted in the PRO database too. Hence each “biological feature” (ORF, transcript or gene) is recorded one unique and single time in the PRO database, whatever the number of time it has been described by the original data sources.</p>
<p>Nevertheless, the relationship between the ORFs and the transcripts has not yet been recorded in the PRO database at this stage. In particular, it has to be noticed that an ORF can be located on several transcripts whilst a transcript can obviously harbor several ORFs. In the DS database, this level of information is recorder in the <em>DSORFTranscriptAsso</em> table. Thus, the information from this table needs to be summarized and registered in the PRO database.</p>
<p>The following steps are performed:</p>
<ol type="1">
<li><p>First, for each entry of the <em>DSORFTranscriptAsso</em> table, the ID of the unique <em>DSORF</em> entry and the ID of the unique <em>DSTranscript</em> ID related to it are get.</p></li>
<li><p>Then, knowing that a <em>DSORF</em> entry may have been either totally discarded from the PRO database, or used one single time during the merging (unambiguous merging) or used several times during the merging (ambiguous merging), the list of the <em>ORF</em> entrie(s) that derives from this <em>DSORF</em> entry are get.</p></li>
<li><p>Similarly to the previous step, knowing that a <em>DSTranscript</em> entry may have been either totally discarded from the PRO database, or used one single time during the merging (unambiguous merging) or used several times during the merging (ambiguous merging), the list of the <em>Transcript</em> entrie(s) that derives from this <em>DSTranscript</em> entry are get.</p></li>
<li><p>Thus, at this stage we are able to associate to each <em>DSORFTranscriptAsso</em> ID the list of <em>ORF</em> and <em>Transcript</em> entries that may be related to it. The cartesian product, define as the list of all ( <em>ORF</em> ID, <em>Transcript</em> ID ) that may exist, is computed from these list.</p></li>
<li><p>Using the result of the previous steps for <strong>all</strong> <em>DSORFTranscriptAsso</em> entries, we associate to each unique ( <em>ORF</em> ID, <em>Transcript</em> ID ) the list of <em>DSORFTranscriptAsso</em> IDs that register their interaction.</p></li>
<li><p>All the <em>DSORFTranscriptAsso</em> of the same list are merged together (see next main step of the algorithm).</p></li>
</ol>
<p><em>Example</em></p>
<p>For more clarity about this algorithm, here is an example. We assume that: - The <em>DSORFTranscriptAsso</em> with ID <code>DSOTA_1</code> is related to the <em>DSORF</em> entry with ID <code>DSORF_2</code> and with the <em>DSTranscript</em> entry with ID <code>DSTranscript_3</code>. - The <em>DSORFTranscriptAsso</em> with ID <code>DSOTA_4</code> is related to the <em>DSORF</em> entry with ID <code>DSORF_5</code> and with the <em>DSTranscript</em> entry with ID <code>DSTr_6</code>. - The <em>DSORF</em> with ID <code>DSTranscript_6</code> and the <em>DSORF</em> with ID <code>DSORF_5</code> have been merged together and the <em>ORF</em> entry with ID <code>ORF_7</code>derives from them. - The <em>DSTranscript</em> with ID <code>DSTranscript_3</code> and the <em>DSTranscript</em> with ID <code>DSTranscript_6</code> have been merged together and the <em>Transcript</em> entry with ID <code>Transcript_8</code> derives from it.</p>
<pre><code># NB: The following lines of codes are written in pseudo-language for more clarity

# Loop over the DSORFTranscriptAsso entries
for dsorftranscriptasso_id in ( DSOTA_1, DSOTA_2 ):
    
    # --------------- Let&#39;s see what happen when dsorftranscriptasso_id equals DSOTA_1
    # 1. Get the ID of the unique DSORF entry related to it and 
    #    the ID of the unique DSTranscript entry related to it
    dsorf_id = DSORF_2
    dstranscript_id = DSTranscript_3
    
    # 2. Get the list of ORF IDs that derives from this DSORF
    orf_ids = [ ORF_7 ]
    
    # 3. Get the list of Transcript IDs that derives from this DSTranscript
    transcript_ids = [ Transcript_8 ]
    
    # 4. Compute the cartesian product of ORF IDs and Transcript IDs
    cartesian_prod = orf_ids x transcript_ids
    cartesian_prod = [ ORF_7 ] x [ Transcript_8 ]
    cartesian_prod = [ (ORF_7, Transcript_8) ]
    
    # We keep the result of this algorithm in memory
    
    
    # Restart the previous algorithm with the next DSORFTranscriptAsso ID
    
    
    # --------------- Let&#39;s see what happen when dsorftranscriptasso_id equals DSOTA_4
    # 1bis. Get the ID of the unique DSORF entry related to it and 
    #    the ID of the unique DSTranscript entry related to it
    dsorf_id = DSORF_5
    dstranscript_id = DSTranscript_6
    
    # 2bis. Get the list of ORF IDs that derives from this DSORF
    orf_ids = [ ORF_7 ]
    
    # 3bis. Get the list of Transcript IDs that derives from this DSTranscript
    transcript_ids = [ Transcript_8 ]
    
    # 4bis. Compute the cartesian product of ORF IDs and Transcript IDs
    cartesian_prod = orf_ids x transcript_ids
    cartesian_prod = [ ORF_7 ] x [ Transcript_8 ]
    cartesian_prod = [ (ORF_7, Transcript_8) ]
    
    # We keep the result of this algorithm in memory
    
    
# 5. We collect the information from the for loop to associate to each unique (ORF ID, Transcript ID) the list of DSORFTranscriptAsso IDs that register their interaction.
(ORF_7, Transcript_7) : [ DSOTA_1, DSOTA_4 ]

# Hence, at the end of this process, we know that the DSORFTranscriptAsso with IDs 1 and 4 needs to be merged together to create a new entry in the ORFTranscriptAsso table that will register the relationship between the ORF entry with ID ORF_7 and the Transcript entry with ID Transcript_8 (see next section for more information about this merging)    </code></pre>
<h4 id="merge-the-dsorftranscriptasso">Merge the DSORFTranscriptAsso</h4>
<p>Once the <em>DSORFTranscriptAsso</em> to merge together have been identified (see previous section), it is then necessary to merge them.</p>
<p>When the <code>--checkDSOTA</code> option has been selected, the consistency of the information registered <strong>in a single</strong> <em>DSORFTranscriptAsso</em> entry is assessed. This optional step will check the following attributes:</p>
<ul>
<li>The agreement between the nucleic and amino acid sequences.</li>
<li>The agreement between the provided nucleic sequence and length.</li>
<li>The agreement between the provided amino acid sequence and length.</li>
<li>The agreement between the nucleic and amino acid lengths.</li>
</ul>
<p>And any inconsistent information will be removed from the entry and the operation will be logged in the main log file. Be aware that selecting this option could be highly time-consuming; thus we advice not to use it with the six original data sources when you cannot use more than 20 threads.</p>
<p>If there is one single entry in the list of <em>DSORFTranscriptAsso</em> entries to merge, then the algorithm just basically copy the information registered in it in a new <em>ORFTranscriptAsso</em> entry.</p>
<p>Otherwise, when there are several <em>DSORFTranscriptAsso</em> entries to merge together, the following steps are performed:</p>
<ul>
<li><p>The identification methods (bioinformatics prediction, Ribo-seq, MS) that detected the ORF - Transcript relationship is summarized (set to <code>True</code> if detected at least once with the method).</p></li>
<li><p>If the <code>--computeConsensus</code> option has been selected, a consensus of the amino acid and nucleic sequences is computed (aligning the sequences with MUSCLE and computing the consensus with the <code>Bio.Align</code> methods of the <code>BioPython</code> package). If it is not selected then the sequence is replaced by an integer representing the number of sequences that would have been available to compute the consensus. The <code>SEQUENCE_CONSENSUS_AMBIGUOUS_THRESHOLD</code> item may be provided as a float in the database and will be used to compute the consensus. For each position in the sequence, if the percentage of the most common residue is greater than the threshold, then this residue will be considered as being the consensus for the position (see the documentation of the <a href="http://biopython.org/DIST/docs/api/Bio.Align.AlignInfo.SummaryInfo-class.html#gap_consensus"><code>threshold</code> parameter in the <code>gap_consensus()</code> function of <code>Bio.Align</code> module</a> for more information). Be aware that selecting this option could be highly time-consuming; thus we advice not to use it with the six original data sources when you cannot use more than 20 threads.</p></li>
<li><p>A consensus of the start codon sequence is computed.</p></li>
<li><p>The Kozak context information is summarized. If the Kozak context has been reported by at least one of the data sources, then it is registered as existing. Be aware that this is an information that is computed using the information extracted from the data sources; an other Kozak context may be computed later using our own algorithm (see the <strong>Complete the missing information and compute new information</strong> section of the current manual).</p></li>
<li><p>A summary of the lengths and various scores (PhyloCSF, ORF score, PhastCons, FLOSS) is made by getting the minial and maximal values, by computing the median and by registering the list of values.</p></li>
<li><p>“Clusters” of <em>DSORFTranscriptAsso</em> entries are identified. Due to the high complexity of the algorithm previously described to merge the ORF, the transcripts and then identify the <em>DSORFTranscriptAsso</em> that need to be merge together, it may sometimes happen that <em>DSORFTranscriptAsso</em> entries that are actually not describing the same ORF - Transcript relationship are merged together. Hence, it is important to have a way to identify these cases and get a confidence about the quality of the merging. As the length is one of the most important feature available to characterize an ORF, we decided to establish “clusters” or <em>DSORFTranscriptAsso</em> entries based on their length. Briefly, <em>DSORFTranscriptAsso</em> entries that have a difference in their ORF length that exceeds the <code>MAX_LEN_DIFF_FOR_DSOTA_CLUSTERS</code> value (in amino acids, that may be defined in the config file) will belong to two different clusters. For instance if this value is set to <code>3</code>, then as soon as the difference between two lengths equal or exceeds <code>4</code> amino acids, then they will belong to different clusters. As a consequence, a number of clusters equal to <code>1</code> suggests that the selection of <em>DSORFTranscriptAsso</em> entries to be merged together was probably relevant. On a contrary, a high value may suggest that the merging was probably irrelevant; and we should be worried by a large amount of <em>ORFTranscript</em> entries for which the number of cluster computed does not equals <code>1</code>. The number of computed cluster and their composition are registered in the <em>ORFTranscriptAsso</em> attribute. As this computation is exclusively based on the length in amino acids, the number of lengths used to performed this computation is registered too. Indeed, with this algorithm clusters of <em>DSORFTranscriptAsso</em> entries missing their ORF length value cannot be computed, and in such cases they are considered as belonging to the same cluster.</p></li>
<li><p>All the cell contexts in which the ORF has been reported on the transcript are recorded and registered in the <em>CellContext</em> table.</p></li>
<li><p>All the ORF categories for the ORF on the transcript as provided by the data sources are recorded and registered in the <em>ProvidedCategory</em> table. Be aware that this is an information that is computed using the information extracted from the data sources; other ORF categories may be computed later using our own algorithm (see the <strong>Complete the missing information and compute new information</strong> section of the current manual).</p></li>
<li><p>Finally, all the FLOSS classes reported by the data sources are recorded in the <em>FlossClass</em> table of the PRO database.</p></li>
</ul>
<h4 id="clean-the-pro-database">Clean the PRO database</h4>
<p>Finally the database is clean by removing:</p>
<ul>
<li>all the <em>ORF</em> entries for which no <em>ORFTranscriptAsso</em> may have been computed,</li>
<li>all the <em>Transcript</em> entries for which no <em>ORFTranscriptAsso</em> may have been computed.</li>
</ul>
<p>Be aware that none of the gene (or their symbol / alias / IDs) will be removed; as it may be useful to know that an ID / alias / symbol is known by the database and there are just no ORF on it. Indeed this case is different from the case where a gene harbor ORFs but one of its alias or ID is missing from the cross-references.</p>
<h3 id="merge-command-line">Merge command line</h3>
<p>To run the Merge strategy, use:</p>
<pre><code>sORFdatafreezer Merge -c ConfigFilePath [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-c</code>, <code>--configfile</code>: Absolute path to the config file.</li>
</ul>
<p>The following section and items of the config file are mandatory:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DS_DATABASE_NAME</code> item.</li>
<li><code>PRO_DATABASE_NAME</code> item.</li>
<li><code>DATABASE_SPECIES</code> item.</li>
</ul></li>
</ul>
<p>The following section and items of the config file may be provided:</p>
<ul>
<li><code>[MERGE_PARAMETERS]</code> section:
<ul>
<li><code>GENOMIC_LENGTH_DIFF_THRESHOLD</code> item: Threshold for absolute difference in genomic length. The genomic length (defined as the cumulative sum of an ORF exons) is computed for each entry of the ORF table prior and after the lift over (<em>i.e.</em> the conversion of genomic coordinates from an annotation version to the current one) and their absolute difference is calculated. This item allow to exclude all the entries that have a difference larger or equal to the provided threshold. Setting the threshold to <code>-1</code> allow to ignore this option.</li>
<li><code>SEQUENCE_CONSENSUS_AMBIGUOUS_THRESHOLD</code> item: Threshold to use to include a nucleotide or an amino acid in a sequence consensus.</li>
<li><code>MAX_LEN_DIFF_FOR_DSOTA_CLUSTERS</code> item: Maximum difference between the lengths of two ORF to belong to the same cluster when merging the DSORFTranscriptAsso entries (in amino acids). When setting this parameter to 3, two DSORFTranscriptAsso will be considered as being part of two different “clusters” if the difference of their length equals or exceeds 4.</li>
</ul></li>
</ul>
<p>When using MySQL databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_HOST_IP</code>: The IP of the database host.</li>
<li><code>DATABASE_PORT</code>: The port to use to establish the connection to the database.</li>
<li><code>DATABASE_USER_NAME</code>: The username to use to connect to MySQL server.</li>
<li><code>DATABASE_USER_PASSWD</code>: The password to use to connect to MySQL server.</li>
</ul></li>
</ul>
<p>When using SQLite databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_FOLDER</code>: The folder of the database.</li>
</ul></li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-f</code>, <code>--forceOverwrite</code>: Delete any existing PRO database at the provided path / on the server prior to build a new one. The DS database will not be affected.</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-t</code>, <code>--threads</code>: Number of threads available. If not provided the program try to use all the threads available on the computer.</li>
<li><code>-d</code>, <code>--checkDSOTA</code>: Should the content of the DSORFTranscriptAsso table need to be check prior to run the strategy? Be aware that selecting this option may be highly time-consuming. We advice to provide as many threads as possible when using this option.</li>
<li><code>-s</code>, <code>--computeConsensus</code>: Should a consensus of the DSORFTranscriptAsso sequences be computed? Be aware that selecting this option may be highly time-consuming. We advice to provide as many threads as possible when using this option.</li>
</ul>
<h2 id="resume-a-merging-that-failed">Resume a merging that failed</h2>
<p>Related to its high complexity, the <strong>Merge</strong> strategy is a highly resources-consuming and time-consuming strategy. For some reasons independent from the source code, the merging may failed (<em>e.g.</em> the computer run out of memory, connection with the MySQL server has been lost…). Hopefully, this is possible to resume the merging from where it failed using the <strong>ResumeMerge</strong> strategy.</p>
<h3 id="information-regarding-the-resumemerge-strategy">Information regarding the ResumeMerge strategy</h3>
<p>To use this strategy, you need first to identify the step that failed (consulting the main log file) as it will be necessary to provide this information to the program.</p>
<p>Here are some hints to <strong>identify the step that failed</strong>:</p>
<ul>
<li><p>Using the log file, if the last log at the <strong>INFO</strong> level is:</p>
<ul>
<li><p><code>Copying the entries of the gene-related and metadata-related tables into the PRO database.</code>, then the merging failed during the copy of conserved information (step 1).</p></li>
<li><p>one of the following: <code>Starting to merge the entries of the DSORF table.</code>, <code>Starting to regroup the perfectly identical entries of the DSORF table (DS database) into new ORF entries (PRO database).</code>, <code>Starting to regroup the identical entries of the DSORF table (DS database) into new ORF entries (PRO database).</code>, <code>Starting to regroup the similar entries of the DSORF table (DS database) into existing ORF entries (PRO database).</code>, then the merging failed during the merging of the ORFs (step 2).</p></li>
<li><p>one of the following: <code>Starting to merge the entries of the DSTranscript table.</code>, <code>Starting to regroup the entries of the DSTranscript table (DS database) with the same official ID into new Transcript entries (PRO database).</code>, then the merging failed during the merging of the transcripts (step 3).</p></li>
<li><p><code>Starting to merge the entries of the DSORFTranscriptAsso table.</code> or a log regarding the save of (ORF, Transcript) associations in csv files, then the merging failed during the resolution of the associations between the ORFs and the transcripts (or whilst saving these information in files in the output folder) (step 4).</p></li>
<li><p><code>Starting to merge the DSORFTranscriptAsso entries for all existing ( ORF ID, Transcript ID ) couples.</code>, then the merging failed during the merging of ORF-Transcript associations (step 5).</p></li>
<li><p><code>Starting to clean the PRO database.</code>, then the merging failed trying to clean the database (step 6)</p></li>
</ul></li>
<li><p>Consulting the database (with adminer, phpMyAdmin or SQLite browser for instance):</p>
<ul>
<li><p>If the <em>PROSpeciesCatalog</em> or the <em>PROGene</em> or the <em>PROGeneAlias</em> table is empty, then the merging failed during the copy of conserved information (step 1).</p></li>
<li><p>If the <em>ORF</em> or the <em>Transcript</em> table is empty, then the merging failed during the merging of the ORFs (step 2) or during the merging of the transcripts (step 3). <strong>Caution</strong>: existing entries in the <em>ORF</em> table does not necessarily mean that the ORF merging was completed successfully!</p></li>
<li><p>If the <em>Transcript</em> or the <em>ORFTranscriptAsso</em> is empty, then the merging failed during the merging of the transcripts (step 3) or during the merging of the ORF-Transcript associations (step 4 or 5). <strong>Caution</strong>: existing entries in the <em>Transcript</em> table does not necessarily mean that the transcript merging was completed successfully!</p></li>
<li><p>If the <em>ORFTranscriptAsso</em> is empty, then the merging failed during the resolution of the associations between the ORFs and the transcripts (or whilst saving these information in files in the output folder) (step 4) or during the merging of ORF-Transcript associations (step 5). <strong>Caution</strong>: existing entries in the <em>ORFTranscriptAsso</em> table does not necessarily mean that the ORF-transcript associations merging was completed successfully!</p></li>
<li><p>If entries of the <em>ORF</em> or of the <em>Transcript</em> have not any child in the <em>ORFTranscriptAsso</em> table, then the merging failed during the resolution of the associations between the ORFs and the transcripts (or whilst saving these information in files in the output folder) (step 4) or during the merging of ORF-Transcript associations (step 5) or trying to clean the database (step 6).</p></li>
</ul></li>
</ul>
<p>Always prefer to use the log to identify this information, except if you set the verbosity at an inappropriate level to clearly identify the last step that run successfully (<em>e.g.</em> log set at <code>critical</code> level).</p>
<p>When this step is identified, the <strong>ResumeMerge</strong> strategy may be started using the <code>--resumeAtStep</code> option. This option takes one of the following values:</p>
<ul>
<li><p><code>after_conserved</code>: to restart <strong>after</strong> the copy of conserved information. Use this when the last step successfully performed was the step 1.</p></li>
<li><p><code>after_orf</code>: to restart <strong>after</strong> the merging of the ORF entries. Use this when the last step successfully performed was the step 2.</p></li>
<li><p><code>after_transcript</code>: to restart <strong>after</strong> the merging of the Transcript entries. Use this when the last step successfully performed was the step 3.</p></li>
<li><p><code>after_ota_id_asso</code>: to restart <strong>after</strong> the resolution of the associations between the ORFs and the transcripts. Use this when the last step successfully performed was the step 4.</p></li>
<li><p><code>during_ota</code>: to restart <strong>during</strong> the merging of the <em>DSORFTranscriptAsso</em> entries. <code>after_ota_id_asso</code> will restart this step from the principle whilst <code>during_ota</code> will first identify the merging that have been performed successfully and restart this step from where it failed. Use this when the last step successfully performed was the step 4.</p></li>
<li><p><code>after_ota</code>: to restart <strong>after</strong> the merging of the <em>DSORFTranscriptAsso</em> entries. Use this when the last step successfully performed was the step 5.</p></li>
</ul>
<p>Be aware that these strategy can only work successfully if you did <strong>not</strong> alter neither any of the hidden (<code>.dcorf</code>) files nor the DS nor the PRO database! For more information about any of these steps, read the documentation of the <strong>Merge</strong> strategy.</p>
<h3 id="troubleshooting">Troubleshooting</h3>
<p>If the program run out of memory, it will be halted and raise errors such as <code>OSError: [Errno 12] Cannot allocate memory</code>. When it happen, this issue is usually met during the computation of the <em>ORFTranscriptAsso</em> entries (step 5) and may be fixed by reducing the amount of entries managed at the same time. In fact, the program is taking advantage of multi-processing for this step, which could require high amounts of memory. You can try to fix the error by reducing the amount of entries handled at the same time by lowering the value of the <code>MAX_POOL_SIZE</code> variable in the <code>fr.tagc.uorf.core.utils.Constants</code> module. This should slightly reduce the efficiency of the computation but may allow to fix the issue.</p>
<h3 id="resumemerge-command-line">ResumeMerge command line</h3>
<p>To run the ResumeMerge strategy, use:</p>
<pre><code>sORFdatafreezer ResumeMerge -c ConfigFilePath -a stepName [OPTIONS]</code></pre>
<p>Options and config sections / items that may be provided to the <strong>Merge</strong> strategy may be provided to the <strong>ResumeMerge</strong> too (expected for the <code>-f</code> option).</p>
<p>The following options are mandatory:</p>
<ul>
<li><code>-c</code>, <code>--configfile</code>: Absolute path to the config file.</li>
<li><code>-a</code>, <code>--resumeAtStep</code>: The name of the step at which the merging should be resumed.</li>
</ul>
<p>The following section and items of the config file are mandatory:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DS_DATABASE_NAME</code> item.</li>
<li><code>PRO_DATABASE_NAME</code> item.</li>
<li><code>DATABASE_SPECIES</code> item.</li>
</ul></li>
</ul>
<p>The following section and items of the config file may be provided:</p>
<ul>
<li><code>[MERGE_PARAMETERS]</code> section:
<ul>
<li><code>GENOMIC_LENGTH_DIFF_THRESHOLD</code> item: Threshold for absolute difference in genomic length. The genomic length (defined as the cumulative sum of an ORF exons) is computed for each entry of the ORF table prior and after the lift over (<em>i.e.</em> the conversion of genomic coordinates from an annotation version to the current one) and their absolute difference is calculated. This item allow to exclude all the entries that have a difference larger or equal to the provided threshold (<code>1</code> by default). Setting the threshold to <code>-1</code> allow to ignore this option.</li>
<li><code>SEQUENCE_CONSENSUS_AMBIGUOUS_THRESHOLD</code> item: Threshold to use to include a nucleotide or an amino acid in a sequence consensus.</li>
<li><code>MAX_LEN_DIFF_FOR_DSOTA_CLUSTERS</code> item: Maximum difference between the lengths of two ORF to belong to the same cluster when merging the DSORFTranscriptAsso entries (in amino acids). When setting this parameter to 3, two DSORFTranscriptAsso will be considered as being part of two different “clusters” if the difference of their length equals or exceeds 4.</li>
</ul></li>
</ul>
<p>When using MySQL databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_HOST_IP</code>: The IP of the database host.</li>
<li><code>DATABASE_PORT</code>: The port to use to establish the connection to the database.</li>
<li><code>DATABASE_USER_NAME</code>: The username to use to connect to MySQL server.</li>
<li><code>DATABASE_USER_PASSWD</code>: The password to use to connect to MySQL server.</li>
</ul></li>
</ul>
<p>When using SQLite databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_FOLDER</code>: The folder of the database.</li>
</ul></li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-f</code>, <code>--forceOverwrite</code>: Delete any existing database at the provided path / on the server prior to build a new one.</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-t</code>, <code>--threads</code>: Number of threads available. If not provided the program try to use all the threads available on the computer.</li>
<li><code>-d</code>, <code>--checkDSOTA</code>: Should the content of the DSORFTranscriptAsso table need to be check prior to run the strategy? Be aware that selecting this option may be highly time-consuming. We advice to provide as many threads as possible when using this option.</li>
<li><code>-s</code>, <code>--computeConsensus</code>: Should a consensus of the DSORFTranscriptAsso sequences be computed? Be aware that selecting this option may be highly time-consuming. We advice to provide as many threads as possible when using this option.</li>
</ul>
<h1 id="complete-the-missing-information-normalize-data-and-compute-new-information">Complete the missing information, normalize data and compute new information</h1>
<h2 id="download-missing-information-and-normalize-cell-contexts">Download missing information and normalize cell contexts</h2>
<p>Once the PRO database has been created with the <strong>Merge</strong> strategy, there are still some information that could be normalized as well as some data that are missing and could be recovered using external databases (Ensembl). The <strong>ComputeMissingInfo</strong> strategy aims to perform these operations.</p>
<p><strong>Caution</strong>: This strategy needs the <strong>Merge</strong> strategy to have been run successfully to be used.</p>
<h3 id="information-regarding-the-computemissinginfo-strategy">Information regarding the ComputeMissingInfo strategy</h3>
<p>First the <strong>computeMissingInfo</strong> strategy will compare for each <em>ORFTranscriptAsso</em> entry its genomic length (<code>length_nt_min</code>, <code>length_nt_max</code>) with the genomic length registered in the related <em>ORF</em> entry (<code>orf_genomic_length</code> attribute, see the documentation about the <strong>LiftOver</strong> strategy for more information). If the values of the <code>length_nt_min</code> and <code>length_nt_max</code> attributes are different, then the <code>gen_len_eq_orf_len</code> attribute of the <em>ORFTranscriptAsso</em> entry is set to False. Otherwise, their value is compared to the genomic length of the <em>ORF</em> entry and if they are equal, the <code>gen_len_eq_orf_len</code> attribute takes the <code>True</code> value.</p>
<p>Then, the names of the cell contexts are normalized. At this stage, the cell contexts are using the name provided by the data sources. Hence an actual same context can be registered under several names in the database (<em>e.g.</em> both <code>Primary human fibroblast (HFF)</code>, <code>HFF</code> and <code>rutkowski_2015</code> refers to primary human fibroblasts). To do so, the program uses a dictionary that associates to each new name to use for a cellular context the list of names used by the data sources. A custom dictionary may be provided in the config file with the <code>CELL_CONTEXTS_DICTIONARY</code> item, using a Python-like syntax. Be aware that the old cell type names will be erased, so this is no longer possible to give different names to cell contexts that have already been merged together by previously running the current strategy.</p>
<p>When the <code>--downloadMissingInfo</code> option has been selected, the strategy will try to download missing information. This step uses both the <code>PyEnsembl</code> package and the Ensembl REST API to download the information. The following information are recorded:</p>
<ul>
<li>For the <em>ORF</em> entries:
<ul>
<li>The nucleic sequences are downloaded (using the Ensembl REST API). For the ORFs which are spliced, only the sequences of the exons are downloaded. The stop codon is included in the sequence. This information is registered under the <code>sequence</code> attribute.</li>
<li>The amino acid sequences are computed by <em>in silico</em> translation of the DNA sequence previously downloaded (with the <code>Bio.Seq</code> module of the <code>BioPython</code> package). This information is registered under the <code>sequence_aa</code> attribute.</li>
</ul></li>
<li>For the <em>Transcript</em> entries:
<ul>
<li>When the transcript has an official ID (not starting with <code>UNKNOWN</code>), the strategy try to get its name, strand, absolute start and end genomic coordinates, absolute CDS start and stop genomic coordinates (for protein coding transcripts), its RNA biotype and its full sequence (including 3’ and 5’ UTRs) (using the <code>PyEnsembl</code> package).</li>
<li>If there are entries missing their sequence, then it try to download it with the Ensembl REST API using the start and stop genomics coordinates if they are provided.</li>
</ul></li>
</ul>
<p>Finally, a list of all RNA biotypes existing in the database is computed and recorded in the <code>UTRNABiotypeCatalog</code> table.</p>
<p>NB: - For the steps that use the Ensembl REST API, if an HTTP request fails due to an error that is not related to the data itself (<em>e.g.</em> server unreachable, connection lost…), then the attempt to download the sequence is repeated until success.</p>
<h3 id="computemissinginfo-command-line">computeMissingInfo command line</h3>
<p>To run the computeMissingInfo strategy, use:</p>
<pre><code>sORFdatafreezer computeMissingInfo -c ConfigFilePath [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-c</code>, <code>--configfile</code>: Absolute path to the config file.</li>
</ul>
<p>The following section and items of the config file are mandatory:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>PRO_DATABASE_NAME</code> item.</li>
<li><code>DATABASE_SPECIES</code> item.</li>
</ul></li>
</ul>
<p>The following section and item of the config file may be provided:</p>
<ul>
<li><code>[COMPUTE_MISSING_INFO_PARAMETERS]</code> section:
<ul>
<li><code>CELL_CONTEXTS_DICTIONARY</code> item: The dictionary that inform how the cell contexts have to be renamed and / or merged. This dictionary must be provided using a Python-like syntax.</li>
</ul></li>
</ul>
<p>When using MySQL databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_HOST_IP</code>: The IP of the database host.</li>
<li><code>DATABASE_PORT</code>: The port to use to establish the connection to the database.</li>
<li><code>DATABASE_USER_NAME</code>: The username to use to connect to MySQL server.</li>
<li><code>DATABASE_USER_PASSWD</code>: The password to use to connect to MySQL server.</li>
</ul></li>
</ul>
<p>When using SQLite databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_FOLDER</code>: The folder of the database.</li>
</ul></li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-f</code>, <code>--forceOverwrite</code>: Enforce the computation of all steps, including the ones that already succeed. When this option is not selected, the strategy will resume from where it failed.</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-d</code>, <code>--downloadMissingInfo</code>: Download the missing information (such as ORF and Transcript sequences) from external databases. Note that selecting this option may be highly time-consuming.</li>
</ul>
<h3 id="resume-a-computemissinginfo-that-failed">Resume a ComputeMissingInfo that failed</h3>
<p>To resume a <strong>ComputeMissingInfo</strong> strategy that failed, just restart the strategy using the same command line as previously used. Make sure to do <strong>not</strong> select the <code>-f</code> option, as this would restart the strategy from the beginning!</p>
<h3 id="troubleshooting-1">Troubleshooting</h3>
<p>When the <code>--downloadMissingInfo</code> option has been selected, the <strong>ComputeMissingInfo</strong> may be susceptible to log a lot of error messages reporting bad request status to Ensembl databases. This may happen when:</p>
<ul>
<li>Your connection to the Internet is unstable.</li>
<li>Other processes or users are using the Ensembl REST API at the same time on your network. This is susceptible to happen if you try to start the ComputeMissingInfo strategy at the same time on different databases.</li>
<li>Ensembl servers are under maintenance or encoutering issues.</li>
</ul>
<h2 id="computing-the-relative-coordinates">Computing the relative coordinates</h2>
<p>So far, all coordinates registered in the database are absolute genomic coordinates. The <strong>ComputeRelCoord</strong> strategy allows to compute the relative coordinates for the entries related to a <strong>transcript having an official ID</strong>.</p>
<h3 id="information-regarding-the-computerelcoord-strategy">Information regarding the ComputeRelCoord strategy</h3>
<p>This strategy uses the R <code>annotation_hub</code> and <code>ensembldb</code> libraries to perform this operation. The computation of relative coordinates takes obviously into account the phenomena of (alternative) splicing when occurring.</p>
<p>The following coordinates are converted:</p>
<ul>
<li><p>Transcript CDS start and stop coordinates: For transcripts with an official ID and that harbor a CDS (coding transcripts), the relative start and stop of the CDS are computed and registered under the <code>rel_cds_start_pos</code> and <code>rel_cds_stop_pos</code> attributes of the <em>Transcript</em> table.</p></li>
<li><p>ORF start and stop coordinates: For the ORFs that are located on one (or several) identified transcript(s) and for which the official ID(s) is known, the relative start and stop coordinates are computed <strong>for each transcript</strong> (as the position is relative to the start of the transcript) are thus registered under the <code>rel_start_pos</code> and <code>rel_stop_pos</code> attributes of the <em>ORFTranscriptAsso</em> table.</p></li>
</ul>
<h3 id="computerelcoord-command-line">ComputeRelCoord command line</h3>
<p>To run the ComputeRelCoord strategy, use:</p>
<pre><code>sORFdatafreezer ComputeRelCoord -c ConfigFilePath [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-c</code>, <code>--configfile</code>: Absolute path to the config file.</li>
<li><code>-N</code>, <code>--databaseName</code>: The database name.</li>
<li><code>-M</code>, <code>--databaseModel</code>: The schema of the database (PRO / DS).</li>
</ul>
<p>The following section and items of the config file are mandatory:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>PRO_DATABASE_NAME</code> item.</li>
<li><code>DATABASE_SPECIES</code> item.</li>
</ul></li>
</ul>
<p>When using MySQL databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_HOST_IP</code>: The IP of the database host.</li>
<li><code>DATABASE_PORT</code>: The port to use to establish the connection to the database.</li>
<li><code>DATABASE_USER_NAME</code>: The username to use to connect to MySQL server.</li>
<li><code>DATABASE_USER_PASSWD</code>: The password to use to connect to MySQL server.</li>
</ul></li>
</ul>
<p>When using SQLite databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_FOLDER</code>: The folder of the database.</li>
</ul></li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-f</code>, <code>--forceOverwrite</code>: Compute again any existing relative coordinates.</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-t</code>, <code>--threads</code>: Number of threads available. If not provided the program try to use all the threads available on the computer.</li>
</ul>
<h3 id="resume-a-computerelcoord-that-failed">Resume a ComputeRelCoord that failed</h3>
<p>To resume a <strong>ComputeRelCoord</strong> strategy that failed, just restart the strategy using the same command line as previously used. Make sure to do <strong>not</strong> select the <code>-f</code> option, as this would restart the strategy from the beginning!</p>
<h3 id="troubleshooting-2">Troubleshooting</h3>
<p>If the program run out of memory, it will be halted and raise errors such as <code>OSError: [Errno 12] Cannot allocate memory</code>. This issue may be fixed by reducing the amount of coordinates converted at the same time. In fact, the program is taking advantage of multi-processing for this step, which could require high amounts of memory. You can try to fix the error by reducing the amount of subprocess handled in the same pool by lowering the value of the <code>MAX_POOL_SIZE</code> variable in the <code>fr.tagc.uorf.core.utils.Constants</code> module and / or by reducing the number of entries handled at the same time by a process by lowering the value of the <code>MAX_ENTRIES_PER_DATAFRAME</code> variable in the <code>fr.tagc.uorf.core.utils.Constants</code> module. This may reduce the efficiency of the computation but could help fixing the issue.</p>
<h2 id="get-the-start-flanking-sequence-and-information-regarding-the-kozak-context">Get the start flanking sequence and information regarding the Kozak context</h2>
<p>As described earlier, the <code>kozak_context</code> attribute of the <em>ORFTranscriptAsso</em> table records information regarding the Kozak context (as a boolean) from the data sources. Nevertheless most of the data sources are missing this information and the criteria used to define a Kozak context are not necessarily the same.</p>
<p>Hence, the <strong>ComputeKozakContext</strong> strategy allows to get the sequences flanking the start codon of the ORFs and to provide new levels of information about the Kozak context.</p>
<p><strong>Caution</strong>: This strategy needs the <strong>ComputeRelCoord</strong> strategy to have been run successfully to be used.</p>
<h3 id="information-regarding-the-computekozakcontext-strategy">Information regarding the ComputeKozakContext strategy</h3>
<p>First, for each ORF that is related to one (or several) transcript(s) which has(ve) an official ID, and for which the computation of the relative start coordinates has succeed, the sequence flanking the start codon is computed. This sequence includes the -6 to +4 nucleotides, the first nucleotide of the start codon being at the +1 position.</p>
<p><em>e.g.</em> An <strong>ATG</strong> start codon could have the flanking sequence: GCCACC<strong>ATG</strong>G.</p>
<p>This strategy is able to define four kinds of Kozak contexts, based on <a href="http://10.1016/j.tibs.2019.07.001">Hernandez et al., Trends in Biochemical Sciences, 2019 (doi: 10.1016/j.tibs.2019.07.001)</a>. The following regular expression are used to find out the type of Kozak context:</p>
<ul>
<li>Optimal: <code>GCC[AG]CC.{3}G</code></li>
<li>Strong: <code>.{3}[AG].{2}.{3}G</code></li>
<li>Moderate: <code>(.{3}[AG].{2}.{3}[ATC]|.{3}[CT].{2}.{3}G)</code></li>
<li>Weak: <code>.{3}[CT].{2}.{3}[ACT]</code></li>
</ul>
<h3 id="computekozakcontext-command-line">ComputeKozakContext command line</h3>
<p>To run the ComputeKozakContext strategy, use:</p>
<pre><code>sORFdatafreezer ComputeKozakContext -c ConfigFilePath [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-c</code>, <code>--configfile</code>: Absolute path to the config file.</li>
</ul>
<p>The following section and items of the config file are mandatory:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>PRO_DATABASE_NAME</code> item.</li>
<li><code>DATABASE_SPECIES</code> item.</li>
</ul></li>
</ul>
<p>When using MySQL databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_HOST_IP</code>: The IP of the database host.</li>
<li><code>DATABASE_PORT</code>: The port to use to establish the connection to the database.</li>
<li><code>DATABASE_USER_NAME</code>: The username to use to connect to MySQL server.</li>
<li><code>DATABASE_USER_PASSWD</code>: The password to use to connect to MySQL server.</li>
</ul></li>
</ul>
<p>When using SQLite databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_FOLDER</code>: The folder of the database.</li>
</ul></li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-f</code>, <code>--forceOverwrite</code>: Should all Kozak contexts be computed again?</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
</ul>
<h3 id="resume-a-computekozakcontext-that-failed">Resume a ComputeKozakContext that failed</h3>
<p>To resume a <strong>ComputeKozakContext</strong> strategy that failed, just restart the strategy using the same command line as previously used. Make sure to do <strong>not</strong> select the <code>-f</code> option, as this would restart the strategy from the beginning!</p>
<h2 id="normalize-the-orf-categories-compute-new-orf-annotations">Normalize the ORF categories, compute new ORF annotations</h2>
<p>As in the section dedicated to the <strong>Merge</strong> strategy, the ORF categories provided by the data sources are registered in the <em>ProvidedCategory</em> table. Nevertheless, like for the cellular contexts, several names could have been used to define a particular category (<em>e.g.</em> both <code>5'UTR</code> and <code>upstream</code> may be describing upstream ORFs).</p>
<p>The <strong>AnnotateORF</strong> strategy allows to normalize this information by: - Normalizing the vocabulary to describe the ORFs. - Computing new ORF categories with normalized definitions</p>
<p><strong>Caution</strong>: This strategy needs the <strong>ComputeMissingInfo</strong> strategy to have been run successfully to be used.</p>
<h3 id="information-regarding-the-annotateorf-strategy">Information regarding the AnnotateORF strategy</h3>
<p>When the <code>--computeCatFromSource</code> option is selected, the names of the provided categories are normalized. The method is similar to the one used for the cellular contexts in the <strong>ComputeMissingInfo</strong> strategy. To do so, the program uses a dictionary that associates to each new name to use for a category the list of names used by the data sources. A custom dictionary may be provided in the config file with the <code>CATEGORY_ASSOCIATION_DICTIONARY</code> item, using a Python-like syntax. Contrary to the cell types, the old category names will be kept in the database. Hence if you update the dictionary and restart the strategy it will still be possible to redefine the categories as if it has not yet been performed. These information are stored in the <em>ORFCategory</em> table.</p>
<p>When the <code>--computeAnnot</code> option is selected the ORFs categories are computed from scratch (<em>i.e.</em> provided categories are not used for this computation) and the information are registered in the <em>ORFAnnotation</em> table.</p>
<p>This annotation is performed in sevel successive steps based on these 5 criteria:</p>
<ul>
<li><p>The <strong>length</strong> of the ORFs. ORFs which size in amino acids is lower of equal to the size defined in the config file using the <code>SHORT_ORF_ANNOTATION_SIZE_THRESHOLD</code> item will be annotated as short (<code>sORF</code>).</p></li>
<li><p>The <strong>strand</strong> of the ORF compared to the one of the transcript. When the ORF is located on the opposite strand than its transcripts, it is annotated <code>Opposite</code>.</p></li>
<li><p>The <strong>reading frame</strong> of the ORF. When the ORF reading frame is not the same than the one of the CDS, it is annotated <code>Alternative</code>.</p></li>
<li><p>The <strong>biotype</strong> of the transcript. The following ORF annotations are defined according to the type of their transcript:</p>
<ul>
<li><p>ORFs located on <code>Non sense mediated decay</code>, <code>NMD</code>, <code>nonsense_mediated_decay</code> or <code>non_stop_decay</code> biotypes are annotated <code>NMD</code>.</p></li>
<li><p>ORFs located on <code>Pseudogene</code>, <code>IG pseudogene</code>, <code>Polymorphic pseudogene</code>, <code>Processed pseudogene</code>, <code>processed_pseudogene</code>, <code>Transcribed pseudogene</code>, <code>transcribed_processed_pseudogene</code>, <code>transcribed_unprocessed_pseudogene</code>, <code>unprocessed_pseudogene</code>, <code>transcribed_unitary_pseudogene</code>, <code>Translated pseudogene</code>, <code>Unitary pseudogene</code>, <code>unitary_pseudogene</code> or <code>Unprocessed pseudogene</code> biotypes are annotated <code>Pseudogene</code>.</p></li>
<li><p>ORFs located on <code>3' overlapping ncRNA</code> biotypes are annotated <code>Downstream</code>.</p></li>
<li><p>ORFs located on <code>Readthrough</code> or <code>Stop codon readthrough</code> biotypes are annotated <code>Readthrough</code>.</p></li>
<li><p>ORFs located on <code>Long intergenic ncRNA</code> or <code>lincRNA</code> biotypes are annotated <code>Intergenic</code>.</p></li>
<li><p>ORFs located on <code>Non coding</code>, <code>ncRNA</code>, <code>Processed transcript</code>, <code>processed_transcript</code>, <code>Long non-coding RNA</code>, <code>lncRNA</code>, <code>3' overlapping ncRNA</code>, <code>Macro lncRNA</code>, <code>Long intergenic ncRNA</code>, <code>lincRNA</code>, <code>miRNA</code>, <code>miscRNA</code>, <code>piRNA</code>, <code>rRNA</code>, <code>siRNA</code>, <code>snRNA</code>, <code>snoRNA</code>, <code>tRNA</code> or <code>vaultRNA</code> biotypes are annotated <code>ncRNA</code>.</p></li>
<li><p>ORFs located on <code>retained_intron</code>, <code>sense_intronic</code>, <code>sense_overlapping</code> biotypes are annotated <code>Intronic</code>.</p></li>
<li><p>ORFs located on <code>Antisense</code>, <code>antisense</code> biotypes are annotated <code>Overlapping</code>.</p></li>
</ul></li>
<li><p>The <strong>relative position</strong> of the ORF compared with the CDS (main coding sequence) of the transcript looking at the absolute genomic coordinates. The following ORF annotations are defined according to this relative position:</p>
<ul>
<li><p>If the ORF start codon is located upstream of the CDS start codon, and the ORF stop codon is located upstream of the CDS stop codon, then the ORFs is annotated <code>Upstream</code>.</p></li>
<li><p>If the ORF start codon is located downstream of the CDS start codon, and stop codon is located downstream of the CDS stop codon, then the ORF is annotated <code>Downstream</code>.</p></li>
<li><p>If the ORF start codon is located upstream of the CDS start codon, and the ORF stop codon is located upstream of the CDS stop codon and within the CDS, then the ORF is annotated <code>Overlapping</code>.</p></li>
<li><p>If the ORF start codon is located within the CDS, and stop codon is located downstream of the CDS stop codon, then the ORF is annotated <code>Overlapping</code>.</p></li>
<li><p>If the ORF start codon is located upstream of the CDS start codon and the ORF stop codon is located at the CDS stop codon, then the ORF is the annotated <code>InCDS</code>.</p></li>
<li><p>If the ORF start codon is located at the CDS start codon and the ORF stop codon is located at the CDS stop codon, then the ORF is the annotated <code>CDS</code>.</p></li>
<li><p>If the ORF start codon is located upstream of the CDS start codon, and the ORF stop codon is located downstream of the CDS stop codon, then the ORF is annotated <code>NewCDS</code>.</p></li>
</ul></li>
</ul>
<h3 id="annotateorf-command-line">AnnotateORF command line</h3>
<p>To run the AnnotateORF strategy, use:</p>
<pre><code>sORFdatafreezer AnnotateORF -c ConfigFilePath -a -s [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-c</code>, <code>--configfile</code>: Absolute path to the config file.</li>
</ul>
<p>The following section and item of the config file may be provided:</p>
<ul>
<li><code>[ANNOTATE_ORF_PARAMETERS]</code> section:
<ul>
<li><code>CATEGORY_ASSOCIATION_DICTIONARY</code> item: The dictionary that inform how the provided categories have to be renamed and / or merged. This dictionary must be provided using a Python-like syntax.</li>
<li><code>SHORT_ORF_ANNOTATION_SIZE_THRESHOLD</code> item: The maximal size for an ORF to be annotated as short (in amino acids, <em>e.g.</em> if set to <code>100</code>, then all ORF with a length shortest or equal to 100 amino acids will be annotated as short).</li>
</ul></li>
</ul>
<p>The following section and items of the config file are mandatory:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>PRO_DATABASE_NAME</code> item.</li>
<li><code>DATABASE_SPECIES</code> item.</li>
</ul></li>
</ul>
<p>When using MySQL databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_HOST_IP</code>: The IP of the database host.</li>
<li><code>DATABASE_PORT</code>: The port to use to establish the connection to the database.</li>
<li><code>DATABASE_USER_NAME</code>: The username to use to connect to MySQL server.</li>
<li><code>DATABASE_USER_PASSWD</code>: The password to use to connect to MySQL server.</li>
</ul></li>
</ul>
<p>When using SQLite databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_FOLDER</code>: The folder of the database.</li>
</ul></li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-f</code>, <code>--forceOverwrite</code>: Delete all the entries of the ORFCategory and ORFCategoryCatalog and/or of the ORFAnnotation and ORFAnnotationCatalog tables (PRO database, depending on the other options selected) prior to run the strategy.</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-s</code>, <code>--computeCatFromSource</code>: Compute the ORF categories from the categories provided by the datasource (ORFCatagory table).</li>
<li><code>-a</code>, <code>--computeAnnot</code>: Annotate ORFs using our own algorithm based on length, biotype, strand and relative position (ORFAnnotation table).</li>
</ul>
<h3 id="resume-a-annotateorf-that-failed">Resume a AnnotateORF that failed</h3>
<p>To resume a <strong>AnnotateORF</strong> strategy that failed, just restart the strategy using the same command line as previously used. Make sure to do <strong>not</strong> select the <code>-f</code> option, as this would restart the strategy from the beginning!</p>
<h1 id="filter-in-the-database-content-and-create-a-new-database">Filter in the database content and create a new database</h1>
<p>Once the PRO database has been created and completed with previously described strategies, it may sometimes be useful to filter the content of the database using one or several filters. This can obviously be achieved by querying directly the database. Nevertheless, it may be of interest for some users to be able to extract a “subset” of the full data contained in the database to restrict its content to the data related to a list gene or an ORF annotation for instance. The <strong>Filter</strong> strategy aims to help doing this.</p>
<p><strong>Caution</strong>: This strategy may need the the <strong>ComputeMissingInfo</strong> and/or the <strong>AnnotateORF</strong> strategies to have been run successfully to be used (depending on the filters required).</p>
<h3 id="information-regarding-the-filter-strategy">Information regarding the Filter strategy</h3>
<p>The data can be filtered using either:</p>
<ul>
<li>A list of genes (<code>GENE_LIST_FILTER</code> item of the config file): A path to a csv file has to be provided. The list could be either located on a line or a column (this will be detected automatically), but the file must not have several columns and several lines at the same time.</li>
<li>A list of cellular contexts (<code>CELL_CONTEXT_FILTER</code> item of the config file): A comma-separated list.</li>
<li>A list of ORF categories (<code>ORF_CATEGORY_FILTER</code> item of the config file): A comma-separated list.</li>
<li>A list of ORF annotations (<code>ORF_ANNOTATION_FILTER</code> item of the config file): A comma-separated list.</li>
</ul>
<p><strong>Caution</strong>: The strategy currently allows only <strong>one single type</strong> of filter, so this is not possible to provide a list of genes and ORF annotations at the same time for instance. If you need to do so, we advice to first use the <strong>Filter</strong> strategy with one of the filter in order to create an intermediate database and then to use again the <strong>Filter</strong> strategy on this intermediate database with the second filter. The order in which the filters are provided does not matter.</p>
<p>You need then to provide a type of filtering in the config file with the <code>FILTERING_TYPE</code> item. You may provide either <code>intersection</code> or <code>union</code> values.</p>
<ul>
<li><p><code>intersection</code>: Extract the ORFs for which all the criteria of the list are respected. For instance if the filtering is performed on ORF annotations providing the list <code>sORF, upstream</code>, then only the ORFs that have <strong>both</strong> of these annotation will be get. This type of filtering is not allowed for gene lists as an ORF cannot belong to two different genes according to the database model we use.</p></li>
<li><p><code>union</code>: Extract the ORFs for which at least one of the criteria of the list are respected. For instance if the filtering is performed on ORF annotations providing the list <code>sORF, upstream</code>, then all the ORFs that have <strong>at least</strong> one of these annotation will be get.</p></li>
</ul>
<p>The strategy consist of successive queries to extract all the data that satisfy the criteria provided by the user.</p>
<p><strong>NB</strong>: - Comma-separated list of values may eventually contain one space after the comma. - For more information about the differences between the ORF categories and the ORF annotations, please see the <em>Normalize the ORF categories, compute new ORF annotations</em> section of the current manual.</p>
<h3 id="filter-command-line">Filter command line</h3>
<p>To run the Filter strategy, use:</p>
<pre><code>sORFdatafreezer Filter -c ConfigFilePath [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-c</code>, <code>--configfile</code>: Absolute path to the config file.</li>
</ul>
<p>The following section and items of the config file are mandatory:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>PRO_DATABASE_NAME</code> item.</li>
<li><code>FILT_DATABASE_NAME</code> item.</li>
<li><code>DATABASE_SPECIES</code> item.</li>
</ul></li>
<li><code>[FILTERING]</code> section:
<ul>
<li><code>FILTERING_TYPE</code> item.</li>
<li>One of the following item has to be provided:
<ul>
<li><code>GENE_LIST_FILTER</code>: The absolute path to a csv file containing a list of genes.</li>
<li><code>CELL_CONTEXT_FILTER</code>: A comma-separated list of cell contexts.</li>
<li><code>ORF_CATEGORY_FILTER</code>: A comma-separated list of ORF categories.</li>
<li><code>ORF_ANNOTATION_FILTER</code>: A comma-separated list of ORF annotations.</li>
</ul></li>
</ul></li>
</ul>
<p>When using MySQL databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_HOST_IP</code>: The IP of the databases host.</li>
<li><code>DATABASE_PORT</code>: The port to use to establish the connection to the databases.</li>
<li><code>DATABASE_USER_NAME</code>: The username to use to connect to MySQL server.</li>
<li><code>DATABASE_USER_PASSWD</code>: The password to use to connect to MySQL server.</li>
</ul></li>
</ul>
<p>When using SQLite databases, the following section and items of the config file may be used:</p>
<ul>
<li><code>[DATABASE]</code> section:
<ul>
<li><code>DATABASE_FOLDER</code>: The folder of the databases.</li>
</ul></li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-f</code>, <code>--forceOverwrite</code>: Delete any existing FILT database at the provided path / on the server prior to build a new one. The PRO database from which data is get will not be affected.</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
</ul>
<h1 id="export-the-database-content">Export the database content</h1>
<p>The sORF datafreezer comes with some strategies that allow to export the content of a PRO database at different convenient formats (Fasta, BED…). This section of the manual presents more extensively these utils.</p>
<h2 id="export-the-orf-sequences-at-fasta-format">Export the ORF sequences at fasta format</h2>
<p>The sequences registered in the <em>ORF</em> and <em>ORFTranscriptAsso</em> tables may be exported at the fasta format using the <strong>GenerateFastaFile</strong> strategy. This strategy allow to export the content of one of this table, adding long or short fasta headers depending on the option selected. The fasta headers follows the <a href="https://www.uniprot.org/help/fasta-headers">UniProt recommendations</a> and should be compatible with most of the tools that accept fasta files.</p>
<h3 id="information-regarding-the-headers">Information regarding the headers</h3>
<p>When exporting the data from the <strong>ORF</strong> table, the headers look like:</p>
<ul>
<li>Short headers:</li>
</ul>
<pre><code>&gt;db|UniqueIdentified|EntryName</code></pre>
<ul>
<li>Long headers:</li>
</ul>
<pre><code>&gt;db|UniqueIdentifier|EntryName OS=OrganismName OX=OrganismIdentifier chr=ChromosomeName strand=Strand start_pos=GenomicStartPos stop_pos=GenomicStopPos exons=NumberOfExons database=DatabaseName url=DatabaseUrl release=DatabaseVersion</code></pre>
<p>When exporting the data from the <strong>ORFTranscriptAsso</strong> table, the headers look like:</p>
<ul>
<li>Short headers:</li>
</ul>
<pre><code>&gt;db|UniqueIdentified|EntryName</code></pre>
<ul>
<li>Long headers:</li>
</ul>
<pre><code>&gt;db|UniqueIdentifier|EntryName OS=OrganismName OX=OrganismIdentifier rel_start_pos=RelativeStartPos rel_stop_pos=RelativeStopPos orf_id=RelatedORFid transcript_id=RelatedTranscriptID database=DatabaseName url=DatabaseUrl release=DatabaseVersion</code></pre>
<p>Where:</p>
<ul>
<li><p><code>db</code> is the alias of the database (‘mORF’ standing for MetamORF).</p></li>
<li><p><code>UniqueIdentifier</code> is the unique identifier of the ORF or of the OTA (respectively with <code>ORF</code> or <code>OTA</code> prefix).</p></li>
<li><p><code>EntryName</code> is the unique identifier followed with the taxon code (separated by an underscore).</p></li>
<li><p><code>OrganismName</code> is the <a href="https://www.uniprot.org/docs/speclist">scientific name of the organism as defined by UniProt</a>.</p></li>
<li><p><code>OrganismIdentifier</code> is the <a href="https://ncbi.nlm.nih.gov/taxonomy">unique identifier of the organism, assigned by the NCBI</a>.</p></li>
<li><p><code>DatabaseName</code> is the full name of the database (‘MetamORF’).</p></li>
<li><p><code>DatabaseUrl</code> is the URL of the user-friendly web interface of the database.</p></li>
<li><p><code>DatabaseVersion</code> is the tag of the release of the database used to generate the file.</p></li>
<li><p><code>ChromosomeName</code> is the chromosome (or scaffold) name.</p></li>
<li><p><code>Strand</code> is the ORF strand (+/-).</p></li>
<li><p><code>start_pos</code> is the absolute genomics coordinate of the start position (<em>i.e.</em> position of the first nucleotide of the start codon for the ORFs located on the + strand, position of the last nucleotide of the stop codon for the ORFs located on the - strand).</p></li>
<li><p><code>stop_pos</code> is the absolute genomics coordinate of the stop position (<em>i.e.</em> position of the last nucleotide of the stop codon for the ORFs located on the + strand, position of the first nucleotide of the start codon for the ORFs located on the - strand).</p></li>
<li><p><code>NumberOfExons</code> is the number of exons in the ORF.</p></li>
<li><p><code>RelativeStartPos</code> is the relative coordinate of the start position on the transcript (<em>i.e.</em> relative position of the first nucleotide of the start codon for the ORFs located on the + strand, relative position of the last nucleotide of the stop codon for the ORFs located on the - strand). This value is only available for the ORFs located on transcripts that have a canonical CDS.</p></li>
<li><p><code>RelativeStopPos</code> is the relative coordinate of the stop position on the transcript (<em>i.e.</em> relative position of the last nucleotide of the stop codon for the ORFs located on the + strand, relative position of the first nucleotide of the start codon for the ORFs located on the - strand). This value is only available for the ORFs located on transcripts that have a canonical CDS.</p></li>
<li><p><code>RelatedORFid</code> is the unique identifier of the ORF described in this ORF-Transcript association.</p></li>
<li><p><code>RelatedTranscriptID</code> is the unique identifier of the transcript described in this ORF-Transcript association.</p></li>
</ul>
<p>All coordinates are 1-based, <em>i.e.</em> the first position of the chromosome is 1.</p>
<p>Examples:</p>
<pre><code>&gt;mORF|ORF13|ORF13_HUMAN
&gt;mORF|ORF246|ORF246_HUMAN OS=Homo sapiens OX=9606 chr=6 strand=+ start_pos=32972748 stop_pos=32972927 exons=1 database=MetamORF url=http://metamorf.univ-amu.fr release=1

&gt;mORF|OTA6|OTA6_HUMAN
&gt;mORF|OTA7|OTA7_HUMAN OS=Homo sapiens OX=9606 rel_start_pos=312 rel_stop_pos=344 orf_id=4199 transcript_id=4200 database=MetamORF url=http://metamorf.univ-amu.fr release=1</code></pre>
<h3 id="generatefastafile-command-line">GenerateFastaFile command line</h3>
<p>To run the GenerateFastaFile strategy, use:</p>
<pre><code>sORFdatafreezer GenerateFastaFile [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-N</code>, <code>--databaseName</code>: The database name.</li>
</ul>
<p>When using MySQL databases, the following options may be used:</p>
<ul>
<li><code>-H</code>, <code>--databaseHost</code>: The IP of the database host.</li>
<li><code>-P</code>, <code>--databasePort</code>: The port to use to establish the connection to the database.</li>
<li><code>-u</code>, <code>--databaseUser</code>: The username to use to connect to MySQL server.</li>
<li><code>-p</code>, <code>--databasePassword</code>: The password to use to connect to MySQL server.</li>
</ul>
<p>When using SQLite databases, the following options may be used:</p>
<ul>
<li><code>-F</code>, <code>--databaseFolder</code>: The folder of the database.</li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-f</code>, <code>--forceOverwrite</code>: Delete any existing database at the provided path / on the server prior to build a new one.</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-s</code>, <code>--seqType</code>: Type of the sequence required (<code>DNA</code> or <code>PROT</code>).</li>
<li><code>-q</code>, <code>--queryTable</code>: Table to query to generate the FASTA file (<code>ORF</code> for <em>ORF</em> table, <code>OTA</code> for <em>ORFTranscriptAsso</em> table).</li>
<li><code>-e</code>, <code>--excludeSqcesWithStop</code>: If selected, all the sequences that contains stop codons (at any other place that their end) will be excluded of the fasta file.</li>
<li><code>-l</code>, <code>--longHeader</code>: Use this option to get long fasta headers.</li>
<li><code>-o</code>, <code>--outputFolder</code>: The absolute path to the folder in which the GFF file has to be saved.</li>
<li><code>-a</code>, <code>--fastaFilename</code>: The name for the FASTA file generated (without its extension).</li>
</ul>
<h2 id="export-the-orf-information-at-bed-format">Export the ORF information at BED format</h2>
<p>The content of the <em>ORF</em> table may be exported at <a href="https://genome.ucsc.edu/FAQ/FAQformat.html#format1">BED format</a> using the <strong>GenerateBEDFile</strong> strategy. The BED file generated is a 12 columns files compatible with all tools accepting this format. In particular, it may be used with <a href="https://genome.ucsc.edu">UCSC</a> and <a href="https://www.ensembl.org">Ensembl</a> genome browsers as well as <a href="https://software.broadinstitute.org/software/igv/home">IGV software</a>.</p>
<p>The <code>--bigBed</code> option of the strategy may be used to generate an additional file at the bigBed format.</p>
<h3 id="information-regarding-the-bed-format">Information regarding the BED format</h3>
<p>For extensive information regarding the Bed format, you may consult:</p>
<ul>
<li><a href="http://genome-euro.ucsc.edu/FAQ/FAQformat.html#format3">http://genome-euro.ucsc.edu/FAQ/FAQformat.html#format3</a></li>
<li><a href="https://genome.ucsc.edu/goldenPath/help/customTrack.html#TRACK">https://genome.ucsc.edu/goldenPath/help/customTrack.html#TRACK</a></li>
</ul>
<p>The BED files created by the sORF datafreezer are tab-delimited and contains 12 columns by default and 12+5 columns when the <code>--extendBed</code> option is selected. Missing values are registered as <code>.</code>.</p>
<p>A line of the BED file looks like:</p>
<pre><code>chrom  chromStart  stopPosition  name  score  strand  thickStart  thickEnd  itemRgb  blockCount  blockSizes  blockStarts</code></pre>
<p>Where:</p>
<ul>
<li><code>chrom</code> is the chromosome name (or scaffold), with the <code>chr</code> prefix.</li>
<li><code>chromStart</code> is the absolute genomics coordinate of the start position (<em>i.e.</em> position of the first nucleotide of the start codon for the ORFs located on the + strand, position of the last nucleotide of the stop codon for the ORFs located on the - strand) <strong>in a 0-based system</strong>. Hence, these positions correspond to the ones recorded in our database <strong>minus one</strong>.</li>
<li><code>chromEnd</code> is the absolute genomics coordinate of the stop position (<em>i.e.</em> position of the last nucleotide of the stop codon for the ORFs located on the + strand, position of the first nucleotide of the start codon for the ORFs located on the - strand) <strong>in a 1-based system</strong>. Hence, these positions correspond to the ones recorded in our database.</li>
<li><code>name</code> is the unique identifier for the ORF in the database (integer, without the <code>ORF</code> prefix).</li>
<li><code>score</code> is currently not used and always set to <code>0</code>. This may evolve in the future release of the tool.</li>
<li><code>strand</code> is the strand of the ORF.</li>
<li><code>thickStart</code> is the start position at which the feature is drawn thickly (in coordinates relative to the ORF start).</li>
<li><code>thickEnd</code> is the end position at which the feature is drawn thickly (in coordinates relative to the ORF start).</li>
<li><code>itemRgb</code> is a color in the R,G,B format. One color is currently use for each strand. This is susceptible to evolve in the future releases.</li>
<li><code>blockCount</code> is the number of exons constituting the ORF.</li>
<li><code>blockSizes</code> is a comma-separated list of exon sizes.</li>
<li><code>blockStarts</code> is a comma-separated list of the exon starts, relatively to the position of the ORF start codon (<code>chromStart</code>).</li>
</ul>
<p>BED files are using “0-start, half-open” systems (also inaccurately called “0-based start, 1-based end” systems sometimes; which may be easier to understand). You may find more information about counting systems for genomics coordinates on the <a href="http://genome.ucsc.edu/blog/the-ucsc-genome-browser-coordinate-counting-systems/">UCSC blog</a>.</p>
<p>Example:</p>
<pre><code>chr1  8361096  8361132  4093  0  -  8361096  8361132  0,0,255  1  36  0</code></pre>
<h3 id="adding-a-track-line-to-the-file">Adding a track line to the file</h3>
<p>For extensive information regarding the Bed format, you may consult:</p>
<ul>
<li>References provided in the previous section</li>
<li><a href="https://software.broadinstitute.org/software/igv/TrackLine">https://software.broadinstitute.org/software/igv/TrackLine</a></li>
</ul>
<p>By default, the BED file is generated without any track line, header or comment. It is possible to add a track line before the first line by using the <code>--trackLine</code> option. The track line may help the user to visualize its data on a genome browser as it will provide the visualization software the best settings (as space separated “key-value” information, this includes using the right genome assembly). Be aware that, excepting the genome browser / viewer, numerous software that accept BED files ask the track line to be removed.</p>
<p>The trackline looks like:</p>
<pre><code>track name=trackName description=trackDescription htmlUrl=trackHtmlDescription url=databaseUrl db=assembly visibility=full color=defaultColor itemRgb=On  </code></pre>
<p>Where:</p>
<ul>
<li><code>trackName</code> is the name of the track.</li>
<li><code>trackDescription</code> is a short description of the track.</li>
<li><code>trackHtmlDescription</code> is the link to the HTML description page to be displayed with the track.</li>
<li><code>databaseUrl</code> is the link to the user-friendly web interface of the database.</li>
<li><code>assembly</code> is the genome assembly for which the data is intended, using the UCSC assembly name (<em>e.g</em> <code>hg38</code>).</li>
<li><code>visibility</code> defines the initial display mode of the annotation track.</li>
<li><code>defaultColor</code> is the main color for the annotation track.</li>
<li><code>itemRgb</code> inform the genome browser if it must use the RGB value to color items.</li>
</ul>
<p>NB: - If you are trying to convert the BED file at BigBed format by yourself, using <a href="https://genome.ucsc.edu/goldenPath/help/bigBed.html">UCSC bedToBigBed tool</a> will failed if you provide a BED that contains a track line needs to be removed. Nevertheless, this option is <strong>not</strong> incompatible with the <code>--bigBed</code> option of the strategy. Hence if you select both the <code>--trackLine</code> and the <code>--bigBed</code> options of this strategy, you will get both the BED file with the track line and the BigBed file.</p>
<h3 id="information-regarding-the-additional-columns">Information regarding the additional columns</h3>
<p>Five additional columns providing extensive information may be added to the BED file using the <code>--extendBed</code> option.</p>
<p>In such cases, a line of the BED file looks like:</p>
<pre><code>chrom  chromStart  stopPosition  name  score  strand  thickStart  thickEnd  itemRgb  blockCount  blockSizes  blockStarts  transcriptIDs  rnaBiotypes  orfAnnotations  KozakContext</code></pre>
<p>Where:</p>
<ul>
<li>First 12 elements are the same as the one previously described</li>
<li><code>transcriptIDs</code> is a comma-separated list of transcript IDs (“official” IDs, such as Ensembl transcript IDs) that harbor the ORF. The <code>UNKNOWN_TRANSCRIPT</code> ID indicates that at least one of the original data sources did not provide any information regarding the transcript harboring this ORF.</li>
<li><code>rnaBiotypes</code> is a comma-separated list of the RNA biotypes harboring this ORF.</li>
<li><code>orfAnnotations</code> is a comma-separated list of the annotations related to this ORF. Please read the <strong>Normalize the ORF categories, compute new ORF annotations</strong> section of the current manual for more information. This list includes information from the <em>ORFAnnotation</em> table <strong>exclusively</strong>.</li>
<li><code>KozakContext</code> is a comma-separated list of the Kozak context computed for this ORF. The context corresponds to the one computed using our own algorithm. Please read the <strong>Get the start flanking sequence and information regarding the Kozak context</strong> of the current manual for more information.</li>
</ul>
<p>Example:</p>
<pre><code>chr1  8361096  8361132  4093  0  -  8361096  8361132  0,0,255  1  36  0  ENST00000377464  protein_coding B_cell  Alternative,InCDS,Overlapping,sORF  weak</code></pre>
<p><strong>Caution</strong>: - Be aware that there are <strong>no</strong> correspondences between list-element of the five last columns. For instance, the first transcript ID of the list does <strong>not</strong> necessarily correspond to the first annotation of the list. This is explained by the fact that the transcript IDs, biotypes, annotations and computed Kozak contexts are provided as <strong>non-redudant</strong> lists. Moreover an ORF may have several distinct annotations when located on the same transcript (<em>e.g.</em> it can be <em>Upstream</em> and <em>Overlapping</em> at the same time for instance) and there may be missing data in the database (<em>e.g.</em> biotype of a transcript unknown), making impossible any correspondence between the other columns and this column.</p>
<p>NB: - Using this option will generate a new file with <code>.as</code> extension in the output folder. This file is an auto-sql file generated by our program and necessary to perform conversion at the BigBed format. It contains a description of the 12+5 columns contained in the BED file.</p>
<h3 id="converting-the-bed-file-at-bigbed-format">Converting the BED file at bigBed format</h3>
<p>Conversion at the BigBed format can be easily performed using the <a href="https://genome.ucsc.edu/goldenPath/help/bigBed.html">UCSC bedToBigBed</a> tool. Nevertheless, the conversion could sometimes be tricky; in particular the BED file needs to do not contain track line, an auto-sql file needs to be provided when using files at non-conventional formats (such as 12+5 format). In order to make the conversion easier, we implement the <code>--bigBed</code> option.</p>
<p>Using this option will first prepare a temporary file of your BED file, without track line, as well as the appropriate auto-sql (<code>.as</code>) file necessary to perform the conversion.</p>
<p>Using this option will generate tow new files in the output folder:</p>
<ul>
<li>The bigBed file (with <code>.bb</code> extension).</li>
<li>A file with the <code>.chrom.sizes</code> extension and containing all the chromosome sizes. As, the chromosome sizes are required to perform the conversion, this file is download from the UCSC using the <code>fetchChromSizes</code> executable.</li>
</ul>
<p>NB: - This option is compatible with the <code>--trackLine</code> option. - This option is compatible with the <code>--extendBed</code> option. - This option is not incompatible with the <code>--includeNonConventionalChr</code> option but the conversion at BigBed format is susceptible to fail when both of them are used. Hence, if there are chromosomes registered in the database that do not exists in this file, the conversion will fail. - The <code>.as</code> and <code>.chrom.sizes</code> file may eventually be removed manually, as they were only necessary for the conversion. - Using this option will <strong>not</strong> delete the file generate at the BED format.</p>
<h3 id="additional-information-regarding-the-generatebedfile-strategy">Additional information regarding the GenerateBEDFile strategy</h3>
<p>The <strong>GenerateBEDFile</strong> uses the <strong>GenerateBEDContent</strong> strategy to first generate one line respecting the BED format (12+5 columns) for <strong>all</strong> the ORF entries and save them in the PRO database (in the <em>UTBEDContent</em> table). In a second time, it query the database and assembles the lines to generate output file.</p>
<p>Doing this instead of directly create the BED file allows to:</p>
<ul>
<li><p>Lower the computation time required to create the BED file, as the lines will be computed only once (the first time the <strong>GenerateBEDFile</strong> strategy is used), even if several BED files are generated (with and without track line for instance),</p></li>
<li><p>Easily create new BED files restricted to a subset of the database, with any interface (web interface, R API…). Indeed, this is no longer necessary to collect the information necessary to build a line and to parse and compute some information (such as exon relative start positions), as it is just needed to query the lines corresponding to the set ORF entries desired. This allows user that would like to build new BED files restricted to some particular <em>ORF</em> entries to do it easily without needing any knowledge regarding BED formatting.</p></li>
</ul>
<p>If you need to compute the content of the <em>UTBEDContent</em> without generating BED files, you can directly use the <strong>GenerateBEDContent</strong> strategy.</p>
<h3 id="generatebedfile-command-line">GenerateBEDFile command line</h3>
<p>To run the GenerateBEDFile strategy, use:</p>
<pre><code>sORFdatafreezer GenerateBEDFile [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-N</code>, <code>--databaseName</code>: The database name.</li>
</ul>
<p>When using MySQL databases, the following options may be used:</p>
<ul>
<li><code>-H</code>, <code>--databaseHost</code>: The IP of the database host.</li>
<li><code>-P</code>, <code>--databasePort</code>: The port to use to establish the connection to the database.</li>
<li><code>-u</code>, <code>--databaseUser</code>: The username to use to connect to MySQL server.</li>
<li><code>-p</code>, <code>--databasePassword</code>: The password to use to connect to MySQL server.</li>
</ul>
<p>When using SQLite databases, the following options may be used:</p>
<ul>
<li><code>-F</code>, <code>--databaseFolder</code>: The folder of the database.</li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-o</code>, <code>--outputFolder</code>: Absolute path to the folder in which the BED file has to be saved.</li>
<li><code>-b</code>, <code>--bedFilename</code>: Name for the BED file generated (without “.bed” extension).</li>
<li><code>-a</code>, <code>--generateBEDTableContent</code>: Should the content of the UTBEDContent table be removed and computed again? When not selected, the BED file will be built with the existing content of the UTBEDContent. It is not necessary to use this option when running this strategy for the first time.</li>
<li><code>-l</code>, <code>--trackLine</code>: Add the track line at the beginning of the BED file.</li>
<li><code>-n</code>, <code>--includeNonConventionalChr</code>: Should the ORFs located on “non conventional” chromosomes (<em>e.g.</em> mitochondrial, scaffold) be included in the BED file?</li>
<li><code>-e</code>, <code>--extendBed</code>: Extend the BED file at 12+5 format.</li>
<li><code>-g</code>, <code>--bigBed</code>: Convert the BED file at the BigBed.</li>
</ul>
<h3 id="generatebedcontent-command-line">GenerateBEDContent command line</h3>
<p>To run the GenerateBEDContent strategy, use:</p>
<pre><code>sORFdatafreezer GenerateBEDContent [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-N</code>, <code>--databaseName</code>: The database name.</li>
</ul>
<p>When using MySQL databases, the following options may be used:</p>
<ul>
<li><code>-H</code>, <code>--databaseHost</code>: The IP of the database host.</li>
<li><code>-P</code>, <code>--databasePort</code>: The port to use to establish the connection to the database.</li>
<li><code>-u</code>, <code>--databaseUser</code>: The username to use to connect to MySQL server.</li>
<li><code>-p</code>, <code>--databasePassword</code>: The password to use to connect to MySQL server.</li>
</ul>
<p>When using SQLite databases, the following options may be used:</p>
<ul>
<li><code>-F</code>, <code>--databaseFolder</code>: The folder of the database.</li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
</ul>
<h2 id="generate-a-trackdb-file-for-track-hub-implementation">Generate a trackDb file for track hub implementation</h2>
<p>It might be interesting to implement track hubs accessible from <a href="https://genome.ucsc.edu">UCSC</a> and <a href="https://www.ensembl.org">Ensembl</a> genome browsers. Once the bigBed file has been successfully generated (see previous section), it is necessary to prepare couple of file allowing the UCSC and Ensembl genome browsers to access the genome track. The <strong>GenerateTrackDbFile</strong> strategy allows to generate the <code>trackDb.txt</code> file necessary to implement a new track hub with some advanced settings, such as filters on ORF annotations or RNA biotypes.</p>
<p>Please, read the following documentation for extensive information regarding the track hubs, the other files required and how to connect the UCSC and Ensembl genome browsers to a new track hub:</p>
<ul>
<li><a href="https://genome.ucsc.edu/goldenPath/help/hubQuickStart.html">https://genome.ucsc.edu/goldenPath/help/hubQuickStart.html</a></li>
<li><a href="http://genome.ucsc.edu/goldenPath/help/trackDb/trackDbHub.html">http://genome.ucsc.edu/goldenPath/help/trackDb/trackDbHub.html</a></li>
<li><a href="http://genome-euro.ucsc.edu/cgi-bin/hgHubConnect">http://genome-euro.ucsc.edu/cgi-bin/hgHubConnect</a></li>
</ul>
<h3 id="information-regarding-the-trackdb-file-generated">Information regarding the trackDb file generated</h3>
<p>The strategy generates a <code>trackDb.txt</code> file that may be directly used to implement track hubs.</p>
<p>It includes lists of transcript IDs, RNA biotypes, cell types, ORF annotations and computed Kozak contexts that may be used as filter in the UCSC or Ensembl genome browsers.</p>
<p>Example of trackDb file:</p>
<pre><code>track MetamORF_Hsapiens_hg38
shortLabel MetamORF_Hsapiens_hg38
longLabel MetamORF Hsapiens track hub (hg38)
html ../MetamorfHub
bigDataUrl MetamORF.bb
type bigBed 12 +
visibility full
thickDrawItem on
itemRgb on
maxItems 100000
exonArrows on
exonNumbers on
filterType.transcripts multipleListOr
filterText.transcripts *
filterLabel.transcripts Transcript IDs
filterValues.transcripts ENST00000175506,\
ENST00000216268,\
ENST00000218364,\
ENST00000222673,\
ENST00000225171,\
ENST00000225698,\
ENST00000249289
filterType.rna_biotypes multipleListOr
filterText.rna_biotypes *
filterLabel.rna_biotypes RNA biotypes
filterValues.rna_biotypes TEC,\
antisense_RNA,\
processed_transcript,\
protein_coding
filterType.cell_types multipleListOr
filterText.cell_types *
filterLabel.cell_types Cell types (cell lines, tissues...)
filterValues.cell_types Brain,\
Breast,\
Flp-In T-REx-293,\
HEK293,\
HFF,\
HeLa,\
Jurkat
filterType.kozak_contexts multipleListOr
filterText.kozak_contexts *
filterLabel.kozak_contexts Computed Kozak context
filterValues.kozak_contexts moderate,\
strong,\
weak
labelFields name, transcripts, rna_biotypes, cell_types, orf_annotations, kozak_contexts
urls name=&quot;http://metamorf.univ-amu.fr/orfID/$$&quot;\
transcripts=&quot;http://metamorf.univ-amu.fr/transcriptCentric/$$&quot;</code></pre>
<p>NB: - As this strategy has been implemented to facilitate the creation of MetamORF track hubs and inclusion of these track hubs in our website, some of the parameters (such as the URLs) are hard-coded and cannot be set by the user. Please contact the developer of the sORF datafreezer if you intend to change these parameters (see <strong>Contact</strong> section at the end of the current manual).</p>
<h3 id="generatetrackdbfile-command-line">GenerateTrackDbFile command line</h3>
<p>To run the GenerateTrackDbFile strategy, use:</p>
<pre><code>sORFdatafreezer GenerateTrackDbFile [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-N</code>, <code>--databaseName</code>: The database name.</li>
</ul>
<p>When using MySQL databases, the following options may be used:</p>
<ul>
<li><code>-H</code>, <code>--databaseHost</code>: The IP of the database host.</li>
<li><code>-P</code>, <code>--databasePort</code>: The port to use to establish the connection to the database.</li>
<li><code>-u</code>, <code>--databaseUser</code>: The username to use to connect to MySQL server.</li>
<li><code>-p</code>, <code>--databasePassword</code>: The password to use to connect to MySQL server.</li>
</ul>
<p>When using SQLite databases, the following options may be used:</p>
<ul>
<li><code>-F</code>, <code>--databaseFolder</code>: The folder of the database.</li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-o</code>, <code>--outputFolder</code>: Absolute path to the folder in which the trackDb file has to be saved</li>
<li><code>-f</code>, <code>--trackFilename</code>: Name for the trackDb file generated (without “.txt” extension).</li>
<li><code>-g</code>, <code>--bigBed</code>: Create the bigBed file corresponding to the trackDb file at the same time. See the <strong>Export the ORF information at BED format</strong> section of the current manual for more information. If selected, both the BED, bigBed, <code>.as</code> and <code>.chrom.sizes</code> files will be generated in the same folder than the <code>trackDb.txt</code> file. The output generated by the use of this option are the same than the one generated using the <strong>GenerateBEDFile</strong> strategy <strong>with</strong> <code>--extendBed</code> and <code>--bigBed</code> options and <strong>without</strong> <code>--includeNonConventionalChr</code> options.</li>
</ul>
<h2 id="export-the-orf-information-at-gff-format-beta-version">Export the ORF information at GFF format [BETA VERSION]</h2>
<p>In addition to the BED format, the content of the <em>ORF</em> table may be exported at the <a href="https://www.ensembl.org/info/website/upload/gff3.html">GFF3 format</a> using the <strong>GenerateGFFFile</strong> strategy. As BED format, the GFF3 format is accepted by many tools, in particular genome browsers and sequence alignment tools. GFF3 files propose the information in an highly structure way, using <a href="http://www.sequenceontology.org/so_wiki/index.php/Category:SO:SOFA">sequence ontology</a> and relationships between the features.</p>
<p><strong>Caution</strong>: Be aware that the <strong>GenerateGFFFile</strong> strategy is currently efficiently working and will generate a “GFF3-like formated” file, <strong>respecting all the GFF3 requirement excepted the sequence ontology</strong>. More information regarding this issue are provided below. Hence, if you need a file at GFF3 format but the sequence ontology does not matter for you, then you can use this strategy. Next release of the sORF datafreezer may include an update of this strategy in order to fix this issue and propose GFF3 files that respect the sequence ontology.</p>
<h3 id="information-regarding-the-gff3-file">Information regarding the GFF3 file</h3>
<p>For extensive information regarding the GFF3 format, you may consult:</p>
<ul>
<li><a href="https://www.ensembl.org/info/website/upload/gff3.html">https://www.ensembl.org/info/website/upload/gff3.html</a></li>
<li><a href="http://gmod.org/wiki/GFF3">http://gmod.org/wiki/GFF3</a></li>
<li><a href="https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md">https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md</a></li>
<li><a href="http://www.sequenceontology.org/so_wiki/index.php/Category:SO:SOFA">http://www.sequenceontology.org/so_wiki/index.php/Category:SO:SOFA</a></li>
</ul>
<p>The GFF3 files created by the sORF datafreezer are tab-delimited and contains 9 columns. Missing values are registered as <code>.</code>. The first line of the file contains <code>##gff-version 3</code>. No comments are added in the file, but may eventually be added manually after its generation using the <code>#</code> prefix. Columns are tab-delimited.</p>
<p>A line of the GFF3 file looks like:</p>
<pre><code>chr  source  type  start  end  score  strand  phase  attributes   ID=52.start;Parent=52</code></pre>
<p>Where:</p>
<ul>
<li><code>chr</code> is the name of the chromosome (or scaffold), without the <code>chr</code> prefix.</li>
<li><code>source</code> is the name of the database (MetamORF).</li>
<li><code>type</code> is the type of feature. The type is necessarily one defined in the <a href="http://www.sequenceontology.org/so_wiki/index.php/Category:SO:SOFA">Sequence Ontology (SOFA subset)</a>.</li>
<li><code>start</code> is the absolute genomis coordinate of the start position of the feature(<em>i.e.</em> the position of the first nucleotide of the feature) <strong>in a 1-based system</strong>. Hence, these positions correspond to the ones recorded in our database.</li>
<li><code>end</code> is the absolute genomis coordinate of the start position of the feature(<em>i.e.</em> the position of the last nucleotide of the feature) <strong>in a 1-based system</strong>. Hence, these positions correspond to the ones recorded in our database.</li>
<li><code>score</code> is currently not used (always replaced with <code>.</code>). This may evolve in the future releases of the tool.</li>
<li><code>strand</code> is the strand of the feature.</li>
<li><code>phase</code> is required for all features of type ‘CDS’ and indicates where the feature begins with reference to the reading frame. The phase indicates the number of bases that should be removed from the beginning of the feature to reach the first base of the next codon. 0 indicates the next codon begins at the first base of the region, 1 at the second base and 2 at the third base. <code>phase</code> is currently not used (always replaced with <code>.</code>). This may evolve in the future releases of the tool. NB: This is not too be confused with the frame. See external documentation for more information.</li>
<li><code>attributes</code> is a semi-colon separated list of tag-value pairs providing addition information about the features. It contains at list the unique entry of the feature in our database, at the format <code>ID=</code>.</li>
</ul>
<p>The following types of features are currently used:</p>
<ul>
<li>The <code>ORF</code> <a href="http://www.sequenceontology.org/so_wiki/index.php/Category:SO:0000236_!_ORF">feature</a> is used to describe open reading frames (<em>i.e.</em> entries of the <em>ORF</em> table).</li>
<li>The <code>start_codon</code> <a href="http://www.sequenceontology.org/so_wiki/index.php/Category:SO:0000318_!_start_codon">feature</a> is used to describe the ORF start codons (this information correspond to the information registered in the <code>start_pos</code> or <code>stop_pos</code> attributes of the <em>ORF</em> entries, for the ORFs respectively located on the + and - strand).</li>
<li>The <code>stop_codon</code> <a href="http://www.sequenceontology.org/so_wiki/index.php/Category:SO:0000319_!_stop_codon">feature</a> is used to describe the ORF stop codons (this information correspond to the information registered in the <code>stop_pos</code> or <code>start_pos</code> attributes of the <em>ORF</em> entries, for the ORFs respectively located on the + and - strand).</li>
<li>The <code>exon</code> <a href="http://www.sequenceontology.org/so_wiki/index.php/Category:SO:0000147_!_exon">feature</a> is used to describe the ORF exons (this information correspond to a part of the information registered in the <code>splice_starts</code> and <code>splice_ends</code> attributes of the <em>ORF</em> entries).</li>
</ul>
<p>NB: GFF3 files are using “1-start, full-closed” systems (also inaccurately called “1-based start, 1-based end” systems sometimes; which may be easier to understand). You may find more information about counting systems for genomics coordinates on the <a href="http://genome.ucsc.edu/blog/the-ucsc-genome-browser-coordinate-counting-systems/">UCSC blog</a>.</p>
<p>In the current version, the following sequence ontology is used. Be aware that this ontology does <strong>not</strong> respect the official Sequence Ontology.</p>
<ul>
<li>A <code>start_codon</code> is located on an ORF and thus as an <code>ORF</code> as parent.</li>
<li>A <code>stop_codon</code> is located on an ORF and thus as an <code>ORF</code> as parent.</li>
<li>An <code>exon</code> is located on an ORF and thus as an <code>ORF</code> as parent.</li>
<li>An <code>ORF</code> is orphan and has:
<ul>
<li>One unique <code>start_codon</code> feature as child.</li>
<li>and one unique <code>stop_codon</code> feature as child.</li>
<li>and one or several <code>exon</code> features as children (depending on the ORF splicing).</li>
</ul></li>
</ul>
<p>Depending on the feature type, the content of the attributes column vary:</p>
<ul>
<li><code>ORF</code> features have <code>ID=orfID</code> attributes, where <code>orfID</code> is the unique ID of the ORF in our database.</li>
<li><code>start_codon</code> features have <code>ID=orfID.start;Parent=orfID</code> attributes, where <code>orfID</code> is the unique ID of the ORF in our database.</li>
<li><code>stop_codon</code> features have <code>ID=orfID.stop;Parent=orfID</code> attributes, where <code>orfID</code> is the unique ID of the ORF in our database.</li>
<li><code>exon</code> features have <code>ID=orfID.nb;Parent=orfID</code> attributes, where <code>orfID</code> is the unique ID of the ORF in our database and <code>nb</code> is the logical number of the exon on the ORF starting at 0 (<em>i.e.</em> the first exon is <code>0</code>, the second is <code>1</code> and so on, in the reading order of the ORF - not in the increasing or decreasing order of start positions).</li>
</ul>
<p>Examples:</p>
<pre><code>1   MetamORF  ORF           114733767   114734026   .   -   .   ID=61
1   MetamORF  start_codon   114734024   114734026   .   -   .   ID=61.start;Parent=61
1   MetamORF  stop_codon    114733767   114733769   .   -   .   ID=61.stop;Parent=61
1   MetamORF  exon          114733767   114734026   .   -   .   ID=1009.0;Parent=1009

1   MetamORF  ORF           1091150     1091543     .   -   .   ID=1009
1   MetamORF  start_codon   1091541     1091543     .   -   .   ID=1009.start;Parent=1009
1   MetamORF  stop_codon    1091150     1091152     .   -   .   ID=1009.stop;Parent=1009
1   MetamORF  exon          1091150     1091374     .   -   .   ID=1009.1;Parent=1009
1   MetamORF  exon          1091472     1091543     .   -   .   ID=1009.0;Parent=1009

1   MetamORF  ORF           25983956    25990816    .   -   .   ID=1393
1   MetamORF  start_codon   25990814    25990816    .   -   .   ID=1393.start;Parent=1393
1   MetamORF  stop_codon    25983956    25983958    .   -   .   ID=1393.stop;Parent=1393
1   MetamORF  exon          25990727    25990816    .   -   .   ID=1393.0;Parent=139
1   MetamORF  exon          25989448    25989601    .   -   .   ID=1393.1;Parent=1393
1   MetamORF  exon          25988231    25988327    .   -   .   ID=1393.2;Parent=1393
1   MetamORF  exon          25984460    25984528    .   -   .   ID=1393.3;Parent=1393
1   MetamORF  exon          25983956    25984102    .   -   .   ID=1393.4;Parent=1393</code></pre>
<h3 id="generategfffile-command-line">GenerateGFFFile command line</h3>
<p>To run the GenerateGFFFile strategy, use:</p>
<pre><code>sORFdatafreezer GenerateGFFFile [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-N</code>, <code>--databaseName</code>: The database name.</li>
</ul>
<p>When using MySQL databases, the following options may be used:</p>
<ul>
<li><code>-H</code>, <code>--databaseHost</code>: The IP of the database host.</li>
<li><code>-P</code>, <code>--databasePort</code>: The port to use to establish the connection to the database.</li>
<li><code>-u</code>, <code>--databaseUser</code>: The username to use to connect to MySQL server.</li>
<li><code>-p</code>, <code>--databasePassword</code>: The password to use to connect to MySQL server.</li>
</ul>
<p>When using SQLite databases, the following options may be used:</p>
<ul>
<li><code>-F</code>, <code>--databaseFolder</code>: The folder of the database.</li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-o</code>, <code>--outputFolder</code>: Absolute path to the folder in which the GFF file has to be saved.</li>
<li><code>-g</code>, <code>--gffFilename</code>: Name for the GFF file generated (without the “.gff” or “.gff3” extension).</li>
</ul>
<h1 id="diagnosis-tools">Diagnosis tools</h1>
<p>The sORF datafreezer provides some tools that might help to ensure of the consistency of the data registered in the database. They might help to detect any problems related to the data, error that happened during the execution of the program or bugs that need to be fixed.</p>
<p>If you detect any bug, please contact the developers (see the <strong>Contact</strong> section at the end of this manual).</p>
<h2 id="assess-consistency-of-the-database-content">Assess consistency of the database content</h2>
<p>The <strong>AssessDatabaseContent</strong> strategy allows to ensure the consistency of data in a DS or PRO-like database. It performs a couple of checks on the data. These check output are registered in a 3-columns csv file where the first column contains the name of the check, the second contains the output message of the check and the third its status.</p>
<p>For each step, three kind of status may be registered:</p>
<ul>
<li><code>[OK]</code> means that the consistency is ensured.</li>
<li><code>[ERROR]</code> means that the consistency is not respected. Most of the time this is due to a programming error. If you see this king of error, please report it to the developer.</li>
<li><code>[TO CHECK]</code> means that the data have to be checked manually. Checking the content of the second columns is generally sufficient to make sure of the data consistency.</li>
</ul>
<h3 id="assessment-of-ds-databases">Assessment of DS databases</h3>
<p>The following checks are performed during the execution of the strategy:</p>
<ul>
<li><p>Check the chromosomes registered in the <em>DSORF</em> table (the list needs to be checked manually).</p></li>
<li><p>Check the raw strands registered in the <em>DSORF</em> table (<code>+</code>/<code>-</code> allowed).</p></li>
<li><p>Check the strands registered in the <em>DSORF</em> table (<code>+</code>/<code>-</code> allowed).</p></li>
<li><p>Check all the raw start positions are lower then the raw stop positions in the <em>DSORF</em> table.</p></li>
<li><p>Check all the start positions are lower then the stop positions in the <em>DSORF</em> table.</p></li>
<li><p>Check that all the ORFs that are not spliced have one single exon (in the <em>DSORF</em> table).</p></li>
<li><p>Check that all the ORFs that are not spliced do not have any exon coordinates registered (in the <em>DSORF</em> table).</p></li>
<li><p>Check that all the ORFs that are spliced have at least two exons (in the <em>DSORF</em> table).</p></li>
<li><p>Check that all the ORF raw genomic lengths are positive (in the <em>DSORF</em> table).</p></li>
<li><p>Check that all the ORF genomic lengths are positive (in the <em>DSORF</em> table).</p></li>
<li><p>Check that all the raw start positions of the exons are in the increasing order, all the raw stop positions are in the increasing order, and that the raw start position of exons are always higher than the raw stop position of the exon that precede it, for the ORFs located on the + strand (in the <em>DSORF</em> table).</p></li>
<li><p>Check that all the raw start positions of the exons are in the drecreasing order, all the raw stop positions are in the drecreasing order, and that the raw start position of exons are always lower than the raw stop position of the exon that precede it, for the ORFs located on the - strand (in the <em>DSORF</em> table).</p></li>
<li><p>Check that all the start positions of the exons are in the increasing order, all the stop positions are in the increasing order, and that the start position of exons are always higher than the stop position of the exon that precede it, for the ORFs located on the + strand (in the <em>DSORF</em> table).</p></li>
<li><p>Check that all the start positions of the exons are in the drecreasing order, all the stop positions are in the drecreasing order, and that the start position of exons are always lower than the stop position of the exon that precede it, for the ORFs located on the - strand (in the <em>DSORF</em> table).</p></li>
<li><p>Check that all the raw start positions are lower than the corresponding raw end positions in the <em>DSTranscript</em> table.</p></li>
<li><p>Check that all the start positions are lower than the corresponding end positions in the <em>DSTranscript</em> table.</p></li>
<li><p>Check that all the CDS raw start positions are lower than the corresponding CDS raw stop positions in the <em>DSTranscript</em> table.</p></li>
<li><p>Check that all the CDS start positions are lower than the corresponding CDS stop positions in the <em>DSTranscript</em> table.</p></li>
<li><p>Check the RNA biotypes used in the <em>DSTranscript</em> table (the list needs to be checked manually).</p></li>
<li><p>Check that all the nucleic lengths are consistent with the amino acid lengths in the <em>DSORFTranscriptAsso</em> table.</p></li>
<li><p>Check the chromosomes registered in the <em>Gene</em> table (the list needs to be checked manually).</p></li>
</ul>
<p>Example:</p>
<pre><code>---  Assessment of the consistency the DSORF table content
List of chromosomes:    1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 20, 21, 22, 3, 4, 5, 6, 7, 8, 9, GL000191.1, GL000192.1, GL000193.1, GL000194.1, GL000195.1, GL000201.1, GL000204.1, GL000205.1, GL000209.1, GL000212.1, GL000213.1, GL000215.1, GL000218.1, GL000219.1, GL000221.1, GL000222.1, GL000223.1, GL000228.1, GL000237.1, GL000242.1, MT, NC_006273, X, X|Y, Y [TO CHECK]
Raw strands:    +, -    [OK]
Strands:    +, -    [OK]
Raw positions:  All DSORFs have the raw start position lower than the raw stop position [OK]
Positions:  All DSORFs have the start position lower than the stop position [OK]
Splicing / Exon number: All DSORFs not spliced have a single exon   [OK]
Splicing / Exon positions:  All DSORFs not spliced do not have exonic positions [OK]
Splicing / Exon number: All DSORF spliced have at least two exons   [OK]
Raw genomic lengths:    All DSORFs have a positive raw genomic length   [OK]
Genomic lengths:    All DSORFs have a positive genomic length   [OK]
Spliced position (DSORFs on + raw strand):  All DSORFs on + raw strand have their raw spliced positions in the increasing order [OK]
Spliced position (DSORFs on - raw strand):  All DSORFs on - raw strand have their raw spliced positions in the decreasing order [OK]
Spliced position (DSORFs on + strand):  All DSORFs on + strand have their spliced positions in the increasing order [OK]
Spliced position (DSORFs on - strand):  All DSORFs on - strand have their spliced positions in the decreasing order [OK]

--- Assessment of the consistency the DSTranscript table content
Raw positions:  All DSTranscripts have the raw start position lower than the raw end position   [OK]
Positions:  All DSTranscripts have the start position lower than the end position   [OK]
Raw CDS positions:  All DSTranscripts have the raw CDS start position lower than the raw CDS stop position  [OK]
CDS positions:  All DSTranscripts have the CDS start position lower than the CDS stop position  [OK]
List of RNA biotypes:   TEC, antisense, lincRNA, non_stop_decay, nonsense_mediated_decay, processed_pseudogene, processed_transcript, protein_coding, retained_intron, sense_intronic, sense_overlapping, transcribed_processed_pseudogene, transcribed_unitary_pseudogene, transcribed_unprocessed_pseudogene, unitary_pseudogene, unprocessed_pseudogene  [TO CHECK]
--- Assessment of the consistency the DSORFTranscriptAsso table content
Lengths:    All DSORFTranscriptAsso have their nucleic lengths consistent with their lengths in amino acids [OK]

--- Assessment of the consistency the Gene table content
List of chromosomes:    1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 20, 21, 22, 3, 4, 5, 6, 7, 8, 9, GL000191.1, GL000192.1, GL000193.1, GL000194.1, GL000195.1, GL000201.1, GL000204.1, GL000205.1, GL000209.1, GL000212.1, GL000213.1, GL000215.1, GL000218.1, GL000219.1, GL000221.1, GL000222.1, GL000223.1, GL000228.1, GL000237.1, GL000242.1, MT, NC_006273, X, X|Y, Y, c10_B, reserved, unplaced  [TO CHECK]
</code></pre>
<h3 id="assessment-of-pro-databases">Assessment of PRO databases</h3>
<p>The following checks are performed during the execution of the strategy:</p>
<ul>
<li><p>Check the chromosomes registered in the <em>ORF</em> table (the list needs to be checked manually).</p></li>
<li><p>Check the strands registered in the <em>ORF</em> table (<code>+</code>/<code>-</code> allowed).</p></li>
<li><p>Check all the start positions are lower then the stop positions in the <em>ORF</em> table.</p></li>
<li><p>Check that all the ORFs that are not spliced have one single exon (in the <em>ORF</em> table).</p></li>
<li><p>Check that all the ORFs that are not spliced do not have any exon coordinates registered (in the <em>ORF</em> table).</p></li>
<li><p>Check that all the ORFs that are spliced have at least two exons (in the <em>ORF</em> table).</p></li>
<li><p>Check that all the ORF genomic lengths are positive (in the <em>ORF</em> table).</p></li>
<li><p>Check that all the start positions of the exons are in the increasing order, all the stop positions are in the increasing order, and that the start position of exons are always higher than the stop position of the exon that precede it, for the ORFs located on the + strand (in the <em>ORF</em> table).</p></li>
<li><p>Check that all the start positions of the exons are in the drecreasing order, all the stop positions are in the drecreasing order, and that the start position of exons are always lower than the stop position of the exon that precede it, for the ORFs located on the - strand (in the <em>ORF</em> table).</p></li>
<li><p>Check that all the start positions are lower than the corresponding end positions in the <em>Transcript</em> table.</p></li>
<li><p>Check that all the CDS start positions are lower than the corresponding CDS stop positions in the <em>Transcript</em> table.</p></li>
<li><p>Check that all the CDS relative start positions are lower than the corresponding CDS relative stop positions in the <em>Transcript</em> table.</p></li>
<li><p>Check that all the relative ORF start positions are lower than the relative stop position (<em>ORFTranscriptAsso</em> table).</p></li>
<li><p>Check the RNA biotypes used in the database (the list needs to be checked manually).</p></li>
<li><p>Check the chromosomes registered in the <em>PROGene</em> table (the list needs to be checked manually).</p></li>
<li><p>Check the provided ORF categories (registered in the <em>ProvidedCategoryCatalog</em> table, the list needs to be checked manually).</p></li>
<li><p>Check the cell contexts (registered in the <em>CellContextCatalog</em> table, the list needs to be checked manually).</p></li>
<li><p>Check the FLOSS classes (registered in the <em>FLOSSClassCatalog</em> table, the list needs to be checked manually).</p></li>
<li><p>Check the ORF categories (registered in the <em>ORFCategoryCatalog</em> table, the list needs to be checked manually).</p></li>
</ul>
<p>Example:</p>
<pre><code>--- Assessment of the consistency the ORF table content
List of chromosomes:    1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 20, 21, 22, 3, 4, 5, 6, 7, 8, 9, MT, X, Y [TO CHECK]
Strands:    +, -    [OK]
Positions:  All ORFs have the start position lower than the stop position   [OK]
Splicing / Exon number: All ORFs not spliced have a single exon [OK]
Splicing / Exon positions:  All ORFs not spliced do not have any exonic positions   [OK]
Splicing / Exon number: All ORF spliced have at least two exons [OK]
Genomic lengths:    All ORFs have a positive genomic length [OK]
Spliced position (ORFs on + strand):    All ORFs on + strand have their spliced positions in the increasing order   [OK]
Spliced position (ORFs on - strand):    All ORFs on - strand have their spliced positions in the decreasing order   [OK]

--- Assessment of the consistency the Transcript table content
Positions:  All Transcripts have the start position lower than the end position [OK]
CDS positions:  All Transcripts have the CDS start position lower than the CDS stop position    [OK]
List of RNA biotypes:   TEC, antisense, antisense_RNA, lincRNA, non_stop_decay, nonsense_mediated_decay, polymorphic_pseudogene, processed_pseudogene, processed_transcript, protein_coding, retained_intron, sense_intronic, sense_overlapping, transcribed_processed_pseudogene, transcribed_unitary_pseudogene, transcribed_unprocessed_pseudogene, unitary_pseudogene, unprocessed_pseudogene   [TO CHECK]

--- Assessment of the consistency the PROGene table content
List of chromosomes:    1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 20, 21, 22, 23, 3, 4, 5, 6, 7, 8, 9, MT, X, Y   [TO CHECK]

--- Assessment of the consistency the ORF categories, cell context and FLOSS classes
List of (provided) ORF categories:  3_UTR, 3UTR, 5_UTR, 5UTR, alternative_frame, annotated, Annotated, ANTISENSE, CDS_overlap, dORF, EXON, exonic, In, intergenic, INTERGENIC, INTRON, intronic, iORF, Isoform, lincRNA, lncrna, ncRNA, NMD, NO_FRAME, NSD, other, Out, pseudogene, RETAINED_INTRON, sORF, TEC, uoORF, uORF, utr3, utr5 [TO CHECK]
List of cell contexts:  B_cell, BJ, Blood, Brain, Brain_tumor, Breast, Flp-In T-REx-293, HAP1, HCT116, HEK293, HEK293T, HeLa, hES, HFF, Jurkat, LCL, MDA-MB-231, MM1S, Monocyte, NCCIT, RPE-1, Skeletal_muscle, THP-1, U2OS [TO CHECK]
List of FLOSS classes:  Extreme, Good, No reads, Not in cutoff range    [TO CHECK]
List of (computed) ORF categories:  Alternative, CDS, Downstream, Exonic, Intergenic, Intronic, ncRNA, NMD, NSD, Overlapping, Pseudogene, sORF, Upstream    [TO CHECK]</code></pre>
<h3 id="assessdatabasecontent-command-line">AssessDatabaseContent command line</h3>
<p>To run the AssessDatabaseContent strategy, use:</p>
<pre><code>sORFdatafreezer AssessDatabaseContent [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-N</code>, <code>--databaseName</code>: The database name.</li>
<li><code>-M</code>, <code>--databaseModel</code>: The schema of the database (PRO / DS).</li>
</ul>
<p>When using MySQL databases, the following options may be used:</p>
<ul>
<li><code>-H</code>, <code>--databaseHost</code>: The IP of the database host.</li>
<li><code>-P</code>, <code>--databasePort</code>: The port to use to establish the connection to the database.</li>
<li><code>-u</code>, <code>--databaseUser</code>: The username to use to connect to MySQL server.</li>
<li><code>-p</code>, <code>--databasePassword</code>: The password to use to connect to MySQL server.</li>
</ul>
<p>When using SQLite databases, the following options may be used:</p>
<ul>
<li><code>-F</code>, <code>--databaseFolder</code>: The folder of the database.</li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-o</code>, <code>--outputFolder</code>: Absolute path to the folder in which all the files generated have to be saved.</li>
<li><code>-f</code>, <code>--filename</code>: Name for the log file generated.</li>
</ul>
<h2 id="get-a-summary-of-log-files">Get a summary of log files</h2>
<p>Depending of the level of the verbosity set to run the strategies, the main log files can contain a lot of data (in particular the <strong>Insertion</strong> strategy, around 50,000 - 100,000 lines logged for a full built with the 6 data sources in <em>H. sapiens</em> for instance). The <strong>GenerateStatFiles</strong> strategy allow to generate two files summarizing the information contained in these log files.</p>
<ul>
<li><p>One file registering the number of logs at each verbosity level (<code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code>). Any message logged at the <code>CRITICAL</code> should be checked.</p></li>
<li><p>One file registering the number of logs for each existing warning and error code (cf. file registering the log codes that may be used by the sORF datafreezer).</p></li>
</ul>
<p>In addition, we advice to use the <code>grep -i 'exc' execution.log*</code> command line that is expected to return no result. Otherwise, it will highlight any exception raised using the sORF datafreezer.</p>
<p><strong>Caution</strong>: If the main log files have been altered, then this strategy will obviously not provide accurate information.</p>
<h3 id="generatestatfiles-command-line">GenerateStatFiles command line</h3>
<p>To run the GenerateStatFiles strategy, use:</p>
<pre><code>sORFdatafreezer GenerateStatFiles [OPTIONS]</code></pre>
<p>The following options may be used:</p>
<ul>
<li><code>-f</code>, <code>--forceOverwrite</code>: Overwrite any existing files.</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-o</code>, <code>--outputFolder</code>: Absolute path to the folder in which all the files generated have to be saved.</li>
</ul>
<h2 id="statistical-analysis-of-the-database-content">Statistical analysis of the database content</h2>
<p>The statistical analysis of the databases may help detecting any inconsistency in the data or issue that happened during the execution of one of the strategy. Such analysis can <strong>not</strong> be performed using the sORF datafreezer as it is impossible to make it fully automated and has to be performed manually. Nevertheless, a R package (<strong>RqueryORF</strong>) has been developed to help performing this analysis and provide convenient functions that might help. Please see the documentation of this package for more information.</p>
<h1 id="backup-restore-and-convert-databases">Backup, restore and convert databases</h1>
<p>SQLite databases can be backup easily by copying the unique SQLite3 file. MySQL databases can be dumped at convenient formats, such as <code>.sql.gz</code> using database management tools such as <a href="https://adminer.org">adminer</a> or <a href="https://www.phpmyadmin.net">phpMyAdmin</a>.</p>
<p>Nevertheless, two <strong>Backup</strong> and <strong>Restore</strong> strategies have been implemented respectively to save the content of a database in hidden files and import the content of those files to restore the database. More precisely, the content of each table is saved as serialized objects in <code>.dcorf</code> files.</p>
<p><strong>Caution</strong>: If the hidden files have been altered or deleted, the <strong>Restore</strong> strategy will obviously failed or may result in silent errors.</p>
<h2 id="database-backup">Database backup</h2>
<h3 id="backup-command-line">Backup command line</h3>
<p>To run the Backup strategy, use:</p>
<pre><code>sORFdatafreezer Backup [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-N</code>, <code>--databaseName</code>: The database name.</li>
<li><code>-M</code>, <code>--databaseModel</code>: The schema of the database (PRO / DS).</li>
</ul>
<p>When using MySQL databases, the following options may be used:</p>
<ul>
<li><code>-H</code>, <code>--databaseHost</code>: The IP of the database host.</li>
<li><code>-P</code>, <code>--databasePort</code>: The port to use to establish the connection to the database.</li>
<li><code>-u</code>, <code>--databaseUser</code>: The username to use to connect to MySQL server.</li>
<li><code>-p</code>, <code>--databasePassword</code>: The password to use to connect to MySQL server.</li>
</ul>
<p>When using SQLite databases, the following options may be used:</p>
<ul>
<li><code>-F</code>, <code>--databaseFolder</code>: The folder of the database.</li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-o</code>, <code>--outputFolder</code>: Absolute path to the folder in which the files have to be saved.</li>
<li><code>-x</code>, <code>--filePrefix</code>: Prefix to add to the file names where data are saved.</li>
</ul>
<h2 id="restoring-a-database">Restoring a database</h2>
<p>If there is a database of this name already existing and the <code>--forceOverwrite</code> has not been selected, the sORF datafreezer will ask the user if the existing database has to be deleted. Otherwise, it will automatically create the database prior to restore its content.</p>
<h3 id="restore-command-line">Restore command line</h3>
<p>To run the Restore strategy, use:</p>
<pre><code>sORFdatafreezer Restore [OPTIONS]</code></pre>
<p>The following options are mandatory:</p>
<ul>
<li><code>-N</code>, <code>--databaseName</code>: The database name.</li>
<li><code>-M</code>, <code>--databaseModel</code>: The schema of the database (PRO / DS).</li>
</ul>
<p>When using MySQL databases, the following options may be used:</p>
<ul>
<li><code>-H</code>, <code>--databaseHost</code>: The IP of the database host.</li>
<li><code>-P</code>, <code>--databasePort</code>: The port to use to establish the connection to the database.</li>
<li><code>-u</code>, <code>--databaseUser</code>: The username to use to connect to MySQL server.</li>
<li><code>-p</code>, <code>--databasePassword</code>: The password to use to connect to MySQL server.</li>
</ul>
<p>When using SQLite databases, the following options may be used:</p>
<ul>
<li><code>-F</code>, <code>--databaseFolder</code>: The folder of the database.</li>
</ul>
<p>The following options may be used:</p>
<ul>
<li><code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite).</li>
<li><code>-f</code>, <code>--forceOverwrite</code>: Delete any existing database at the provided path / on the server prior to restore the database from backup.</li>
<li><code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</li>
<li><code>-i</code>, <code>--inputFolder</code>: Absolute path to the folder in which the files are located.</li>
<li><code>-x</code>, <code>--filePrefix</code>: Prefix used when generated the files with the Restore strategy.</li>
</ul>
<h2 id="convert-sqlite-databases-at-mysql-format-and-vice-versa">Convert SQLite databases at MySQL format and vice versa</h2>
<p>According to the way the data are handled by the <strong>Backup</strong> and <strong>Restore</strong> strategies, this is theoretically possible to convert a SQLite database at the MySQL format and vice versa. To do this, use sequentially these strategies with different <code>--databaseType</code> options.</p>
<p><strong>Caution</strong>: This method of conversion has not been extensively assessed or bench-marked and may be susceptible to result in unexpected errors. Hence, we advice to avoid as most as possible converting SQLite databases to MySQL format and vice versa.</p>
<h1 id="information-to-developers">Information to developers</h1>
<p>A documentation dedicated to the developers (generated with <a href="https://www.doxygen.nl/">Doxygen</a>) is available at HTML format and provided with the source code. Please refer to this documentation for extensive information about the source code.</p>
<p>This section of the manual only presents <strong>some</strong> of the constants which could be interesting to change in occasional cases. Nevertheless, we <strong>highly discourage</strong> the change of these constant values and <strong>do not guarantee</strong> the successful execution of the strategies when modifying these values.</p>
<p>To change the default output main folder, update the <code>OUTPUT_FOLDER</code> defined in the <code>fr.tagc.uorf.core.util.DefaultOutputFolder</code> module.</p>
<p>To change the default temporary main folder, update the <code>TEMPORARY_FOLDER</code> defined in the <code>fr.tagc.uorf.core.util.DefaultTemporaryFolder</code> module.</p>
<p>Description of some constantes defined in the <code>Constants</code> file (<code>fr.tagc.uorf.core.util.Constants</code>):</p>
<ul>
<li><p>The list of accepted species are defined in the <strong>General constant</strong> section. Be aware that some strategies uses tools which are not necessarily compatible with other species than <em>H. sapiens</em> and <em>M. musculus</em>. In any case, you need to provide the correspondences between species common, scientific names, genome annotations names etc. as defined by the constants of this section.</p></li>
<li><p><code>EMPTY_VALUES</code>: List of values that have to be considered as empty / missing values in the data sources.</p></li>
<li><p><code>ALIAS_OFF_PREFIX</code> allows to set the prefix to add to official symbols when filling the GeneAlias table.</p></li>
<li><p><code>CURRENT_ENSEMBL_RELEASE</code> defines the number of the current Ensembl release.</p></li>
<li><p><code>PATH_LOG</code> defines the path to use for the main log file.</p></li>
<li><p><code>PATH_GENEREF_LOG</code> defines the path to use for the gene references log file.</p></li>
<li><p><code>LOG_SIZE_MAX</code> and <code>GENEREF_LOG_SIZE_MAX</code> define the maximum size of log files.</p></li>
<li><p><code>LOG_MAX_FILES_NB</code> and <code>GENEREF_LOG_MAX_FILES_NB</code> define the maximum number of log files that can be generated.</p></li>
<li><p><code>MAX_POOL_SIZE</code> defines the maximum number of process that can be pushed in a pool (when multi-processing computations).</p></li>
<li><p><code>CHROMOSOME_NAME_XY</code> defines the chromosome name to use for the sexual chromosome.</p></li>
<li><p><code>MITOCHONDRIAL_CHR</code> defines the chromosome name to use for the mitochondrial chromosome. <code>MITOCHONDRIAL_CHR_LIST</code> is the list of chromosome names to be considered as mitochondrial chromosome.</p></li>
<li><p><code>PREFIX_FAKE_TRANSCRIPT</code> defines the prefix to use for “fake” transcripts.</p></li>
<li><p><code>UNKNOWN_TRANSCRIPT</code> defines the string to use for unknown transcripts.</p></li>
<li><p><code>PREFIX_UNKNOWN_GENE</code> defines the prefix to use for unknown genes.</p></li>
<li><p><code>PREFIX_OVERLAPPING_GENES</code> and <code>PREFIX_OVERLAPPING_LNCRNAS</code> define the prefix to use for ORFs overlapping with several genes or lncRNAs.</p></li>
<li><p><code>PREFIX_INTERGENIC_GENE</code> defines the prefix to use for ORF located in intergenic regions.</p></li>
<li><p><code>PREFIX_CONFLICT_GENE_TRANSCRIPT</code> defines the prefix to use for genes on related to a transcript that for which the actual genes information is conflicting.</p></li>
<li><p><code>FAKE_CROSSREF</code> defines the string to use for cross-references of fake genes.</p></li>
<li><p><code>ORF_SPLICING_COORD_SEPARATOR</code> defines the separator to use for exon coordinates in the <em>DSORF</em> and <em>ORF</em> tables.</p></li>
<li><p><code>OTA_LIST_VALUES_SEPARATOR</code> defines the separators to use for list of values in the <em>ORFTranscriptAsso</em> table.</p></li>
<li><p><code>DENCELLORFOBJ_AMBIGUOUS_ATT</code> defines the flag to use for conflicting information from a data source.</p></li>
<li><p>The <strong>Constants relative to the Metadata table</strong> section defines strings to use in the metadata tables.</p></li>
<li><p><code>SEQUENCE_AMBIGUOUS_DNA_BASE</code> defines the letter to use for ambiguous nucleotide.</p></li>
<li><p><code>SEQUENCE_AMBIGUOUS_PROT_AA</code> defines the letter to use for ambiguous amino acid.</p></li>
<li><p><code>MAX_ENTRIES_PER_DATAFRAME</code> defines the maximal number of entries that may be stored in data frame when computing the relative coordinates.</p></li>
<li><p>The <strong>Constants relative to the ORF annotations</strong> section defines values to use for the ORF annotations and categories.</p></li>
</ul>
<h1 id="list-of-available-options">List of available options</h1>
<p>The following options can be used with <strong>all</strong> strategies: - <code>-v</code>, <code>--verbosity</code>: Set the level of verbosity.</p>
<p>The following options are <strong>common</strong> to several strategies: - <code>-T</code>, <code>--databaseType</code>: Type of database (MySQL or SQLite). - <code>-c</code>, <code>--configfile</code>: Absolute path to the config file. - <code>-N</code>, <code>--databaseName</code>: The database name. - <code>-M</code>, <code>--databaseModel</code>: The schema of the database (PRO / DS). - <code>-H</code>, <code>--databaseHost</code>: The IP of the database host. - <code>-P</code>, <code>--databasePort</code>: The port to use to establish the connection to the database. - <code>-u</code>, <code>--databaseUser</code>: The username to use to connect to MySQL server. - <code>-p</code>, <code>--databasePassword</code>: The password to use to connect to MySQL server. - <code>-F</code>, <code>--databaseFolder</code>: The folder of the database. - <code>-t</code>, <code>--threads</code>: Number of threads available. If not provided the program try to use all the threads available on the computer.</p>
<p>The following options are specific to one strategy:</p>
<p><strong>DatabaseCheck</strong> strategy: - <code>-f</code>, <code>--forceOverwrite</code>: Delete any existing database at the provided path / on the server prior to build a new one.</p>
<p><strong>AddReleaseVersion</strong> strategy: - <code>-r</code>, <code>--releaseNumber</code>: The tag of the version. - <code>-d</code>, <code>--releaseDescription</code>: The description of the version.</p>
<p><strong>Insertion</strong> strategy: - <code>-f</code>, <code>--forceOverwrite</code>: Delete any existing database at the provided path / on the server prior to build a new one and to run the insertion.</p>
<p><strong>ForceInsertion</strong> strategy: - <code>-s</code>, <code>--source</code>: A comma-separated list of the data source to insert in the database (without space), in the order in which they need to be inserted. You must use <code>UTGeneFromAlias</code> as a source name to re-insert data computed after the insertion of the last gene list and prior to the first data source name if you are re-inserting both gene lists and data sources.</p>
<p><strong>Deletion</strong> strategy: - <code>-s</code>, <code>--source</code>: A comma-separated list of the data source to delete from the database (without space).</p>
<p><strong>Merge</strong> strategy: - <code>-f</code>, <code>--forceOverwrite</code>: Delete any existing PRO database at the provided path / on the server prior to build a new one. The DS database will not be affected. - <code>-d</code>, <code>--checkDSOTA</code>: Should the content of the DSORFTranscriptAsso table need to be check prior to run the strategy? Be aware that selecting this option may be highly time-consuming. We advice to provide as many threads as possible when using this option. - <code>-s</code>, <code>--computeConsensus</code>: Should a consensus of the DSORFTranscriptAsso sequences be computed? Be aware that selecting this option may be highly time-consuming. We advice to provide as many threads as possible when using this option.</p>
<p><strong>ResumeMerge</strong> strategy: - <code>-d</code>, <code>--checkDSOTA</code>: Should the content of the DSORFTranscriptAsso table need to be check prior to run the strategy? Be aware that selecting this option may be highly time-consuming. We advice to provide as many threads as possible when using this option. - <code>-s</code>, <code>--computeConsensus</code>: Should a consensus of the DSORFTranscriptAsso sequences be computed? Be aware that selecting this option may be highly time-consuming. We advice to provide as many threads as possible when using this option. - <code>-a</code>, <code>--resumeAtStep</code>: The name of the step at which the merging should be resumed.</p>
<p><strong>computeMissingInfo</strong> strategy: - <code>-f</code>, <code>--forceOverwrite</code>: Enforce the computation of all steps, including the ones that already succeed. When this option is not selected, the strategy will resume from where it failed. - <code>-d</code>, <code>--downloadMissingInfo</code>: Download the missing information (such as ORF and Transcript sequences) from external databases. Note that selecting this option may be highly time-consuming.</p>
<p><strong>ComputeRelCoord</strong> strategy: - <code>-f</code>, <code>--forceOverwrite</code>: Compute again any existing relative coordinates.</p>
<p><strong>ComputeKozakContext</strong> strategy: - <code>-f</code>, <code>--forceOverwrite</code>: Should all Kozak contexts be computed again?</p>
<p><strong>AnnotateORF</strong> strategy: - <code>-f</code>, <code>--forceOverwrite</code>: Delete all the entries of the ORFCategory and ORFCategoryCatalog and/or of the ORFAnnotation and ORFAnnotationCatalog tables (PRO database, depending on the other options selected) prior to run the strategy. - <code>-s</code>, <code>--computeCatFromSource</code>: Compute the ORF categories from the categories provided by the datasource (ORFCatagory table). - <code>-a</code>, <code>--computeAnnot</code>: Annotate ORFs using our own algorithm based on length, biotype, strand and relative position (ORFAnnotation table).</p>
<p><strong>Filter</strong> strategy: - <code>-f</code>, <code>--forceOverwrite</code>: Delete any existing FILT database at the provided path / on the server prior to build a new one. The PRO database from which data is get will not be affected.</p>
<p><strong>GenerateFastaFile</strong> strategy: - <code>-f</code>, <code>--forceOverwrite</code>: Delete any existing database at the provided path / on the server prior to build a new one. - <code>-s</code>, <code>--seqType</code>: Type of the sequence required (<code>DNA</code> or <code>PROT</code>). - <code>-q</code>, <code>--queryTable</code>: Table to query to generate the FASTA file (<code>ORF</code> for <em>ORF</em> table, <code>OTA</code> for <em>ORFTranscriptAsso</em> table). - <code>-e</code>, <code>--excludeSqcesWithStop</code>: If selected, all the sequences that contains stop codons (at any other place that their end) will be excluded of the fasta file. - <code>-l</code>, <code>--longHeader</code>: Use this option to get long fasta headers. - <code>-o</code>, <code>--outputFolder</code>: The absolute path to the folder in which the GFF file has to be saved. - <code>-a</code>, <code>--fastaFilename</code>: The name for the FASTA file generated (without its extension).</p>
<p><strong>GenerateBEDFile</strong> strategy: - <code>-o</code>, <code>--outputFolder</code>: Absolute path to the folder in which the BED file has to be saved. - <code>-b</code>, <code>--bedFilename</code>: Name for the BED file generated (without “.bed” extension). - <code>-l</code>, <code>--trackLine</code>: Add the track line at the beginning of the BED file. - <code>-n</code>, <code>--includeNonConventionalChr</code>: Should the ORFs located on “non conventional” chromosomes (<em>e.g.</em> mitochondrial, scaffold) be included in the BED file? - <code>-e</code>, <code>--extendBed</code>: Extend the BED file at 12+5 format. - <code>-g</code>, <code>--bigBed</code>: Convert the BED file at the BigBed.</p>
<p><strong>GenerateTrackDbFile</strong> strategy: - <code>-o</code>, <code>--outputFolder</code>: Absolute path to the folder in which the trackDb file has to be saved - <code>-f</code>, <code>--trackFilename</code>: Name for the trackDb file generated (without “.txt” extension). - <code>-g</code>, <code>--bigBed</code>: Create the bigBed file corresponding to the trackDb file at the same time. See the <strong>Export the ORF information at BED format</strong> section of the current manual for more information. If selected, both the BED, bigBed, <code>.as</code> and <code>.chrom.sizes</code> files will be generated in the same folder than the <code>trackDb.txt</code> file. The output generated by the use of this option are the same than the one generated using the <strong>GenerateBEDFile</strong> strategy <strong>with</strong> <code>--extendBed</code> and <code>--bigBed</code> options and <strong>without</strong> <code>--includeNonConventionalChr</code> options.</p>
<p><strong>GenerateGFFFile</strong> strategy: - <code>-o</code>, <code>--outputFolder</code>: Absolute path to the folder in which the GFF file has to be saved. - <code>-g</code>, <code>--gffFilename</code>: Name for the GFF file generated (without the “.gff” or “.gff3” extension).</p>
<p><strong>AssessDatabaseContent</strong> strategy: - <code>-o</code>, <code>--outputFolder</code>: Absolute path to the folder in which all the files generated have to be saved. - <code>-f</code>, <code>--filename</code>: Name for the log file generated.</p>
<p><strong>GenerateStatFiles</strong> strategy: - <code>-f</code>, <code>--forceOverwrite</code>: Overwrite any existing files. - <code>-o</code>, <code>--outputFolder</code>: Absolute path to the folder in which all the files generated have to be saved.</p>
<p><strong>Backup</strong> strategy: - <code>-o</code>, <code>--outputFolder</code>: Absolute path to the folder in which the files have to be saved. - <code>-x</code>, <code>--filePrefix</code>: Prefix to add to the file names where data are saved.</p>
<p><strong>Restore</strong> strategy: - <code>-f</code>, <code>--forceOverwrite</code>: Delete any existing database at the provided path / on the server prior to restore the database from backup. - <code>-i</code>, <code>--inputFolder</code>: Absolute path to the folder in which the files are located. - <code>-x</code>, <code>--filePrefix</code>: Prefix used when generated the files with the Restore strategy.</p>
<h1 id="list-of-default-values">List of default values</h1>
<p>The following values are used by default when no provided in the config file or by an option:</p>
<ul>
<li><p><code>DATABASE_HOST_IP</code>: 127.0.0.1</p></li>
<li><p><code>DATABASE_PORT</code>: 3306</p></li>
<li><p><code>DATABASE_USER_NAME</code>: root</p></li>
<li><p><code>DATABASE_USER_PASSWD</code>: DenCellORFMySQL</p></li>
<li><p><code>DATABASE_FOLDER</code>: /output</p></li>
<li><p><code>GENOMIC_LENGTH_DIFF_THRESHOLD</code>: 1</p></li>
<li><p><code>SEQUENCE_CONSENSUS_AMBIGUOUS_THRESHOLD</code>: 2/3</p></li>
<li><p><code>MAX_LEN_DIFF_FOR_DSOTA_CLUSTERS</code>: 3</p></li>
<li><p><code>CELL_CONTEXTS_DICTIONARY</code>:</p></li>
</ul>
<pre><code>{   HSAPIENS:   { 
                    &#39;BJ&#39;:               [ &#39;loayza_puch_2013&#39;, &#39;rooijers_2013&#39;, &#39;ji_BJ_2015&#39; ],
                    &#39;B_cell&#39;:           [ &#39;B cells&#39; ],
                    &#39;Blood&#39;:            [ &#39;mills_2016&#39; ],
                    &#39;Brain&#39;:            [ &#39;gonzalez_2014&#39; ],
                    &#39;Brain_tumor&#39;:      [ &#39;Human brain tumor&#39; ],
                    &#39;Breast&#39;:           [ &#39;ji_breast_2015&#39; ],
                    &#39;HAP1&#39;:             [ &#39;jakobsson_2017&#39; ],
                    &#39;HCT116&#39;:           [ &#39;crappe_2014&#39; ],
                    &#39;HEK293&#39;:           [ &#39;lee_2012&#39;, &#39;andreev_2015&#39;, &#39;sidrauski_2015&#39;, &#39;liu_2013_HEK&#39;,
                                          &#39;liu_HEK_2013&#39;, &#39;ingolia_2012&#39;, &#39;ingolia_2014&#39;, &#39;calviello_2016&#39;, 
                                          &#39;iwasaki_2016&#39;, &#39;park_2017&#39;, &#39;zhang_2017&#39; ],
                    &#39;HEK293T&#39;:          [ &#39;eichorn_2014&#39;, &#39;jan_2014&#39; ],
                    &#39;HFF&#39;:              [ &#39;Primary human foreskin fibroblasts (HFFs)&#39;, 
                                          &#39;Primary human fibroblast (HFF)&#39;, &#39;rutkowski_2015&#39; ],
                    &#39;HeLa&#39;:             [ &#39;wang_2015&#39;, &#39;niu_2014&#39;, &#39;yoon_2014&#39;, &#39;liu_2013_HeLa&#39;, &#39;liu_Hela_2013&#39;,
                                          &#39;stumpf_2013&#39;, &#39;park_2016&#39;, &#39;zur_2016&#39;, &#39;shi_2017&#39; ],
                    &#39;hES&#39;:              [ &#39;werner_2015&#39;, &#39;xu_2016&#39; ],
                    &#39;Jurkat&#39;:           [ &#39;gawron_2016&#39; ],
                    &#39;LCL&#39;:              [ &#39;cenik_2015&#39; ],
                    &#39;MCF7&#39;:             [ &#39;Loayza_Puch_2016&#39; ],
                    &#39;MDA-MB-231&#39;:       [ &#39;rubio_2014&#39; ],
                    &#39;MM1S&#39;:             [ &#39;wiita_2013&#39; ],
                    &#39;Monocyte&#39;:         [ &#39;su_2015&#39; ],
                    &#39;NCCIT&#39;:            [ &#39;grow_2015&#39; ],
                    &#39;RPE-1&#39;:            [ &#39;tanenbaum_2015&#39;, &#39;tirosh_2015&#39; ],
                    &#39;Skeletal_muscle&#39;:  [ &#39;wein_2014&#39; ],
                    &#39;THP-1&#39;:            [ &#39;fritsch_2012&#39;, &#39;stern_ginossar_2012&#39; ],
                    &#39;U2OS&#39;:             [ &#39;elkon_2015&#39; ],
                    &#39;Flp-In_T-REx-293&#39;: [ &#39;malecki_2017&#39; ]
                },
    MMUSCULUS:  { 
                    &#39;3T3&#39;:              [ &#39;eichorn_3t3_2014&#39; ],
                    &#39;BMDC&#39;:             [ &#39;jovanovic_2015&#39;, &#39;fields_2015&#39; ],
                    &#39;B_cell&#39;:           [ &#39;eichorn_bcell_2014&#39; ],
                    &#39;Brain&#39;:            [ &#39;gonzalez_2014_mmu&#39;, &#39;cho_2015&#39;, &#39;laguesse_2015&#39; ],
                    &#39;C2C12&#39;:            [ &#39;deklerck_2015&#39; ],
                    &#39;E14&#39;:              [ &#39;ingolia_2014_mmu&#39;, &#39;Ingolia_2011&#39; ],
                    &#39;Glioma&#39;:           [ &#39;Mouse gliomal cells&#39;, &#39; Mouse gliomal cells&#39; ],
                    &#39;Liver&#39;:            [ &#39;Mouse liver cell&#39;, &#39;eichorn_liver_2014&#39;, &#39;gao_liver_2014&#39;, 
                                          &#39;gerashchenko_2016&#39;, &#39;janich_2015&#39; ],
                    &#39;MEF&#39;:              [ &#39; Mouse Embryonic Fibroblast (MEFs)&#39;, &#39;Mouse Embryonic Fibroblast (MEFs)&#39;, 
                                          &#39;thoreen_2012&#39;, &#39;lee_2012_mmu&#39;, &#39;gao_mef_2014&#39;, 
                                          &#39;reid_er_2016&#39;, &#39;reid_cytosol_2016&#39;, &#39;reid_2014&#39; ],
                    &#39;MESC&#39;:             [ &#39;Mouse Embryonic Stem Cells&#39; ],
                    &#39;NSC&#39;:              [ &#39;katz_2014&#39; ],
                    &#39;Neutrophil&#39;:       [ &#39;guo_2010_mmu&#39; ],
                    &#39;R1E&#39;:              [ &#39;you_2015&#39; ],
                    &#39;Skin_tumor&#39;:       [ &#39;blanco_2016&#39; ],
                    &#39;Spleen_B_cell&#39;:    [ &#39;diaz_munoz_2015&#39; ],
                    &#39;Testis&#39;:           [ &#39;castaneda_2014&#39; ],
                    &#39;v6-5&#39;:             [ &#39;hurt_2013&#39; ]
                } 
}</code></pre>
<ul>
<li><code>CATEGORY_ASSOCIATION_DICTIONARY</code>:</li>
</ul>
<pre><code>{
    &#39;None&#39;:             [&#39;NO_FRAME&#39;, &#39;other&#39;, &#39;TEC&#39;, &#39;In&#39;], 
    &#39;Intergenic&#39;:       [&#39;lincRNA&#39;, &#39;INTERGENIC&#39;, &#39;intergenic&#39;], 
    &#39;Upstream&#39;:         [&#39;5UTR&#39;, &#39;5_UTR&#39;, &#39;uoORF&#39;, &#39;uORF&#39;, &#39;utr5&#39;], 
    &#39;Intronic&#39;:         [&#39;INTRON&#39;, &#39;iORF&#39;, &#39;intronic&#39;, &#39;RETAINED_INTRON&#39;], 
    &#39;Exonic&#39;:           [&#39;EXON&#39;, &#39;exonic&#39;], 
    &#39;ncRNA&#39;:            [&#39;lincRNA&#39;, &#39;lncrna&#39;, &#39;ncRNA&#39;], 
    &#39;Pseudogene&#39;:       [&#39;pseudogene&#39;], 
    &#39;Downstream&#39;:       [&#39;3UTR&#39;, &#39;3_UTR&#39;, &#39;dORF&#39;, &#39;utr3&#39;], 
    &#39;NSD&#39;:              [&#39;NSD&#39;], 
    &#39;NMD&#39;:              [&#39;NMD&#39;], 
    &#39;Overlapping&#39;:      [&#39;CDS_overlap&#39;, &#39;uoORF&#39;, &#39;ANTISENSE&#39;], 
    &#39;sORF&#39;:             [&#39;sORF&#39;], 
    &#39;CDS&#39;:              [&#39;annotated&#39;, &#39;Annotated&#39;, &#39;Isoform&#39;], 
    &#39;Alternative&#39;:      [&#39;Out&#39;, &#39;alternative_frame&#39;]
}</code></pre>
<ul>
<li><p>Default output folder: /output</p></li>
<li><p>Default temporary folder: /output/.tmp</p></li>
<li><p>Default ambiguous letter to use for unknown nucleotide: N</p></li>
<li><p>Default ambiguous letter to use for unknown amino acid: X</p></li>
</ul>
<h1 id="additional-information">Additional information</h1>
<ul>
<li><p>List of accepted species in the config file: <code>Hsapiens</code>, <code>Mmusculus</code>.</p></li>
<li><p>List of files that can be parsed:</p>
<ul>
<li>Cross-references:
<ul>
<li><code>HGNCGeneList</code>: List of cross-reference provided by the <a href="https://www.genenames.org/">HUGO Gene Nomenclature Committee</a> (HGNC).<br />
</li>
<li><code>NCBIGeneList</code>: List of cross-references provided by the <a href="https://www.ncbi.nlm.nih.gov/gene">NCBI</a>.</li>
</ul></li>
<li>ORF datasources:
<ul>
<li><code>Johnstone2016</code>: Dataset from Johnstone <em>et al.</em>, <em>EMBO</em>, 2016 (“Location and translation data for all analyzed transcripts and ORFs”, datasets EV2 and EV3).</li>
<li><code>Mackowiak2015</code>: Dataset from Mackowiak <em>et al.</em>, <em>Genome Biol.</em>, 2015 (“All sORF information”, Table S1 and S2).</li>
<li><code>Samandi2017</code>: Dataset from Samandi <em>et al.</em>, <em>eLIFE</em>, 2017 (“Alternative protein predictions”, TSV files).</li>
<li><code>sORFs_org</code>: Databases from <a href="http://sorfs.org">sORFs.org</a>, Olexiouk <em>et al.</em>, <em>Nucl. Ac. Res.</em>, 2018, databases download from sORFs.org using the Biomart Graphic User Interface. The ORF data source name used in the config file <strong>must</strong> be <code>sORFs_org_Human</code> or <code>sORFs_org_Mouse</code>.</li>
<li><code>Erhard2018</code>: Dataset from Erhard <em>et al.</em>, <em>Nat. Meth.</em>, 2018 (“Identified ORFs”, supplementary table 3).</li>
<li><code>Laumont2016</code>: Dataset from Laumont <em>et al.</em>, <em>Nat. Commun.</em>, 2016 (“List of all cryptic MAPs”, supplementary data 2).</li>
</ul></li>
</ul></li>
<li><p>List of accepted genome annotation version:</p>
<ul>
<li>Hsapiens: GRCh38 / hg38, GRCh37 / hg19.</li>
<li>Mmusculus: GRCm38 / mm10.</li>
</ul></li>
</ul>
<h1 id="authors-license-and-copyright">Authors, license and copyright</h1>
<p>Sébastien A. Choteau<sup>1,2</sup>, Lionel Spinelli<sup>1,2</sup>, Philippe Pierre<sup>2</sup>, Christine Brun<sup>1,3</sup></p>
<ol type="1">
<li>Aix-Marseille Univ, INSERM, TAGC, CENTURI, Marseille, France</li>
<li>Aix-Marseille Univ, CNRS, INSERM, CIML, CENTURI, Marseille, France</li>
<li>CNRS, Marseille, France</li>
</ol>
<p>If you have questions or comments, please write to:</p>
<ul>
<li>Sébastien A. Choteau at <a href="mailto:sebastien.choteau@univ-amu.fr">sebastien.choteau@univ-amu.fr</a></li>
</ul>
<h1 id="last-update-of-the-manual-25052020">Last update of the manual: 25/05/2020</h1>
</body>
</html>
